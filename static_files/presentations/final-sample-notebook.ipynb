{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-08T04:21:53.708968Z","iopub.status.busy":"2023-04-08T04:21:53.708638Z","iopub.status.idle":"2023-04-08T04:22:02.410335Z","shell.execute_reply":"2023-04-08T04:22:02.409251Z","shell.execute_reply.started":"2023-04-08T04:21:53.708939Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import json\n","import sys\n","import os\n","\n","#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","directory = \"/kaggle/input/practical-innovative-data-science-2023/\"\n","user_data = directory + \"training_data\"\n","valid_data = directory + \"training_data\"\n","test_data = directory + \"label_book/\" # this can be the label book, or any other test set you create"]},{"cell_type":"markdown","metadata":{},"source":["# Rules\n","\n","- Submission must have less than 10,000 images combined in training and validation\n","\n","**Submissions will be evaluated according to two categories:**\n","1. **Best Performance Overall**\n","2. **Most Innovative**"]},{"cell_type":"markdown","metadata":{},"source":["# Getting started\n","\n","\n","The dataset contains ~4300 images of handwritten roman numerals 1-10. **Your task is to optimize model performance by improving the dataset and making training and validation splits.**\n","\n","You can try fixing incorrect labels, adding data for side case tuning, apply data augmentation techniques, or use any other method to improve the data. You may also find it helpful to take a look at the training script to get a better sense of the preprocessing and model (these are held fixed). The script will resize all images to `(32, 32)` and run them through a cut off ResNet50. "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T04:22:02.414993Z","iopub.status.busy":"2023-04-08T04:22:02.413829Z","iopub.status.idle":"2023-04-08T04:31:44.903654Z","shell.execute_reply":"2023-04-08T04:31:44.902607Z","shell.execute_reply.started":"2023-04-08T04:22:02.414948Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 3365 files belonging to 10 classes.\n","Found 963 files belonging to 10 classes.\n","Found 52 files belonging to 10 classes.\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," tf.__operators__.getitem (S  (None, 32, 32, 3)        0         \n"," licingOpLambda)                                                 \n","                                                                 \n"," tf.nn.bias_add (TFOpLambda)  (None, 32, 32, 3)        0         \n","                                                                 \n"," model (Functional)          (None, 8, 8, 256)         229760    \n","                                                                 \n"," global_average_pooling2d (G  (None, 256)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 232,330\n","Trainable params: 229,386\n","Non-trainable params: 2,944\n","_________________________________________________________________\n","121/121 [==============================] - 7s 13ms/step - loss: 24.9099 - accuracy: 0.0820\n","loss 24.909870147705078, acc 0.08203530311584473\n","Epoch 1/75\n","421/421 [==============================] - 16s 19ms/step - loss: 2.0594 - accuracy: 0.2847 - val_loss: 2.2623 - val_accuracy: 0.2336 - lr: 1.0000e-04\n","Epoch 2/75\n","421/421 [==============================] - 7s 16ms/step - loss: 1.6547 - accuracy: 0.4541 - val_loss: 2.1180 - val_accuracy: 0.2825 - lr: 1.0000e-04\n","Epoch 3/75\n","421/421 [==============================] - 8s 20ms/step - loss: 1.4364 - accuracy: 0.5560 - val_loss: 1.5684 - val_accuracy: 0.5078 - lr: 1.0000e-04\n","Epoch 4/75\n","421/421 [==============================] - 6s 15ms/step - loss: 1.2635 - accuracy: 0.6128 - val_loss: 1.4342 - val_accuracy: 0.5587 - lr: 1.0000e-04\n","Epoch 5/75\n","421/421 [==============================] - 7s 16ms/step - loss: 1.1299 - accuracy: 0.6639 - val_loss: 1.3890 - val_accuracy: 0.5566 - lr: 1.0000e-04\n","Epoch 6/75\n","421/421 [==============================] - 7s 16ms/step - loss: 1.0396 - accuracy: 0.6930 - val_loss: 1.3896 - val_accuracy: 0.5784 - lr: 1.0000e-04\n","Epoch 7/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.9320 - accuracy: 0.7257 - val_loss: 1.4469 - val_accuracy: 0.5628 - lr: 1.0000e-04\n","Epoch 8/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.8465 - accuracy: 0.7522 - val_loss: 1.4866 - val_accuracy: 0.5639 - lr: 1.0000e-04\n","Epoch 9/75\n","421/421 [==============================] - 7s 15ms/step - loss: 0.7557 - accuracy: 0.7789 - val_loss: 1.6800 - val_accuracy: 0.4964 - lr: 1.0000e-04\n","Epoch 10/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.6636 - accuracy: 0.8086 - val_loss: 1.5154 - val_accuracy: 0.5130 - lr: 1.0000e-04\n","Epoch 11/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.5761 - accuracy: 0.8368 - val_loss: 1.4908 - val_accuracy: 0.5597 - lr: 1.0000e-04\n","Epoch 12/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.5298 - accuracy: 0.8496 - val_loss: 1.6855 - val_accuracy: 0.4974 - lr: 1.0000e-04\n","Epoch 13/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.4435 - accuracy: 0.8811 - val_loss: 1.7837 - val_accuracy: 0.4829 - lr: 1.0000e-04\n","Epoch 14/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.3911 - accuracy: 0.8939 - val_loss: 1.7554 - val_accuracy: 0.5005 - lr: 1.0000e-04\n","Epoch 15/75\n","420/421 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.9036\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n","421/421 [==============================] - 7s 16ms/step - loss: 0.3399 - accuracy: 0.9037 - val_loss: 1.8651 - val_accuracy: 0.4984 - lr: 1.0000e-04\n","Epoch 16/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.2553 - accuracy: 0.9456 - val_loss: 1.4516 - val_accuracy: 0.5992 - lr: 1.0000e-05\n","Epoch 17/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.2135 - accuracy: 0.9587 - val_loss: 1.4367 - val_accuracy: 0.6096 - lr: 1.0000e-05\n","Epoch 18/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.2099 - accuracy: 0.9643 - val_loss: 1.4662 - val_accuracy: 0.6085 - lr: 1.0000e-05\n","Epoch 19/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.2035 - accuracy: 0.9620 - val_loss: 1.4486 - val_accuracy: 0.6044 - lr: 1.0000e-05\n","Epoch 20/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1851 - accuracy: 0.9706 - val_loss: 1.4836 - val_accuracy: 0.6023 - lr: 1.0000e-05\n","Epoch 21/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1832 - accuracy: 0.9730 - val_loss: 1.4933 - val_accuracy: 0.6064 - lr: 1.0000e-05\n","Epoch 22/75\n","421/421 [==============================] - 6s 14ms/step - loss: 0.1784 - accuracy: 0.9676 - val_loss: 1.4982 - val_accuracy: 0.6012 - lr: 1.0000e-05\n","Epoch 23/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1723 - accuracy: 0.9700 - val_loss: 1.5016 - val_accuracy: 0.5929 - lr: 1.0000e-05\n","Epoch 24/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1646 - accuracy: 0.9738 - val_loss: 1.4925 - val_accuracy: 0.6189 - lr: 1.0000e-05\n","Epoch 25/75\n","420/421 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9699\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n","421/421 [==============================] - 7s 15ms/step - loss: 0.1670 - accuracy: 0.9700 - val_loss: 1.4863 - val_accuracy: 0.5992 - lr: 1.0000e-05\n","Epoch 26/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1486 - accuracy: 0.9780 - val_loss: 1.4862 - val_accuracy: 0.6033 - lr: 1.0000e-06\n","Epoch 27/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1501 - accuracy: 0.9768 - val_loss: 1.4765 - val_accuracy: 0.6033 - lr: 1.0000e-06\n","Epoch 28/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1446 - accuracy: 0.9801 - val_loss: 1.4821 - val_accuracy: 0.6002 - lr: 1.0000e-06\n","Epoch 29/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1496 - accuracy: 0.9777 - val_loss: 1.4816 - val_accuracy: 0.5992 - lr: 1.0000e-06\n","Epoch 30/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1450 - accuracy: 0.9804 - val_loss: 1.4824 - val_accuracy: 0.6012 - lr: 1.0000e-06\n","Epoch 31/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1433 - accuracy: 0.9807 - val_loss: 1.4840 - val_accuracy: 0.6012 - lr: 1.0000e-06\n","Epoch 32/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1376 - accuracy: 0.9857 - val_loss: 1.4804 - val_accuracy: 0.6012 - lr: 1.0000e-06\n","Epoch 33/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.1431 - accuracy: 0.9798 - val_loss: 1.4817 - val_accuracy: 0.6012 - lr: 1.0000e-06\n","Epoch 34/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1481 - accuracy: 0.9792 - val_loss: 1.4765 - val_accuracy: 0.6002 - lr: 1.0000e-06\n","Epoch 35/75\n","416/421 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9790\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-07.\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1402 - accuracy: 0.9792 - val_loss: 1.4779 - val_accuracy: 0.6023 - lr: 1.0000e-06\n","Epoch 36/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1496 - accuracy: 0.9738 - val_loss: 1.4803 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 37/75\n","421/421 [==============================] - 8s 18ms/step - loss: 0.1457 - accuracy: 0.9813 - val_loss: 1.4792 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 38/75\n","421/421 [==============================] - 7s 15ms/step - loss: 0.1437 - accuracy: 0.9810 - val_loss: 1.4782 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 39/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1552 - accuracy: 0.9750 - val_loss: 1.4798 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 40/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1465 - accuracy: 0.9747 - val_loss: 1.4800 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 41/75\n","421/421 [==============================] - 7s 15ms/step - loss: 0.1419 - accuracy: 0.9771 - val_loss: 1.4805 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 42/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1396 - accuracy: 0.9804 - val_loss: 1.4804 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 43/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1350 - accuracy: 0.9810 - val_loss: 1.4782 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 44/75\n","421/421 [==============================] - 7s 15ms/step - loss: 0.1461 - accuracy: 0.9801 - val_loss: 1.4824 - val_accuracy: 0.6012 - lr: 1.0000e-07\n","Epoch 45/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.1343 - accuracy: 0.9834 - val_loss: 1.4815 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 46/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1433 - accuracy: 0.9813 - val_loss: 1.4798 - val_accuracy: 0.6012 - lr: 1.0000e-07\n","Epoch 47/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1460 - accuracy: 0.9777 - val_loss: 1.4836 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 48/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1355 - accuracy: 0.9845 - val_loss: 1.4819 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 49/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1415 - accuracy: 0.9786 - val_loss: 1.4807 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 50/75\n","421/421 [==============================] - 7s 15ms/step - loss: 0.1362 - accuracy: 0.9842 - val_loss: 1.4808 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 51/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.1382 - accuracy: 0.9795 - val_loss: 1.4812 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 52/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1478 - accuracy: 0.9774 - val_loss: 1.4852 - val_accuracy: 0.5961 - lr: 1.0000e-07\n","Epoch 53/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1433 - accuracy: 0.9774 - val_loss: 1.4830 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 54/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.1496 - accuracy: 0.9774 - val_loss: 1.4804 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 55/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1366 - accuracy: 0.9810 - val_loss: 1.4831 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 56/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1416 - accuracy: 0.9834 - val_loss: 1.4829 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 57/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1331 - accuracy: 0.9842 - val_loss: 1.4823 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 58/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1315 - accuracy: 0.9834 - val_loss: 1.4853 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 59/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1399 - accuracy: 0.9819 - val_loss: 1.4850 - val_accuracy: 0.5971 - lr: 1.0000e-07\n","Epoch 60/75\n","421/421 [==============================] - 6s 14ms/step - loss: 0.1403 - accuracy: 0.9807 - val_loss: 1.4864 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 61/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1379 - accuracy: 0.9840 - val_loss: 1.4840 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 62/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.1385 - accuracy: 0.9842 - val_loss: 1.4852 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 63/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1422 - accuracy: 0.9807 - val_loss: 1.4846 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 64/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1319 - accuracy: 0.9834 - val_loss: 1.4841 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 65/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1369 - accuracy: 0.9804 - val_loss: 1.4826 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 66/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1334 - accuracy: 0.9842 - val_loss: 1.4827 - val_accuracy: 0.5971 - lr: 1.0000e-07\n","Epoch 67/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.1363 - accuracy: 0.9840 - val_loss: 1.4855 - val_accuracy: 0.5971 - lr: 1.0000e-07\n","Epoch 68/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1408 - accuracy: 0.9828 - val_loss: 1.4855 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 69/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1424 - accuracy: 0.9789 - val_loss: 1.4868 - val_accuracy: 0.6002 - lr: 1.0000e-07\n","Epoch 70/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1432 - accuracy: 0.9798 - val_loss: 1.4854 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 71/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1443 - accuracy: 0.9792 - val_loss: 1.4853 - val_accuracy: 0.5981 - lr: 1.0000e-07\n","Epoch 72/75\n","421/421 [==============================] - 7s 16ms/step - loss: 0.1416 - accuracy: 0.9786 - val_loss: 1.4841 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 73/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1341 - accuracy: 0.9840 - val_loss: 1.4859 - val_accuracy: 0.5971 - lr: 1.0000e-07\n","Epoch 74/75\n","421/421 [==============================] - 6s 15ms/step - loss: 0.1313 - accuracy: 0.9819 - val_loss: 1.4839 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","Epoch 75/75\n","421/421 [==============================] - 7s 17ms/step - loss: 0.1336 - accuracy: 0.9822 - val_loss: 1.4816 - val_accuracy: 0.5992 - lr: 1.0000e-07\n","121/121 [==============================] - 1s 7ms/step - loss: 1.4925 - accuracy: 0.6189\n","final loss 1.4924625158309937, final acc 0.6188992857933044\n","7/7 [==============================] - 0s 15ms/step - loss: 1.8875 - accuracy: 0.5769\n","test loss 1.8874746561050415, test acc 0.5769230723381042\n"]}],"source":["### DO NOT MODIFY BELOW THIS LINE, THIS IS THE FIXED MODEL ###\n","batch_size = 8\n","tf.random.set_seed(2023)\n","\n","train = tf.keras.preprocessing.image_dataset_from_directory(\n","        user_data + '/train',\n","        labels=\"inferred\",\n","        label_mode=\"categorical\",\n","        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n","        shuffle=True,\n","        seed=2023,\n","        batch_size=batch_size,\n","        image_size=(32, 32),\n","    )\n","\n","valid = tf.keras.preprocessing.image_dataset_from_directory(\n","        user_data + '/val',\n","        labels=\"inferred\",\n","        label_mode=\"categorical\",\n","        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n","        shuffle=True,\n","        seed=2023,\n","        batch_size=batch_size,\n","        image_size=(32, 32),\n",")\n","\n","total_length = ((train.cardinality() + valid.cardinality()) * batch_size).numpy()\n","\n","if total_length > 10_000:\n","    print(f\"Dataset size larger than 10,000. Got {total_length} examples\")\n","    sys.exit()\n","\n","test = tf.keras.preprocessing.image_dataset_from_directory(\n","        test_data,\n","        labels=\"inferred\",\n","        label_mode=\"categorical\",\n","        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n","        shuffle=False,\n","        seed=123,\n","        batch_size=batch_size,\n","        image_size=(32, 32),\n",")\n","\n","base_model = tf.keras.applications.ResNet50(\n","        input_shape=(32, 32, 3),\n","        include_top=False,\n","        weights=None,\n",")\n","base_model = tf.keras.Model(\n","        base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n",")\n","\n","inputs = tf.keras.Input(shape=(32, 32, 3))\n","x = tf.keras.applications.resnet.preprocess_input(inputs)\n","x = base_model(x)\n","x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","x = tf.keras.layers.Dense(10)(x)\n","model = tf.keras.Model(inputs, x)\n","\n","\n","model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n","        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","        metrics=[\"accuracy\"],\n",")\n","model.summary()\n","    \n","loss_0, acc_0 = model.evaluate(valid)\n","print(f\"loss {loss_0}, acc {acc_0}\")\n","\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","        \"best_model\",\n","        monitor=\"val_accuracy\",\n","        mode=\"max\",\n","        save_best_only=True,\n","        save_weights_only=True,\n",")\n","lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1, min_lr=1e-7)\n","\n","history = model.fit(\n","        train,\n","        validation_data=valid,\n","        epochs=75,\n","        callbacks=[checkpoint, lr_scheduler],\n",")\n","\n","model.load_weights(\"best_model\")\n","\n","loss, acc = model.evaluate(valid)\n","print(f\"final loss {loss}, final acc {acc}\")\n","\n","test_loss, test_acc = model.evaluate(test)\n","print(f\"test loss {test_loss}, test acc {test_acc}\")\n","\n","### DO NOT MODIFY ABOVE THIS LINE, THIS IS THE FIXED MODEL ###"]},{"cell_type":"markdown","metadata":{},"source":["## Make your submission"]},{"cell_type":"markdown","metadata":{},"source":["Remember that the evaluation metric is Macro F1 score, you may want to also evaluate the above results using the Macro F1 score before submission."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T04:32:28.734394Z","iopub.status.busy":"2023-04-08T04:32:28.734019Z","iopub.status.idle":"2023-04-08T04:32:30.496472Z","shell.execute_reply":"2023-04-08T04:32:30.495412Z","shell.execute_reply.started":"2023-04-08T04:32:28.734361Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 400 files belonging to 1 classes.\n","400/400 [==============================] - 1s 3ms/step\n"]}],"source":["test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    directory+\"test_data\",\n","    shuffle = False,\n","    image_size=(32, 32),\n","    batch_size=1)\n","\n","prob = model.predict(test_dataset)\n","predictions = []\n","for i in range(0, prob.shape[0]):\n","    predictions.append(np.argmax(prob[i,:])+1)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-08T04:32:30.500034Z","iopub.status.busy":"2023-04-08T04:32:30.499355Z","iopub.status.idle":"2023-04-08T04:32:30.510240Z","shell.execute_reply":"2023-04-08T04:32:30.509221Z","shell.execute_reply.started":"2023-04-08T04:32:30.499994Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","paths = test_dataset.file_paths\n","\n","Ids = []\n","for x in paths:\n","    Ids.append(x.split(\"/\")[-1])\n","    \n","df = pd.DataFrame()\n","df[\"Id\"] = Ids\n","df[\"Predicted\"] = predictions\n","df.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Click <a href=\"submission.csv\"> here </a> to download the submission"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
