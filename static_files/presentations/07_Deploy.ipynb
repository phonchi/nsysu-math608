{"cells":[{"cell_type":"markdown","metadata":{"id":"1QiCFLer1FIe"},"source":["**Lab 7 – Deploy**"]},{"cell_type":"markdown","metadata":{"id":"9J5g6PDs1FIk"},"source":["<table align=\"left\">\n","  <td>\n","    <a href=\"https://colab.research.google.com/github/phonchi/nsysu-math608/blob/master/static_files/presentations/07_Deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/phonchi/nsysu-math608/blob/master/static_files/presentations/07_Deploy.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n","  </td>\n","</table>"]},{"cell_type":"code","source":["!pip install bentoml -qq\n","!pip install pyngrok -qq\n","!pip install PyYAML -U -qq\n","!pip install streamlit -qq\n","!pip install gradio -qq\n","!pip install evidently -qq"],"metadata":{"id":"8YFCNVkuZ3U4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed67a996-412c-4966-844b-af48b91e41ac","executionInfo":{"status":"ok","timestamp":1680053944396,"user_tz":-480,"elapsed":71243,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m968.6/968.6 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 KB\u001b[0m \u001b[31m991.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bentoml 1.0.16 requires starlette<0.26, but you have starlette 0.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["Notice that **you may need to restart the kernel** after the above installations."],"metadata":{"id":"ORfWcYOulopf"}},{"cell_type":"code","source":["# Scientific computing\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt\n","from matplotlib import cm\n","%matplotlib inline\n","\n","# Modeling\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn import ensemble\n","from sklearn import datasets\n","\n","# Deploy\n","import bentoml\n","import gradio as gr\n","\n","# Monitoring\n","from evidently import ColumnMapping\n","from evidently.report import Report\n","from evidently.metric_preset import DataDriftPreset, TargetDriftPreset, RegressionPreset\n","\n","# Helper library\n","from pyngrok import ngrok, conf\n","import getpass\n","\n","# Other system library\n","from pathlib import Path\n","import requests\n","import os\n","import json\n","import sys\n","\n","import zipfile\n","import io\n","from datetime import datetime, time"],"metadata":{"id":"5bV_HvPiH-9i","executionInfo":{"status":"ok","timestamp":1680060373190,"user_tz":-480,"elapsed":971,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":["Here are some tips for this notebook https://amitness.com/2020/06/google-colaboratory-tips/ and https://stackoverflow.com/questions/59741453/is-there-a-general-way-to-run-web-applications-on-google-colab."],"metadata":{"id":"VCxpUaR0Eot3"}},{"cell_type":"markdown","source":["`ngrok` is a reverse proxy tool that opens secure tunnels from public URLs to localhost, perfect for exposing local web servers, building webhook integrations, enabling SSH access, testing chatbots, demoing from your own machine, and more. In this lab, we will use use https://pyngrok.readthedocs.io/en/latest/integrations.html. However, for production environment, it is recommended to use cloud service such as AWS, GCP or Azure, see [here](https://towardsdatascience.com/the-hierarchy-of-ml-tooling-on-the-public-cloud-ed387cac3c27) or https://pycaret.gitbook.io/docs/get-started/functions/deploy#deploy_model for more details."],"metadata":{"id":"xyQuXGAscwSG"}},{"cell_type":"code","source":["print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n","conf.get_default().auth_token = getpass.getpass()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mR37ypzgQtw5","outputId":"b7c7d297-00ad-4ce0-bbac-e2892a5221d7","executionInfo":{"status":"ok","timestamp":1680054591860,"user_tz":-480,"elapsed":3300,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\n","··········\n"]}]},{"cell_type":"code","source":["# Setup a tunnel to the streamlit port 8050\n","public_url = ngrok.connect(8050)"],"metadata":{"id":"ZX7_8hbYPMyo","executionInfo":{"status":"ok","timestamp":1680054596602,"user_tz":-480,"elapsed":2393,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c502971-8404-49da-fd41-799fa139b4d9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"code","source":["public_url"],"metadata":{"id":"S7fv6CyzPjMj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5843bfa-9f67-4e3d-d51b-4dfe49562f5e","executionInfo":{"status":"ok","timestamp":1680054596602,"user_tz":-480,"elapsed":3,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"http://faf8-34-147-81-41.ngrok.io\" -> \"http://localhost:8050\">"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["if not tf.config.list_physical_devices('GPU'):\n","    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n","    if \"google.colab\" in sys.modules:\n","        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n","              \"accelerator.\")\n","    if \"kaggle_secrets\" in sys.modules:\n","        print(\"Go to Settings > Accelerator and select GPU.\")"],"metadata":{"id":"W9szDcW86f33","executionInfo":{"status":"ok","timestamp":1680054597640,"user_tz":-480,"elapsed":1040,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Deploying TensorFlow models to TensorFlow Serving (TFS)"],"metadata":{"id":"crG8mceteV3J"}},{"cell_type":"markdown","source":["You could create your own microservice using any technology you want (e.g., using the Flask library), but why reinvent the wheel when you can just use TF Serving?"],"metadata":{"id":"cV8Zc1Bqy91q"}},{"cell_type":"markdown","source":["### Exporting `SavedModels`"],"metadata":{"id":"Skjq-RutzUhU"}},{"cell_type":"markdown","source":["TensorFlow provides a simple `tf.saved_model.save()` function to export models to the SavedModel format. All you need to do is give it the model, specifying its name and version number, and the function will save the model’s computation graph and its weights:"],"metadata":{"id":"xKWJOHQZzX7I"}},{"cell_type":"code","source":["# Load and split the MNIST dataset\n","mnist = tf.keras.datasets.mnist.load_data()\n","(X_train_full, y_train_full), (X_test, y_test) = mnist\n","X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n","y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ek0vl3M1yKJy","outputId":"4a16016a-6733-4598-c4dc-c9916bcf16b1","executionInfo":{"status":"ok","timestamp":1680002015161,"user_tz":-480,"elapsed":1179,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"markdown","source":["It’s usually a good idea to include all the preprocessing layers in the final model you export so that it can ingest data in its natural form once it is deployed to production. This  avoids  having  to  take  care  of  preprocessing  separately  within  the  application that uses the model. Bundling the preprocessing steps within the model also makes it simpler to update them later on and limits the risk of mismatch between a model and\n","the preprocessing steps it requires!"],"metadata":{"id":"Vj-GEIXH7iPt"}},{"cell_type":"code","source":["# Build & train an MNIST model (also handles image preprocessing)\n","\n","tf.random.set_seed(42)\n","tf.keras.backend.clear_session()\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n","    tf.keras.layers.Rescaling(scale=1 / 255),\n","    tf.keras.layers.Dense(100, activation=\"relu\"),\n","    tf.keras.layers.Dense(10, activation=\"softmax\")\n","])\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n","              metrics=[\"accuracy\"])\n","model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-V7C_DyLzfOK","outputId":"a2f4402a-b274-4da5-9dbe-d9b538746b69","executionInfo":{"status":"ok","timestamp":1680002165184,"user_tz":-480,"elapsed":88509,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 12s 4ms/step - loss: 0.7007 - accuracy: 0.8216 - val_loss: 0.3758 - val_accuracy: 0.8980\n","Epoch 2/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.3560 - accuracy: 0.9020 - val_loss: 0.3034 - val_accuracy: 0.9140\n","Epoch 3/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.3056 - accuracy: 0.9142 - val_loss: 0.2692 - val_accuracy: 0.9246\n","Epoch 4/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.2756 - accuracy: 0.9229 - val_loss: 0.2475 - val_accuracy: 0.9298\n","Epoch 5/10\n","1719/1719 [==============================] - 8s 5ms/step - loss: 0.2528 - accuracy: 0.9296 - val_loss: 0.2286 - val_accuracy: 0.9322\n","Epoch 6/10\n","1719/1719 [==============================] - 6s 4ms/step - loss: 0.2343 - accuracy: 0.9341 - val_loss: 0.2148 - val_accuracy: 0.9392\n","Epoch 7/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.2183 - accuracy: 0.9391 - val_loss: 0.1998 - val_accuracy: 0.9444\n","Epoch 8/10\n","1719/1719 [==============================] - 12s 7ms/step - loss: 0.2045 - accuracy: 0.9424 - val_loss: 0.1895 - val_accuracy: 0.9474\n","Epoch 9/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.1922 - accuracy: 0.9462 - val_loss: 0.1797 - val_accuracy: 0.9502\n","Epoch 10/10\n","1719/1719 [==============================] - 8s 5ms/step - loss: 0.1817 - accuracy: 0.9489 - val_loss: 0.1703 - val_accuracy: 0.9514\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fccb46c1850>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["X_new = X_test[:3]  # pretend we have 3 new digit images to classify\n","np.round(model.predict(X_new), 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2LJJVPvzwWj","outputId":"0d07cb7f-4998-491a-e34f-df8aeda4cc3b","executionInfo":{"status":"ok","timestamp":1680002282480,"user_tz":-480,"elapsed":919,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 326ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99, 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n","      dtype=float32)"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Now to version the model, you just need to create a subdirectory for each model version:"],"metadata":{"id":"1iUUdBrB7tfr"}},{"cell_type":"code","source":["model_name = \"my_mnist_model\"\n","model_version = \"0001\"\n","model_path = Path(model_name) / model_version\n","#model.save(model_path, save_format=\"tf\")"],"metadata":{"id":"R7sB3_2rz_KA","executionInfo":{"status":"ok","timestamp":1680002244615,"user_tz":-480,"elapsed":1952,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["tf.keras.models.save_model(\n","    model,\n","    model_path,\n","    overwrite=True,\n","    include_optimizer=True,\n","    save_format=\"tf\",\n","    signatures=None,\n","    options=None\n",")"],"metadata":{"id":"fGL8NoSU3k3w","executionInfo":{"status":"ok","timestamp":1680002424879,"user_tz":-480,"elapsed":1064,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["A SavedModel represents a version of your model. It is stored as a directory containing a `saved_model.pb` file, which defines the computation graph (represented as a **serialized protocol buffer**), and a variables subdirectory\n","containing the variable values. For models containing a large number of weights, these variable values may be split across multiple files. A SavedModel also includes an `assets` subdirectory that may contain additional data, such as vocabulary files, class names, or some example instances for this model."],"metadata":{"id":"MTwiLc4_13fw"}},{"cell_type":"code","source":["for root, dirs, files in os.walk(model_name):\n","    indent = '    ' * root.count(os.sep)\n","    print('{}{}/'.format(indent, os.path.basename(root)))\n","    for filename in files:\n","        print('{}{}'.format(indent + '    ', filename))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwjxBrY48VCK","executionInfo":{"status":"ok","timestamp":1680002518080,"user_tz":-480,"elapsed":414,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"4192c300-50df-43e9-b06a-ab2052a74cb3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["my_mnist_model/\n","    0001/\n","        keras_metadata.pb\n","        saved_model.pb\n","        fingerprint.pb\n","        assets/\n","        variables/\n","            variables.index\n","            variables.data-00000-of-00001\n"]}]},{"cell_type":"markdown","source":["As you might expect, you can load a SavedModel using the `tf.keras.models.load_model()` function. "],"metadata":{"id":"qrn8ac6t1aL1"}},{"cell_type":"code","source":["saved_model = tf.keras.models.load_model(model_path)\n","np.round(saved_model.predict(X_new), 2)"],"metadata":{"id":"wHPPMDzt0MP4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680002594761,"user_tz":-480,"elapsed":1410,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"ddd83062-d886-48b1-fb7d-c330bacb0d30"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 107ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99, 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n","      dtype=float32)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["TensorFlow also comes with a small `saved_model_cli` command-line tool to inspect SavedModels:"],"metadata":{"id":"wlmN7c9X4deT"}},{"cell_type":"code","source":["!saved_model_cli show --dir {model_path} --all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"550WGkUX4Mhc","outputId":"a6cd163e-8c8b-4201-9297-1446cde0b53e","executionInfo":{"status":"ok","timestamp":1680002624163,"user_tz":-480,"elapsed":6470,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-28 11:23:38.548893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-28 11:23:38.549018: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-28 11:23:38.549041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","\n","MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n","\n","signature_def['__saved_model_init_op']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['__saved_model_init_op'] tensor_info:\n","        dtype: DT_INVALID\n","        shape: unknown_rank\n","        name: NoOp\n","  Method name is: \n","\n","signature_def['serving_default']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","    inputs['flatten_input'] tensor_info:\n","        dtype: DT_UINT8\n","        shape: (-1, 28, 28)\n","        name: serving_default_flatten_input:0\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['dense_1'] tensor_info:\n","        dtype: DT_FLOAT\n","        shape: (-1, 10)\n","        name: StatefulPartitionedCall:0\n","  Method name is: tensorflow/serving/predict\n","2023-03-28 11:23:41.439161: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","\n","Concrete Functions:\n","  Function Name: '__call__'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          flatten_input: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='flatten_input')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #3\n","      Callable with:\n","        Argument #1\n","          flatten_input: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='flatten_input')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #4\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","\n","  Function Name: '_default_save_signature'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          flatten_input: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='flatten_input')\n","\n","  Function Name: 'call_and_return_all_conditional_losses'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          flatten_input: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='flatten_input')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          flatten_input: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='flatten_input')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #3\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #4\n","      Callable with:\n","        Argument #1\n","          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='inputs')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n"]}]},{"cell_type":"markdown","source":["A SavedModel contains one or more metagraphs. When you pass a `tf.keras` model, by default the function saves a simple SavedModel: it saves a single metagraph tagged \"serve\", which contains two signature definitions, an initialization function (called  `_saved_model_init_op`) and a default serving function (called `serving_default`). When saving a `tf.keras` model, the default serving function corresponds to the model’s `call()` function, which of course makes predictions."],"metadata":{"id":"7lisp5Ox5KPZ"}},{"cell_type":"markdown","source":["### Serve your model with TensorFlow Serving (Server side)"],"metadata":{"id":"y8lzCevs56av"}},{"cell_type":"markdown","source":["There are many ways to install TF Serving: using the system’s package manager, using a Docker image, installing from source, and more. Since Colab/Kaggle runs on Ubuntu, we can use Ubuntu’s  apt  package manager like this:"],"metadata":{"id":"vVhUpbsP6io2"}},{"cell_type":"code","source":["if \"google.colab\" in sys.modules or \"kaggle_secrets\" in sys.modules:\n","    url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n","    src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n","    !echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n","    !curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n","    !apt update -q && apt-get install -y tensorflow-model-server\n","    %pip install -q -U tensorflow-serving-api"],"metadata":{"id":"xANYl8LW4mhv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680002929858,"user_tz":-480,"elapsed":158159,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"940edfd9-ff85-43cc-a3fb-80e459fb6b37"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  17011      0 --:--:-- --:--:-- --:--:-- 17011\n","OK\n","Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n","Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n","Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n","Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n","Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n","Hit:7 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n","Get:8 https://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n","Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,407 kB]\n","Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,140 kB]\n","Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n","Get:12 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,025 kB]\n","Get:13 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,060 kB]\n","Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,587 kB]\n","Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n","Get:16 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [348 B]\n","Hit:17 http://archive.ubuntu.com/ubuntu focal InRelease\n","Get:18 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n","Get:20 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n","Get:21 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,322 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,198 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,065 kB]\n","Fetched 16.2 MB in 31s (526 kB/s)\n","Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","33 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tensorflow-model-server\n","0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n","Need to get 414 MB of archives.\n","After this operation, 0 B of additional disk space will be used.\n","Get:1 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.11.1 [414 MB]\n","Fetched 414 MB in 13s (31.4 MB/s)\n","Selecting previously unselected package tensorflow-model-server.\n","(Reading database ... 128285 files and directories currently installed.)\n","Preparing to unpack .../tensorflow-model-server_2.11.1_all.deb ...\n","Unpacking tensorflow-model-server (2.11.1) ...\n","Setting up tensorflow-model-server (2.11.1) ...\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["> The  code  above starts  by  adding  TensorFlow's  package  repository  to  Ubuntu's  list  of package  sources.  Then  it  downloads  TensorFlow's  public  GPG  key  and  adds  it  to the  package  manager’s  key  list  so  it  can  verify  TensorFlow's  package  signatures. Next, it uses  apt  to install the  `tensorflow-model-server`  package. Lastly, it installs the  `tensorflow-serving-api`  library, which we will need to communicate with the\n","server."],"metadata":{"id":"Vn3kputH-V5x"}},{"cell_type":"markdown","source":["If `tensorflow_model_server` is installed (e.g., if you are running this notebook in Colab/Kaggle), then the following 2 cells will start the server. If your OS is Windows, you may need to run the tensorflow_model_server command in a terminal, and replace `${MODEL_DIR}` with the full path to the `my_mnist_model` directory. This is where we start running TensorFlow Serving and load our model. After it loads we can start making inference requests using REST. There are some important parameters:\n","\n","* `port`: The port that you'll use for gRPC requests.\n","* `rest_api_port`: The port that you'll use for REST requests.\n","* `model_name`: You'll use this in the URL of REST requests. It can be anything.\n","* `model_base_path`: This is the path to the directory where you've saved your model."],"metadata":{"id":"lbp5_Vf39fFu"}},{"cell_type":"code","source":["os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"],"metadata":{"id":"smENzAY76z0V","executionInfo":{"status":"ok","timestamp":1680003011042,"user_tz":-480,"elapsed":420,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["%%bash --bg\n","nohup tensorflow_model_server \\\n","     --port=8500 \\\n","     --rest_api_port=8050 \\\n","     --model_name=my_mnist_model \\\n","     --model_base_path=\"${MODEL_DIR}\" > server.log 2>&1"],"metadata":{"id":"PBGHxWHr7C7n","executionInfo":{"status":"ok","timestamp":1680003178381,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["The  `%%bash  --bg`   magic  command  executes  the  cell  as  a  bash script,  running  it  in  the  background.  The  `>my_server.log  2>&1`   part  redirects  the standard output and standard error to the `server.log` file. And that’s it! TF Serving is now running in the background, and its logs are saved to `server.log`."],"metadata":{"id":"ri7TQRCb_Z4Z"}},{"cell_type":"code","source":["!tail server.log"],"metadata":{"id":"DAuShYuE7H2P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680003200497,"user_tz":-480,"elapsed":503,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"2be70f94-97ff-4643-872b-b6068f4694fa"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[warn] getaddrinfo: address family for nodename not supported\n","[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"]}]},{"cell_type":"markdown","source":["### Querying TF Serving through the REST API (client side)"],"metadata":{"id":"75N3zNzk92fg"}},{"cell_type":"markdown","source":["Let’s start by creating the query. It must contain the name of the function signature you want to call, and of course the input data. Since the request must use the JSON format, we have to convert the input images from a `NumPy` array to a Python list:"],"metadata":{"id":"xD8fQFTv-D2e"}},{"cell_type":"code","source":["input_data_json = json.dumps({\n","    \"signature_name\": \"serving_default\",\n","    \"instances\": X_new.tolist(),\n","})"],"metadata":{"id":"tx5imAfy7W8x","executionInfo":{"status":"ok","timestamp":1680003259148,"user_tz":-480,"elapsed":467,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["Note that the JSON format is 100% text-based:"],"metadata":{"id":"gJ9fpeDQ-MTo"}},{"cell_type":"code","source":["repr(input_data_json)[:1500] + \"...\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"tzPnf4Tk7pn0","outputId":"0c2740fd-993d-4545-975e-69cde491d592","executionInfo":{"status":"ok","timestamp":1680003304902,"user_tz":-480,"elapsed":385,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 84, 185, 159, 151, 60, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 222, 254, 254, 254, 254, 241, 198, 198, 198, 198, 198, 198, 198, 198, 170, 52, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 67, 114, 72, 114, 163, 227, 254, 225, 254, 254, 254, 250, 229, 254, 254, 140, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 66, 14, 67, 67, 67, 59, 21, 236, 254, 106, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 83, 253, 209, 18, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 233, 255, 83, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 254, 238, 44, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 249, 254, 62, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["Now let’s send the input data to TF Serving by sending an HTTP POST request. This can be done easily using the `requests` library:"],"metadata":{"id":"uvg-AMbO-T4g"}},{"cell_type":"code","source":["SERVER_URL = 'http://localhost:8050/v1/models/my_mnist_model:predict'\n","response = requests.post(SERVER_URL, data=input_data_json)\n","response.raise_for_status() # raise an exception in case of error\n","response = response.json()"],"metadata":{"id":"KgBfYn8e7rNz","executionInfo":{"status":"ok","timestamp":1680003388838,"user_tz":-480,"elapsed":450,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["The response is a dictionary containing a single \"predictions\" key. The corresponding value is the list of predictions. This list is a Python list, so let’s convert it to a `NumPy` array and round the floats it contains to the\n","second decimal:"],"metadata":{"id":"fFyZFS9V-cA4"}},{"cell_type":"code","source":["y_proba = np.array(response[\"predictions\"])\n","y_proba.round(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-K8iZuQo7xn1","outputId":"72c621ad-38ca-4f1f-8995-8cc608201613","executionInfo":{"status":"ok","timestamp":1680003429009,"user_tz":-480,"elapsed":487,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99, 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["For more information, please refer to https://github.com/tensorflow/serving which include the usuage of gRPC."],"metadata":{"id":"b6f4iUDeAegQ"}},{"cell_type":"markdown","source":["### Deploying a new model version"],"metadata":{"id":"8UGzlBoKA6OA"}},{"cell_type":"markdown","source":["Now let’s create a new model version and export a SavedModel to the `my_mnist_model/0002` directory, just like earlier:"],"metadata":{"id":"XoatJ_43BTjY"}},{"cell_type":"code","source":["# Change the architecture\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n","    tf.keras.layers.Rescaling(scale=1 / 255),\n","    tf.keras.layers.Dense(50, activation=\"relu\"),\n","    tf.keras.layers.Dense(50, activation=\"relu\"),\n","    tf.keras.layers.Dense(10, activation=\"softmax\")\n","])\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n","              metrics=[\"accuracy\"])\n","history = model.fit(X_train, y_train, epochs=10,\n","                    validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4gE94r57zBE","outputId":"7eb1724a-33f4-4896-a64a-6715cd5e239c","executionInfo":{"status":"ok","timestamp":1680003600864,"user_tz":-480,"elapsed":101017,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 11s 6ms/step - loss: 0.7267 - accuracy: 0.8018 - val_loss: 0.3377 - val_accuracy: 0.9046\n","Epoch 2/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.3219 - accuracy: 0.9068 - val_loss: 0.2651 - val_accuracy: 0.9244\n","Epoch 3/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.2697 - accuracy: 0.9216 - val_loss: 0.2269 - val_accuracy: 0.9356\n","Epoch 4/10\n","1719/1719 [==============================] - 12s 7ms/step - loss: 0.2374 - accuracy: 0.9313 - val_loss: 0.2069 - val_accuracy: 0.9388\n","Epoch 5/10\n","1719/1719 [==============================] - 9s 5ms/step - loss: 0.2142 - accuracy: 0.9382 - val_loss: 0.1877 - val_accuracy: 0.9462\n","Epoch 6/10\n","1719/1719 [==============================] - 11s 7ms/step - loss: 0.1953 - accuracy: 0.9429 - val_loss: 0.1765 - val_accuracy: 0.9508\n","Epoch 7/10\n","1719/1719 [==============================] - 14s 8ms/step - loss: 0.1796 - accuracy: 0.9475 - val_loss: 0.1634 - val_accuracy: 0.9540\n","Epoch 8/10\n","1719/1719 [==============================] - 9s 5ms/step - loss: 0.1662 - accuracy: 0.9517 - val_loss: 0.1581 - val_accuracy: 0.9574\n","Epoch 9/10\n","1719/1719 [==============================] - 7s 4ms/step - loss: 0.1547 - accuracy: 0.9551 - val_loss: 0.1477 - val_accuracy: 0.9572\n","Epoch 10/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.1449 - accuracy: 0.9581 - val_loss: 0.1399 - val_accuracy: 0.9596\n"]}]},{"cell_type":"code","source":["model_version = \"0002\"\n","model_name = \"my_mnist_model\"\n","model_path = os.path.join(model_name, model_version)\n","\n","tf.keras.models.save_model(\n","    model,\n","    model_path,\n","    overwrite=True,\n","    include_optimizer=True,\n","    save_format=\"tf\",\n","    signatures=None,\n","    options=None\n",")"],"metadata":{"id":"rCx3wneqA-ld","executionInfo":{"status":"ok","timestamp":1680003602748,"user_tz":-480,"elapsed":548,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["for root, dirs, files in os.walk(model_name):\n","    indent = '    ' * root.count(os.sep)\n","    print('{}{}/'.format(indent, os.path.basename(root)))\n","    for filename in files:\n","        print('{}{}'.format(indent + '    ', filename))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kz6jGDHhBJHQ","outputId":"a0c4b30c-1952-492d-9b3c-d43d5c5d2733","executionInfo":{"status":"ok","timestamp":1680003604934,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["my_mnist_model/\n","    0001/\n","        keras_metadata.pb\n","        saved_model.pb\n","        fingerprint.pb\n","        assets/\n","        variables/\n","            variables.index\n","            variables.data-00000-of-00001\n","    0002/\n","        keras_metadata.pb\n","        saved_model.pb\n","        fingerprint.pb\n","        assets/\n","        variables/\n","            variables.index\n","            variables.data-00000-of-00001\n"]}]},{"cell_type":"markdown","source":["At regular intervals (the delay is configurable), TensorFlow Serving checks for new model versions. If it finds one, it will automatically handle the transition gracefully: by default, it will answer pending requests (if any) with the previous model version, while handling new requests with the new version. As soon as every pending request has been answered, the previous model version is unloaded. You can see this at work in the TF Serving logs:"],"metadata":{"id":"JNiIxJDABhvx"}},{"cell_type":"code","source":["!tail server.log"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01F5f-q_BYYw","executionInfo":{"status":"ok","timestamp":1680003963446,"user_tz":-480,"elapsed":382,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"d3353f9d-eb9b-49bf-e211-a544a83719b7"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[warn] getaddrinfo: address family for nodename not supported\n","[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"]}]},{"cell_type":"code","source":["SERVER_URL = 'http://localhost:8050/v1/models/my_mnist_model:predict'\n","            \n","response = requests.post(SERVER_URL, data=input_data_json)\n","response.raise_for_status()\n","response = response.json()"],"metadata":{"id":"bykQlJsvBLir","executionInfo":{"status":"ok","timestamp":1680003967848,"user_tz":-480,"elapsed":1,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["y_proba = np.array(response[\"predictions\"])\n","y_proba.round(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FThGiclBOHo","outputId":"e070ceb4-ed53-4dbe-a019-32fe48f162dd","executionInfo":{"status":"ok","timestamp":1680003968262,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99, 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.98, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["!pgrep tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AspWanW5KfZP","outputId":"c49930b4-5f67-4120-873a-05ba22a25956","executionInfo":{"status":"ok","timestamp":1680003921549,"user_tz":-480,"elapsed":393,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["12064\n"]}]},{"cell_type":"code","source":["!kill 12064"],"metadata":{"id":"VZonNdWhKhdX","executionInfo":{"status":"ok","timestamp":1680003973244,"user_tz":-480,"elapsed":658,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["As you can see, TF Serving makes it quite simple to deploy new models. Moreover, if you discover that version 2 does not work as well as you expected, then rolling back to version 1 is as simple as removing the `my_mnist_model/0002` directory."],"metadata":{"id":"L6eqGpg-Bwme"}},{"cell_type":"markdown","source":["You can also refer to https://github.com/microsoft/ML-For-Beginners/blob/main/3-Web-App/1-Web-App/README.md or https://github.com/rodrigo-arenas/fast-ml-deploy which use [Flask](https://flask.palletsprojects.com/en/2.1.x/) and [FastAPI](https://fastapi.tiangolo.com/) that may have more flexibility. "],"metadata":{"id":"UgV76GJjDJiZ"}},{"cell_type":"markdown","source":["If you would like to deploy to GCP vertex AI, checkout [here](https://github.com/ageron/handson-ml3/blob/main/19_training_and_deploying_at_scale.ipynb)."],"metadata":{"id":"RElpvr6NCuJY"}},{"cell_type":"markdown","source":["## Deploy a REST API server using BentoML"],"metadata":{"id":"5HnKXdgmhhTv"}},{"cell_type":"markdown","source":["To begin with `BentoML`, you will need to save your trained models with `BentoML` API in its model store (a local directory managed by `BentoML`). The model store is used for managing all your trained models locally as well as accessing them for serving."],"metadata":{"id":"G4rQkFrGDM--"}},{"cell_type":"markdown","source":["### Train a classifier model using the iris dataset"],"metadata":{"id":"xghZJBNqhs0O"}},{"cell_type":"code","source":["# Load training data\n","iris = datasets.load_iris()\n","X, y = iris.data, iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Train the model\n","clf = svm.SVC(gamma='scale')\n","clf.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6RLmbgHho9o","outputId":"8bdc3f4a-5a30-4632-9636-f78e5fee4222","executionInfo":{"status":"ok","timestamp":1680054708908,"user_tz":-480,"elapsed":617,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved: Model(tag=\"iris_clf:ip4lyign2s6ucasc\")\n"]}]},{"cell_type":"code","source":["y_pred = clf.predict(X_test)\n","print(classification_report(y_test,y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TC0bmn6ihxRY","outputId":"995999c5-0bc9-4088-95f4-b14d005c7e16","executionInfo":{"status":"ok","timestamp":1680054712233,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       0.83      0.83      0.83         6\n","           2       0.91      0.91      0.91        11\n","\n","    accuracy                           0.93        30\n","   macro avg       0.91      0.91      0.91        30\n","weighted avg       0.93      0.93      0.93        30\n","\n"]}]},{"cell_type":"markdown","source":["Save the `clf` model with BentoML. We begin by saving a trained model instance to **BentoML’s local model store**. The local model store is used to version your models as well as control which models are packaged with your bento. It is noted that there are a [wide range of models](https://docs.bentoml.org/en/latest/frameworks/index.html#frameworks-page) can be saved via BentoML. \n","\n","> It is possible to use pre-trained models directly with BentoML or import existing trained model files to BentoML. Learn more about it from [Preparing Models](https://docs.bentoml.org/en/latest/concepts/model.html)."],"metadata":{"id":"Q8zYLNH_itMe"}},{"cell_type":"code","source":["# Save model to the BentoML local model store\n","saved_model = bentoml.sklearn.save_model(\"iris_clf\", clf)\n","print(f\"Model saved: {saved_model}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Tr-eMEYimGA","outputId":"89529d09-a01c-4637-915b-b8583f4f78ca","executionInfo":{"status":"ok","timestamp":1680054892157,"user_tz":-480,"elapsed":382,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(tag=\"iris_clf:wewrqnwn2s6ucasc\", path=\"/root/bentoml/models/iris_clf/wewrqnwn2s6ucasc/\")"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Models saved can be accessed via `bentoml models` CLI command:"],"metadata":{"id":"GdbaGBQGjkT3"}},{"cell_type":"code","source":["!bentoml models list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMj0y2KRiwkZ","outputId":"8d21d434-3efb-4488-ae94-3a1e1034e55b","executionInfo":{"status":"ok","timestamp":1680054908745,"user_tz":-480,"elapsed":1785,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m \u001b[0m\u001b[1mTag                      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n"," iris_clf:wewrqnwn2s6ucasc  bentoml.sklearn  5.39 KiB  2023-03-29 01:54:50 \n"," iris_clf:ip4lyign2s6ucasc  bentoml.sklearn  5.39 KiB  2023-03-29 01:51:47 \n"]}]},{"cell_type":"markdown","source":["To verify that the saved model can be loaded correctly:"],"metadata":{"id":"ABLTgSPMjuOG"}},{"cell_type":"code","source":["loaded_model = bentoml.sklearn.load_model(\"iris_clf:latest\")\n","# model = bentoml.sklearn.load_model(\"iris_clf:wewrqnwn2s6ucasc\") #we can instead load specific version of model\n","loaded_model.predict([[5.9, 3.0, 5.1, 1.8]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njBF04-Yjfek","outputId":"007a88ba-b9ba-4c1a-c5f8-423b75d3b911","executionInfo":{"status":"ok","timestamp":1680054993765,"user_tz":-480,"elapsed":360,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["In BentoML, the recommended way of running ML model inference in serving is via `Runner`:"],"metadata":{"id":"VHWgg1aWFQ1f"}},{"cell_type":"code","source":["# Create a Runner instance:\n","iris_clf_runner = bentoml.sklearn.get(\"iris_clf:latest\").to_runner()\n","\n","# Runner#init_local initializes the model in current process, this is meant for development and testing only:\n","iris_clf_runner.init_local()\n","\n","# This should yield the same result as the loaded model:\n","iris_clf_runner.predict.run([[5.9, 3.0, 5.1, 1.8]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JW-VrdvFFXIm","executionInfo":{"status":"ok","timestamp":1680055061498,"user_tz":-480,"elapsed":819,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"29db5e86-08c2-467c-8c00-ab2015906491"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:bentoml._internal.runner.runner:'Runner.init_local' is for debugging and testing only. Make sure to remove it before deploying to production.\n"]},{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["In this example, `bentoml.sklearn.get()` creates a reference to the saved model in the model store, and `to_runner()` creates a `Runner` instance from the model. The `Runner` abstraction gives `BentoServer` more flexibility in terms of how to schedule the inference computation, how to dynamically batch inference calls and better take advantage of all hardware resource available."],"metadata":{"id":"XX9-H0uWHopW"}},{"cell_type":"markdown","source":["### Create a BentoML Service for serving the model"],"metadata":{"id":"UsAvuehvj1zR"}},{"cell_type":"markdown","source":["Services are the core components of BentoML, where the serving logic is defined. With the model saved in the model store, we can define the service by creating a Python file `service.py` with the following contents:"],"metadata":{"id":"g2wgm8sFk5oY"}},{"cell_type":"code","source":["%%writefile service.py\n","import numpy as np\n","import bentoml\n","from bentoml.io import NumpyNdarray\n","\n","# Load the runner for the latest ScikitLearn model we just saved\n","iris_clf_runner = bentoml.sklearn.get(\"iris_clf:latest\").to_runner()\n","\n","# Create the iris_classifier service with the ScikitLearn runner\n","# Multiple runners may be specified if needed in the runners array\n","# When packaged as a bento, the runners here will included\n","svc = bentoml.Service(\"iris_classifier\", runners=[iris_clf_runner])\n","\n","# Create API function with pre- and post- processing logic with your new \"svc\" annotation\n","@svc.api(input=NumpyNdarray(), output=NumpyNdarray())\n","def classify(input_series: np.ndarray) -> np.ndarray:\n","    # Define pre-processing logic\n","    result = iris_clf_runner.predict.run(input_series)\n","    # Define post-processing logic\n","    return result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlhoGXS8jxOA","outputId":"1b74668e-d63c-4eb0-a575-4429523fc68f","executionInfo":{"status":"ok","timestamp":1680055381006,"user_tz":-480,"elapsed":376,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing service.py\n"]}]},{"cell_type":"markdown","source":["In this example, we defined the input and output type to be `numpy.ndarray`. More options, such as `pandas.DataFrame`, `JSON` and `PIL.image` are also supported. The `svc.api` decorator adds a function to the `bentoml.Service` object's APIs list. The input and output parameter takes an IO Descriptor object, which specifies the API function's expected input/output types, and is used for generating HTTP endpoints. Inside the API function, users can define any business logic, feature fetching, and feature transformation code. Model inference calls are made directly through runner objects, that are passed into `bentoml.Service(name=.., runners=[..])` call when creating the service object."],"metadata":{"id":"xz5SAEJulUG_"}},{"cell_type":"markdown","source":["> BentoML Server runs the Service API in an ASGI web serving layer and puts Runners in a separate worker process pool managed by BentoML. **The ASGI web serving layer will expose REST endpoints for inference APIs, such as POST /predict and common infrastructure APIs, such as GET /metrics for monitoring.** You can use other ASGI app like FastAPI or WSGI app like Flask, see [here](https://docs.bentoml.org/en/latest/guides/server.html)."],"metadata":{"id":"BzDoMDYgOLmQ"}},{"cell_type":"markdown","source":["We now have everything we need to serve our first request. Launch the server in debug mode by running the `bentoml serve` command in the current working directory. Using the `--reload` option allows the server to reflect any changes made to the `service.py` module without restarting:"],"metadata":{"id":"i_ZCPRN9lsLY"}},{"cell_type":"code","source":["!nohup bentoml serve ./service.py:svc --reload --port 8050 &"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oLpk4yqoZFH","outputId":"9ff03eb7-15ef-4ede-c9ba-3966049a9189","executionInfo":{"status":"ok","timestamp":1680055472709,"user_tz":-480,"elapsed":369,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}]},{"cell_type":"markdown","source":["We can then send requests to the newly started service with any HTTP client:"],"metadata":{"id":"IbSWqAIPuPGf"}},{"cell_type":"code","source":["requests.post(\n","    \"http://127.0.0.1:8050/classify\",\n","    headers={\"content-type\": \"application/json\"},\n","    data=\"[[5.9, 3, 5.1, 1.8]]\"\n","    ).text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"F-cNwCoXl6u3","outputId":"01034fa3-9b0c-46f7-c688-da520e2d1398","executionInfo":{"status":"ok","timestamp":1680055588751,"user_tz":-480,"elapsed":3,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[2]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["!pgrep bentoml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_T7XLWIzmPlg","outputId":"5a4a181b-f0f9-426c-fa4e-8d1d536794ef","executionInfo":{"status":"ok","timestamp":1680055826657,"user_tz":-480,"elapsed":6,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["7124\n"]}]},{"cell_type":"code","source":["!kill 7124"],"metadata":{"id":"z5jPb8BrqSMT","executionInfo":{"status":"ok","timestamp":1680055832086,"user_tz":-480,"elapsed":525,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["### Build and Deploy Bentos 🍱"],"metadata":{"id":"ldMJBh23vEc_"}},{"cell_type":"markdown","source":["Once we are happy with the service definition, we can build the model and service into a `bento`. Bento is the distribution format for a service. It is a self-contained archive that contains all the source code, model files and dependency specifications required to run the service. Checkout [Building Bentos](https://docs.bentoml.org/en/latest/concepts/bento.html) for more details."],"metadata":{"id":"TZ4o7ucOvF4-"}},{"cell_type":"markdown","source":["To build a Bento, first create a file named `bentofile.yaml` in your project directory:"],"metadata":{"id":"L5qUMltdvcBu"}},{"cell_type":"code","source":["%%writefile bentofile.yaml\n","service: \"service.py:svc\"  # A convention for locating your service: <YOUR_SERVICE_PY>:<YOUR_SERVICE_ANNOTATION>\n","description: \"file: ./README.md\"\n","labels:\n","    owner: nsysu-math608\n","    stage: demo\n","include:\n"," - \"*.py\"  # A pattern for matching which files to include in the bento\n","python:\n","  packages:\n","   - scikit-learn  # Additional libraries to be included in the bento\n","   - pandas\n","  lock_packages: False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l0sEOEowu4w0","outputId":"cc3cbfd2-701e-4331-b0ba-3e316f1a0784","executionInfo":{"status":"ok","timestamp":1680056474402,"user_tz":-480,"elapsed":369,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting bentofile.yaml\n"]}]},{"cell_type":"code","source":["%%writefile README.md\n","This is a iris classifier build in math608"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vj5BPdZPv06u","outputId":"c920c546-0990-403e-b0d7-6aff73673a43","executionInfo":{"status":"ok","timestamp":1680056474912,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting README.md\n"]}]},{"cell_type":"markdown","source":["Next, use the bentoml build CLI command in the same directory to build a bento."],"metadata":{"id":"oq-lbzYhvgI3"}},{"cell_type":"code","source":["!bentoml build"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAA9xJnAvYa_","outputId":"1d31532d-345f-4dbf-a03f-34f22215fbda","executionInfo":{"status":"ok","timestamp":1680056477050,"user_tz":-480,"elapsed":1117,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Building BentoML service \"iris_classifier:mgpj7bgn3c4jyasc\" from build context \"/content\".\n","Packing model \"iris_clf:wewrqnwn2s6ucasc\"\n","\n","██████╗░███████╗███╗░░██╗████████╗░█████╗░███╗░░░███╗██╗░░░░░\n","██╔══██╗██╔════╝████╗░██║╚══██╔══╝██╔══██╗████╗░████║██║░░░░░\n","██████╦╝█████╗░░██╔██╗██║░░░██║░░░██║░░██║██╔████╔██║██║░░░░░\n","██╔══██╗██╔══╝░░██║╚████║░░░██║░░░██║░░██║██║╚██╔╝██║██║░░░░░\n","██████╦╝███████╗██║░╚███║░░░██║░░░╚█████╔╝██║░╚═╝░██║███████╗\n","╚═════╝░╚══════╝╚═╝░░╚══╝░░░╚═╝░░░░╚════╝░╚═╝░░░░░╚═╝╚══════╝\n","\n","\u001b[32mSuccessfully built Bento(tag=\"iris_classifier:mgpj7bgn3c4jyasc\").\u001b[0m\n","\u001b[33m\n","Possible next steps:\n","\n"," * Containerize your Bento with `bentoml containerize`:\n","    $ bentoml containerize iris_classifier:mgpj7bgn3c4jyasc\u001b[0m\n","\u001b[33m\n"," * Push to BentoCloud with `bentoml push`:\n","    $ bentoml push iris_classifier:mgpj7bgn3c4jyasc\u001b[0m\n"]}]},{"cell_type":"markdown","source":["Bentos built will be saved in the local bento store, which you can view using the `bentoml list` CLI command."],"metadata":{"id":"4zwY6y2xwDdf"}},{"cell_type":"code","source":["!bentoml list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yIlQ2J8qvnD5","outputId":"8282b8b4-a799-48c0-fec1-31678a4e285b","executionInfo":{"status":"ok","timestamp":1680056506682,"user_tz":-480,"elapsed":1641,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m \u001b[0m\u001b[1mTag                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mPath                  \u001b[0m\u001b[1m \u001b[0m\n"," iris_classifier:mgpj7…  18.38 KiB  2023-03-29 02:21:15  ~/bentoml/bentos/iris… \n"," iris_classifier:7bb5l…  18.38 KiB  2023-03-29 02:18:19  ~/bentoml/bentos/iris… \n"," iris_classifier:m56it…  18.38 KiB  2023-03-29 02:14:16  ~/bentoml/bentos/iris… \n"]}]},{"cell_type":"markdown","source":["We can serve bentos from the bento store using the `bentoml serve` `--production` CLI command. Using the `--production` option will serve the bento in production mode."],"metadata":{"id":"lTmUPXn7wPFu"}},{"cell_type":"code","source":["%%bash --bg\n","nohup bentoml serve iris_classifier:latest \\\n","     --production \\\n","     --port 8050 > bentoml.log 2>&1"],"metadata":{"id":"_IlkMx2Is1ap","executionInfo":{"status":"ok","timestamp":1680056604113,"user_tz":-480,"elapsed":350,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["This is another way to query the server"],"metadata":{"id":"fv4Ai48uwu9u"}},{"cell_type":"code","source":["!curl \\\n","  -X POST \\\n","  -H \"content-type: application/json\" \\\n","  --data \"[[5.9,3,5.1,1.8]]\" \\\n","  http://127.0.0.1:8050/classify"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KgAcBHm3wbDI","outputId":"34b8ea7f-398f-4e2a-9079-1c140030c5b0","executionInfo":{"status":"ok","timestamp":1680056629885,"user_tz":-480,"elapsed":5,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[2]"]}]},{"cell_type":"markdown","source":["The Bento directory contains all code, files, models and configs required for running this service. BentoML standarlizes this file structure which enables serving runtimes and deployment tools to be built on top of it. By default, Bentos are managed under the ~/bentoml/bentos directory:"],"metadata":{"id":"PbXF0hyfw_og"}},{"cell_type":"code","source":["path =\"/root/bentoml/bentos/iris_classifier/\""],"metadata":{"id":"3agYCiqHwqhI","executionInfo":{"status":"ok","timestamp":1680056719126,"user_tz":-480,"elapsed":539,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["for root, dirs, files in os.walk(path):\n","    indent = ' ' * root.count(os.sep)\n","    print('{}{}/'.format(indent, os.path.basename(root)))\n","    for filename in files:\n","        print('{}{}'.format(indent + ' ', filename))"],"metadata":{"id":"tUKsg5nM0OsH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"295a0d41-8e47-48d1-9b5b-6655996d207d","executionInfo":{"status":"ok","timestamp":1680056720600,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["     /\n","      latest\n","     7bb5lgwn26xiyasc/\n","      README.md\n","      bento.yaml\n","      models/\n","       iris_clf/\n","        latest\n","        wewrqnwn2s6ucasc/\n","         model.yaml\n","         saved_model.pkl\n","      apis/\n","       openapi.yaml\n","      env/\n","       docker/\n","        entrypoint.sh\n","        Dockerfile\n","       python/\n","        version.txt\n","        install.sh\n","        requirements.txt\n","      src/\n","       service.py\n","     mgpj7bgn3c4jyasc/\n","      README.md\n","      bento.yaml\n","      models/\n","       iris_clf/\n","        latest\n","        wewrqnwn2s6ucasc/\n","         model.yaml\n","         saved_model.pkl\n","      apis/\n","       openapi.yaml\n","      env/\n","       docker/\n","        entrypoint.sh\n","        Dockerfile\n","       python/\n","        version.txt\n","        install.sh\n","        requirements.txt\n","      src/\n","       service.py\n","       __pycache__/\n","        service.cpython-39.pyc\n","     m56it3wn26e2gasc/\n","      README.md\n","      bento.yaml\n","      models/\n","       iris_clf/\n","        latest\n","        wewrqnwn2s6ucasc/\n","         model.yaml\n","         saved_model.pkl\n","      apis/\n","       openapi.yaml\n","      env/\n","       docker/\n","        entrypoint.sh\n","        Dockerfile\n","       python/\n","        version.txt\n","        install.sh\n","        requirements.txt\n","      src/\n","       service.py\n"]}]},{"cell_type":"code","source":["!pgrep bentoml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ke_qrRHQzj0n","outputId":"fd5fe03e-f0f9-44db-8b86-cfffba0f6fdd","executionInfo":{"status":"ok","timestamp":1680056729529,"user_tz":-480,"elapsed":539,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["12003\n"]}]},{"cell_type":"code","source":["!kill 12003"],"metadata":{"id":"hNslyi-QzkxH","executionInfo":{"status":"ok","timestamp":1680056735634,"user_tz":-480,"elapsed":648,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["For more information, please refer to https://docs.bentoml.org/en/latest/index.html"],"metadata":{"id":"Bw_A1VnIyReH"}},{"cell_type":"markdown","source":["## Deploy web base application using streamit"],"metadata":{"id":"SB48ta6AGzYI"}},{"cell_type":"markdown","source":["Streamlit's simple and focused API lets you build incredibly rich and powerful tools. It contains a large number of [elements](https://docs.streamlit.io/library/api-reference) and [components](https://streamlit.io/components) that you can use.\n","\n","There are a few ways to display data (tables, arrays, data frames) in Streamlit apps. Below, [`st.write()`](https://docs.streamlit.io/library/api-reference/write-magic/magic) can be used to write anything from text, plots to tables. In addition, when you've got the data or model into the state that you want to explore, you can add in widgets like `st.slider()`, `st.button()` or `st.selectbox()`. Finally, Streamlit makes it easy to organize your widgets in a left panel sidebar with `st.sidebar`. Each element that's passed to `st.sidebar` is pinned to the left, allowing users to focus on the content in your app while still having access to UI controls. For example, if you want to add a selectbox and a slider to a sidebar, use `st.sidebar.slider` and `st.sidebar.selectbox` instead of `st.slider` and `st.selectbox`:"],"metadata":{"id":"3BN-1OnBuWpa"}},{"cell_type":"code","source":["%%writefile iris-app.py\n","import streamlit as st\n","import pandas as pd\n","from sklearn import datasets\n","from sklearn.ensemble import RandomForestClassifier\n","\n","st.write(\"\"\"\n","# Simple Iris Flower Prediction App\n","\n","This app predicts the **Iris flower** type!\n","\"\"\")\n","\n","st.sidebar.header('User Input Parameters')\n","\n","def user_input_features():\n","    sepal_length = st.sidebar.slider('Sepal length', 4.3, 7.9, 5.4)\n","    sepal_width = st.sidebar.slider('Sepal width', 2.0, 4.4, 3.4)\n","    petal_length = st.sidebar.slider('Petal length', 1.0, 6.9, 1.3)\n","    petal_width = st.sidebar.slider('Petal width', 0.1, 2.5, 0.2)\n","    data = {'sepal_length': sepal_length,\n","            'sepal_width': sepal_width,\n","            'petal_length': petal_length,\n","            'petal_width': petal_width}\n","    features = pd.DataFrame(data, index=[0])\n","    return features\n","\n","df = user_input_features()\n","\n","st.subheader('User Input parameters')\n","st.write(df)\n","\n","iris = datasets.load_iris()\n","X = iris.data\n","Y = iris.target\n","\n","clf = RandomForestClassifier()\n","clf.fit(X, Y)\n","\n","prediction = clf.predict(df)\n","prediction_proba = clf.predict_proba(df)\n","\n","st.subheader('Class labels and their corresponding index number')\n","st.write(iris.target_names)\n","\n","st.subheader('Prediction')\n","st.write(iris.target_names[prediction])\n","\n","st.subheader('Prediction Probability')\n","st.write(prediction_proba)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5WOyr1cQcXN","executionInfo":{"status":"ok","timestamp":1680057989180,"user_tz":-480,"elapsed":536,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"4543fda9-69bc-4c3b-c53f-789615eccc2d"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing iris-app.py\n"]}]},{"cell_type":"code","source":["%%bash --bg \n","streamlit run iris-ml-app.py --server.port 8050 > debug.log 2>&1"],"metadata":{"id":"gLBRsyy0G6Uo","executionInfo":{"status":"ok","timestamp":1680057995948,"user_tz":-480,"elapsed":428,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["As soon as you run the script as shown above, a local Streamlit server will spin up and your app will open in a new tab in your default web browser. The app is your canvas, where you'll draw charts, text, widgets, tables, and more."],"metadata":{"id":"gbbZ3vTORYZ5"}},{"cell_type":"code","source":["!tail debug.log"],"metadata":{"id":"FFZL2c_5Kaso","executionInfo":{"status":"ok","timestamp":1680057996538,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["public_url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJuBFXjdtkJA","outputId":"b7e947bd-c4f1-44a7-d765-a0c9b5693dfa","executionInfo":{"status":"ok","timestamp":1680057997587,"user_tz":-480,"elapsed":1,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"http://faf8-34-147-81-41.ngrok.io\" -> \"http://localhost:8050\">"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["Try to click the above link to access the web app. For more information, please refer to https://github.com/streamlit/streamlit"],"metadata":{"id":"-JN1a3SutjUI"}},{"cell_type":"code","source":["!pgrep streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhJbvI0_t-Hx","outputId":"3985ef72-00cd-4834-d0ac-5ba334e5020b","executionInfo":{"status":"ok","timestamp":1680058609786,"user_tz":-480,"elapsed":768,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["16598\n"]}]},{"cell_type":"code","source":["!kill 16598"],"metadata":{"id":"R-6Fhs4auDgR","executionInfo":{"status":"ok","timestamp":1680058615782,"user_tz":-480,"elapsed":359,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["## Deploy web base application using Gradio"],"metadata":{"id":"mJsFDLpWQ7HK"}},{"cell_type":"markdown","source":["UI models are perfect to use with Gradio's image input component, so in this section we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like this."],"metadata":{"id":"mg_eEi4luu9R"}},{"cell_type":"markdown","source":["### Setting up the Image Classification Model"],"metadata":{"id":"zXerdxtzxKOB"}},{"cell_type":"markdown","source":["First, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from Keras. You can use a different pretrained model or train your own."],"metadata":{"id":"X6jU4ZkUxNJB"}},{"cell_type":"code","source":["!wget https://hf.space/embed/abidlabs/keras-image-classifier/file/banana.jpg\n","!wget https://hf.space/embed/abidlabs/keras-image-classifier/file/car.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00anQWulwYlR","outputId":"f5e62a95-aa26-4b8e-df57-f992257b9f7a","executionInfo":{"status":"ok","timestamp":1680058641216,"user_tz":-480,"elapsed":2179,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-29 02:57:18--  https://hf.space/embed/abidlabs/keras-image-classifier/file/banana.jpg\n","Resolving hf.space (hf.space)... 54.81.27.42, 54.81.158.24, 54.91.138.213, ...\n","Connecting to hf.space (hf.space)|54.81.27.42|:443... connected.\n","HTTP request sent, awaiting response... 307 Temporary Redirect\n","Location: https://abidlabs-keras-image-classifier.hf.space/file/banana.jpg [following]\n","--2023-03-29 02:57:18--  https://abidlabs-keras-image-classifier.hf.space/file/banana.jpg\n","Resolving abidlabs-keras-image-classifier.hf.space (abidlabs-keras-image-classifier.hf.space)... 18.211.254.225, 54.156.168.251, 34.195.4.197\n","Connecting to abidlabs-keras-image-classifier.hf.space (abidlabs-keras-image-classifier.hf.space)|18.211.254.225|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28437 (28K) [image/jpeg]\n","Saving to: ‘banana.jpg’\n","\n","banana.jpg          100%[===================>]  27.77K  --.-KB/s    in 0.08s   \n","\n","2023-03-29 02:57:19 (327 KB/s) - ‘banana.jpg’ saved [28437/28437]\n","\n","--2023-03-29 02:57:19--  https://hf.space/embed/abidlabs/keras-image-classifier/file/car.jpg\n","Resolving hf.space (hf.space)... 54.81.27.42, 54.81.158.24, 54.91.138.213, ...\n","Connecting to hf.space (hf.space)|54.81.27.42|:443... connected.\n","HTTP request sent, awaiting response... 307 Temporary Redirect\n","Location: https://abidlabs-keras-image-classifier.hf.space/file/car.jpg [following]\n","--2023-03-29 02:57:19--  https://abidlabs-keras-image-classifier.hf.space/file/car.jpg\n","Resolving abidlabs-keras-image-classifier.hf.space (abidlabs-keras-image-classifier.hf.space)... 18.211.254.225, 54.156.168.251, 34.195.4.197\n","Connecting to abidlabs-keras-image-classifier.hf.space (abidlabs-keras-image-classifier.hf.space)|18.211.254.225|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 79626 (78K) [image/jpeg]\n","Saving to: ‘car.jpg’\n","\n","car.jpg             100%[===================>]  77.76K   454KB/s    in 0.2s    \n","\n","2023-03-29 02:57:20 (454 KB/s) - ‘car.jpg’ saved [79626/79626]\n","\n"]}]},{"cell_type":"code","source":["inception_net = tf.keras.applications.MobileNetV2()"],"metadata":{"id":"EI-LD2DUORgC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23ceaacf-e5c2-41f3-d4d6-81d41b60fd76","executionInfo":{"status":"ok","timestamp":1680058649518,"user_tz":-480,"elapsed":5642,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n","14536120/14536120 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"markdown","source":["### Defining a predict function"],"metadata":{"id":"MYWY_7oExPd5"}},{"cell_type":"markdown","source":["Next, we will need to define a function that takes in the user input, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from [this text file](https://raw.githubusercontent.com/gradio-app/mobilenet-example/master/labels.txt).\n","\n","In the case of our pretrained model, it will look like this:"],"metadata":{"id":"yVHc0kSuxQuC"}},{"cell_type":"code","source":["# Download human-readable labels for ImageNet.\n","response = requests.get(\"https://git.io/JJkYN\")\n","labels = response.text.split(\"\\n\")\n","\n","def classify_image(inp):\n","    inp = inp.reshape((-1, 224, 224, 3))\n","    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n","    prediction = inception_net.predict(inp).flatten()\n","    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n","    return confidences"],"metadata":{"id":"RO2OSENMvSkR","executionInfo":{"status":"ok","timestamp":1680058834641,"user_tz":-480,"elapsed":639,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["Let's break this down. The function takes one parameter:\n","* `inp`: the input image as a NumPy array\n","\n","Then, the function adds a batch dimension, passes it through the model, and returns:\n","* `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities"],"metadata":{"id":"gGFmr0vMxbX6"}},{"cell_type":"markdown","source":["### Creating a Gradio Interface"],"metadata":{"id":"qDONv9Gkxjnh"}},{"cell_type":"markdown","source":["Now that we have our predictive function set up, we can create a Gradio Interface around it. In this case, the input component is a drag-and-drop image component. To create this input, we can use the `gradio.inputs.Image` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n","\n","The output component will be a \"label\", which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n","\n","Finally, we'll add one more parameter, the examples, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:"],"metadata":{"id":"nsem8PFexno5"}},{"cell_type":"code","source":["gr.Interface(fn=classify_image, \n","             inputs=gr.Image(shape=(224, 224), label=\"Input image\"),\n","             outputs=gr.Label(num_top_classes=3, label=\"Predition Probabilities\"),\n","             examples=[\"banana.jpg\", \"car.jpg\"],\n","             description=\"Please upload an image\",\n","             title=\"Classification using MobileNet\",\n","             ).launch(server_port=8050)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"ikag2HB1vWWJ","outputId":"11a98fd0-192f-4f82-c442-027072e8c20e","executionInfo":{"status":"ok","timestamp":1680059245665,"user_tz":-480,"elapsed":882,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(8050, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["Gradio automatically produces sharable links with others, but you can also access the web app with our port as follows:"],"metadata":{"id":"3vtNvjJ4x1Ny"}},{"cell_type":"code","source":["public_url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XddIL9oaxFGC","outputId":"2ba4fa96-13f3-401a-a64b-fdc9c6bd5e32","executionInfo":{"status":"ok","timestamp":1680059204595,"user_tz":-480,"elapsed":409,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"http://faf8-34-147-81-41.ngrok.io\" -> \"http://localhost:8050\">"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["gr.close_all()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8iwl5dDmVUMq","executionInfo":{"status":"ok","timestamp":1680059240285,"user_tz":-480,"elapsed":391,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"c39b5cce-dbf4-46bc-b6a0-c31f501c08ea"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Closing server running on port: 8050\n"]}]},{"cell_type":"markdown","source":["For more information, please refer to https://github.com/gradio-app/gradio"],"metadata":{"id":"6OJN8KHSyFsR"}},{"cell_type":"markdown","source":["## Deploy web base applocation using Tensorflow.js"],"metadata":{"id":"Ra51x79aRCfQ"}},{"cell_type":"markdown","source":["Tensorflow.js is a WebGL accelerated JavaScript library for training and deploying ML models. The TensorFlow.js project includes a `tensorflowjs_converter` tool that can convert a TensorFlow `SavedModel` or a Keras model file to the TensorFlow.js Layers format: this is a directory\n","containing a set of sharded weight files in binary format and a model.json file that describes the model’s architecture and links to the weight files. This format is optimized to be downloaded efficiently on the web.\n","\n","Users can then download the model and run predictions in the browser using the TensorFlow.js library. Here is a code snippet to give you an idea of what the JavaScript API looks like:\n","\n","\n","```\n","import * as tf from '@tensorflow/tfjs';\n","const model = await tf.loadLayersModel('https://example.com/tfjs/model.json');\n","const image = tf.fromPixels(webcamElement);\n","const prediction = model.predict(image);\n","```"],"metadata":{"id":"Htbhi0Iey96K"}},{"cell_type":"markdown","source":["For more information, please refer to https://github.com/tensorflow/tfjs."],"metadata":{"id":"01GAbm5jyifw"}},{"cell_type":"markdown","source":["## Deploy mobile applocation using Tensorflow Lite"],"metadata":{"id":"VRiSAp-DRHg6"}},{"cell_type":"markdown","source":["Once again, doing justice to this topic would require a whole book. If you want to learn more about TensorFlow Lite, check out the O’Reilly book [Practical Deep Learning for Cloud, Mobile, and Edge](https://www.oreilly.com/library/view/practical-deep-learning/9781492034858/) or refer to https://www.tensorflow.org/lite."],"metadata":{"id":"55tvq75Zzdmi"}},{"cell_type":"markdown","source":["## Monitoring shift with evidently"],"metadata":{"id":"VW_L5gzOQ-8Z"}},{"cell_type":"markdown","source":["### The task at hand: bike demand forecasting"],"metadata":{"id":"eVVQCG8F2sg6"}},{"cell_type":"markdown","source":["We took a Kaggle dataset on [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand/data). Our goal is to predict the volume of bike rentals on an hourly basis. To do that, we have some data about the season, weather, and day of the week."],"metadata":{"id":"tdeMSRUU2wpx"}},{"cell_type":"code","source":["content = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\").content\n","with zipfile.ZipFile(io.BytesIO(content)) as arc:\n","    raw_data = pd.read_csv(arc.open(\"hour.csv\"), header=0, sep=',', parse_dates=['dteday'], index_col='dteday')"],"metadata":{"id":"1qTX9Ty1RA88","executionInfo":{"status":"ok","timestamp":1680059913165,"user_tz":-480,"elapsed":1656,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["raw_data.index = raw_data.apply(\n","    lambda row: datetime.combine(row.name, time(hour=int(row['hr']))), axis = 1)\n","raw_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"lNPui-BH2_i3","outputId":"3657c468-a067-4948-9259-21d942879960","executionInfo":{"status":"ok","timestamp":1680059915186,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     instant  season  yr  mnth  hr  holiday  weekday  \\\n","2011-01-01 00:00:00        1       1   0     1   0        0        6   \n","2011-01-01 01:00:00        2       1   0     1   1        0        6   \n","2011-01-01 02:00:00        3       1   0     1   2        0        6   \n","2011-01-01 03:00:00        4       1   0     1   3        0        6   \n","2011-01-01 04:00:00        5       1   0     1   4        0        6   \n","\n","                     workingday  weathersit  temp   atemp   hum  windspeed  \\\n","2011-01-01 00:00:00           0           1  0.24  0.2879  0.81        0.0   \n","2011-01-01 01:00:00           0           1  0.22  0.2727  0.80        0.0   \n","2011-01-01 02:00:00           0           1  0.22  0.2727  0.80        0.0   \n","2011-01-01 03:00:00           0           1  0.24  0.2879  0.75        0.0   \n","2011-01-01 04:00:00           0           1  0.24  0.2879  0.75        0.0   \n","\n","                     casual  registered  cnt  \n","2011-01-01 00:00:00       3          13   16  \n","2011-01-01 01:00:00       8          32   40  \n","2011-01-01 02:00:00       5          27   32  \n","2011-01-01 03:00:00       3          10   13  \n","2011-01-01 04:00:00       0           1    1  "],"text/html":["\n","  <div id=\"df-c2b0c95d-6500-4a19-a5fc-e4f68cde3393\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2011-01-01 00:00:00</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.81</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 01:00:00</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 02:00:00</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>5</td>\n","      <td>27</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 03:00:00</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 04:00:00</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2b0c95d-6500-4a19-a5fc-e4f68cde3393')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c2b0c95d-6500-4a19-a5fc-e4f68cde3393 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c2b0c95d-6500-4a19-a5fc-e4f68cde3393');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":71}]},{"cell_type":"markdown","source":["### Train a model"],"metadata":{"id":"JanaILJc3COD"}},{"cell_type":"markdown","source":["We trained a random forest model using data for the four weeks from January. Let's imagine that in practice, we just started the data collection, and that was all the data available. The performance of the trained model looked acceptable, so we decided to give it a go.\n","\n","We further assume that we only learn the ground truth (the actual demand) **at the end of each week.** That is a realistic assumption in real-world machine learning. Integrating and updating different data sources is not always straightforward. Even after the actual event has occurred! Maybe the daily usage data is stored locally and is only sent and merged in the database once per week."],"metadata":{"id":"uZHcdMIa3GOS"}},{"cell_type":"markdown","source":["To run it, we prepare our performance data as a Pandas DataFrame. It should include:\n","* **Model application logs**—features that went into the model and corresponding prediction; and\n","* **Ground truth data**—the actual number of bikes rented each hour as our \"target.\""],"metadata":{"id":"VQKN3CCfm1Ln"}},{"cell_type":"markdown","source":["Once we train the model, we can take our training dataset and generated predictions and specify it as the \"Reference\" data. We can select this period directly from the DataFrame since it has datetime as an index:"],"metadata":{"id":"sIjj3KO7ZGg4"}},{"cell_type":"code","source":["reference = raw_data.loc['2011-01-01 00:00:00':'2011-01-28 23:00:00']\n","\n","target = 'cnt'\n","prediction = 'prediction'\n","numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'hr', 'weekday']\n","categorical_features = ['season', 'holiday', 'workingday']"],"metadata":{"id":"9kzjKdUd3M6v","executionInfo":{"status":"ok","timestamp":1680060122924,"user_tz":-480,"elapsed":520,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["reference.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"1XbNrI9XYvYn","executionInfo":{"status":"ok","timestamp":1680060122924,"user_tz":-480,"elapsed":3,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"1d7f0074-28f2-4b5d-93eb-11c405d6ff27"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     instant  season  yr  mnth  hr  holiday  weekday  \\\n","2011-01-01 00:00:00        1       1   0     1   0        0        6   \n","2011-01-01 01:00:00        2       1   0     1   1        0        6   \n","2011-01-01 02:00:00        3       1   0     1   2        0        6   \n","2011-01-01 03:00:00        4       1   0     1   3        0        6   \n","2011-01-01 04:00:00        5       1   0     1   4        0        6   \n","\n","                     workingday  weathersit  temp   atemp   hum  windspeed  \\\n","2011-01-01 00:00:00           0           1  0.24  0.2879  0.81        0.0   \n","2011-01-01 01:00:00           0           1  0.22  0.2727  0.80        0.0   \n","2011-01-01 02:00:00           0           1  0.22  0.2727  0.80        0.0   \n","2011-01-01 03:00:00           0           1  0.24  0.2879  0.75        0.0   \n","2011-01-01 04:00:00           0           1  0.24  0.2879  0.75        0.0   \n","\n","                     casual  registered  cnt  \n","2011-01-01 00:00:00       3          13   16  \n","2011-01-01 01:00:00       8          32   40  \n","2011-01-01 02:00:00       5          27   32  \n","2011-01-01 03:00:00       3          10   13  \n","2011-01-01 04:00:00       0           1    1  "],"text/html":["\n","  <div id=\"df-3a0150bd-d075-4af6-b7c1-da6cf7739ff0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2011-01-01 00:00:00</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.81</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 01:00:00</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 02:00:00</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>5</td>\n","      <td>27</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 03:00:00</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 04:00:00</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a0150bd-d075-4af6-b7c1-da6cf7739ff0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3a0150bd-d075-4af6-b7c1-da6cf7739ff0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3a0150bd-d075-4af6-b7c1-da6cf7739ff0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["reference[numerical_features + categorical_features].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wic2e-nXtX3e","outputId":"b136fc2a-3d14-4f5a-8464-b3ca5cf8bf18","executionInfo":{"status":"ok","timestamp":1680060135599,"user_tz":-480,"elapsed":359,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(618, 9)"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)"],"metadata":{"id":"h27i8bmk3Pgp","executionInfo":{"status":"ok","timestamp":1680060142731,"user_tz":-480,"elapsed":550,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["regressor.fit(reference[numerical_features + categorical_features], reference[target])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"4Oroixuy3RNg","outputId":"b3fa9f79-bf78-418e-ad32-eb9378239053","executionInfo":{"status":"ok","timestamp":1680060150564,"user_tz":-480,"elapsed":393,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor(n_estimators=50, random_state=0)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, random_state=0)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["ref_prediction = regressor.predict(reference[numerical_features + categorical_features])"],"metadata":{"id":"caX_rP9i3Z9A","executionInfo":{"status":"ok","timestamp":1680060179698,"user_tz":-480,"elapsed":945,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["reference['prediction'] = ref_prediction"],"metadata":{"id":"2GEMgW4_mFKX","executionInfo":{"status":"ok","timestamp":1680060179699,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":["We also map the columns to show Evidently what each column contains and perform a correct analysis:"],"metadata":{"id":"1l5XKuVunKPJ"}},{"cell_type":"code","source":["column_mapping = ColumnMapping()\n","\n","column_mapping.target = target\n","column_mapping.prediction = prediction\n","column_mapping.numerical_features = numerical_features\n","column_mapping.categorical_features = categorical_features"],"metadata":{"id":"Y1m9tO5imGp5","executionInfo":{"status":"ok","timestamp":1680060378344,"user_tz":-480,"elapsed":423,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":["By default, Evidently uses the index as an x-axis in plots. In this case, it is datetime, so we do not need to add anything else explicitly. Otherwise, we would have to specify it in our column mapping."],"metadata":{"id":"AvQliK72ZcTw"}},{"cell_type":"markdown","source":["Next, we call a corresponding report for regression models."],"metadata":{"id":"L00A7MrPnwoF"}},{"cell_type":"code","source":["regression_perfomance = Report(metrics=[RegressionPreset()])\n","regression_perfomance.run(current_data=reference, reference_data=None, column_mapping=column_mapping)"],"metadata":{"id":"6L4hN2avmJxv","executionInfo":{"status":"ok","timestamp":1680060381560,"user_tz":-480,"elapsed":539,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["# You can also specify the metrics see https://docs.evidentlyai.com/reference/all-metrics\n","#the_report = Report(metrics=[\n","#    RegressionQualityMetric(),\n","#    RegressionErrorPlot(),\n","#    RegressionErrorDistribution(),\n","#    DataDriftPreset(stattest=anderson_stat_test, stattest_threshold=0.9),\n","#])"],"metadata":{"id":"OVx_ym6slJiF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And display the results right in the Jupyter notebook."],"metadata":{"id":"0KpXFbben4nH"}},{"cell_type":"code","source":["regression_perfomance.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SI_s7ISPTjAeT4GyFtDTcLb_38J6fRG2"},"id":"025_Z2s7nzSR","outputId":"bfd74437-e904-4e0d-f348-38d9f4edd38d","executionInfo":{"status":"ok","timestamp":1680060410203,"user_tz":-480,"elapsed":7864,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":83,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["We also save it as a .html file to be able to share it easily."],"metadata":{"id":"hqrrGQ19n-YR"}},{"cell_type":"code","source":["!mkdir reports\n","regression_perfomance.save_html('reports/regression_performance_at_training.html')"],"metadata":{"id":"UlLhOT-bn5lk","executionInfo":{"status":"ok","timestamp":1680060523342,"user_tz":-480,"elapsed":1647,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":["We can see that the model has a fine quality given that we only trained on four weeks of data! The error is symmetric and distributed around zero. There is no obvious under- or over-estimation."],"metadata":{"id":"PoWgZ4pTpkyB"}},{"cell_type":"markdown","source":["**We will continue treating this dataset from model performance in training as our \"reference.\"** It gives us a good feel of the quality we can expect from our model in production use. So, we can contrast the future performance against this benchmark."],"metadata":{"id":"nE4AEQjDptqg"}},{"cell_type":"markdown","source":["### The first week in production"],"metadata":{"id":"A0bri5iupxKw"}},{"cell_type":"markdown","source":["Observing the model in production has straightforward goals. We want to detect if something goes wrong. Ideally, in advance. We also want to diagnose the root cause and get a quick understanding of how to address it. Maybe, the model degrades too fast, and we need to retrain it more often? Perhaps, the error is too high, and we need to adapt the model and rebuild it? Which new patterns are emerging?"],"metadata":{"id":"VLyYWGkGp5Qf"}},{"cell_type":"markdown","source":["**In our case, we simply start by checking how well the model performs outside the training data.** Our first week becomes what would have otherwise been a holdout dataset."],"metadata":{"id":"BsMCe5LtqCA_"}},{"cell_type":"markdown","source":["For demonstration purposes, we generated all predictions for several weeks ahead in a single batch. In reality, we would run the model sequentially as the data comes in."],"metadata":{"id":"dQxmp_hcqcGO"}},{"cell_type":"markdown","source":["Let's start by comparing the performance in the first week to what we have seen in training. The first 28 days are our Reference dataset; the next 7 are the Production."],"metadata":{"id":"QJZfR_1nqN9v"}},{"cell_type":"code","source":["current = raw_data.loc['2011-01-29 00:00:00':'2011-02-28 23:00:00']\n","current_prediction = regressor.predict(current[numerical_features + categorical_features])\n","current['prediction'] = current_prediction"],"metadata":{"id":"IUHnh0T4bEtd","executionInfo":{"status":"ok","timestamp":1680060784336,"user_tz":-480,"elapsed":689,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["regression_perfomance = Report(metrics=[RegressionPreset()])\n","regression_perfomance.run(current_data=current.loc['2011-01-29 00:00:00':'2011-02-07 23:00:00'], \n","                          reference_data=reference,\n","                          column_mapping=column_mapping)\n","\n","regression_perfomance.show()"],"metadata":{"id":"VBj1VwxhqXCv","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1YNiSwDRQ_g7cX2Gp0I593Yo8gioBt5kx"},"executionInfo":{"status":"ok","timestamp":1680060792548,"user_tz":-480,"elapsed":5130,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"84ee6040-8066-4d9c-e3ba-31d52c81211c"},"execution_count":88,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["The error has slightly increased and is leaning towards underestimation. Let's check if there is any statistical change in our target. To do that, we will generate the Target Drift report."],"metadata":{"id":"qbkfM_41qzyg"}},{"cell_type":"code","source":["target_drift = Report(metrics=[TargetDriftPreset()])\n","target_drift.run(current_data=current.loc['2011-01-29 00:00:00':'2011-02-07 23:00:00'],\n","                 reference_data=reference,\n","                 column_mapping=column_mapping)\n","\n","target_drift.show()"],"metadata":{"id":"wVXKswZzqkHG","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ghmNaviGMAS0P9bE7obqMkWYG402ECUX"},"executionInfo":{"status":"ok","timestamp":1680060952144,"user_tz":-480,"elapsed":4477,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"ef5a800a-3fc1-4b00-9037-0d08de3d1bc8"},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["We can see that the distribution of the actual number of bikes rented remains sufficiently similar. To be more precise, the similarity hypothesis is not rejected. No drift is detected. The distributions of our predictions did not change much either.\n","\n","Despite this, a rational decision is to update your model by including the new week's data. This way, the model can continue to learn, and we can probably improve the error. For the sake of demonstration, we'll stick to see how fast things go really wrong."],"metadata":{"id":"LWS-ySJzvECQ"}},{"cell_type":"markdown","source":["### The second week: failing to keep up"],"metadata":{"id":"4QDm3J2ivVzI"}},{"cell_type":"markdown","source":["Once again, we benchmark our new week against the reference dataset."],"metadata":{"id":"DLzuOsh8vbdB"}},{"cell_type":"code","source":["regression_perfomance = Report(metrics=[RegressionPreset()])\n","regression_perfomance.run(current_data=current.loc['2011-02-07 00:00:00':'2011-02-14 23:00:00'], \n","                          reference_data=reference,\n","                          column_mapping=column_mapping)\n","\n","regression_perfomance.show()"],"metadata":{"id":"6dEvt5nSq6KS","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1AfuHwEnufBfLEeFP9eygzQ8wYpysVcRJ"},"executionInfo":{"status":"ok","timestamp":1680061138144,"user_tz":-480,"elapsed":7347,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"26f57a3e-58b6-40be-bfc4-2a9a6f6fa8b4"},"execution_count":90,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["At first glance, the model performance in the second week does not differ much. MAE remains almost the same. But, the skew towards under-estimation continues to grow. It seems that the error is not random! To know more, we move to the plots. We can see that the model catches overall daily trends just fine. So it learned something useful! **But, at peak hours, the actual demand tends to be higher than predicted.**\n","\n","In the error distribution plot, we can see how it became \"wider,\" as we have more predictions with a high error. The shift to the left is visible, too. In some extreme instances, we have errors between 80 and 40 bikes that were unseen previously."],"metadata":{"id":"MolwD2Jmz8ep"}},{"cell_type":"markdown","source":["Let's check our target as well."],"metadata":{"id":"_x9MCofe0lMp"}},{"cell_type":"code","source":["target_drift = Report(metrics=[TargetDriftPreset()])\n","target_drift.run(current_data=current.loc['2011-02-07 00:00:00':'2011-02-14 23:00:00'],\n","                 reference_data=reference,\n","                 column_mapping=column_mapping)\n","\n","target_drift.show()"],"metadata":{"id":"uGXfwnbQvnsP","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1jHkUQ6c_q2kd3dr9ICyKlksxp7s1n_H_"},"executionInfo":{"status":"ok","timestamp":1680061277856,"user_tz":-480,"elapsed":4730,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"3f31667e-3eff-43e5-d7b6-177ef5f0dcc7"},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Things are getting interesting!\n","\n","**We can see that the target distribution is now different: the similarity hypothesis is rejected. Literally, people are renting more bikes. And this is a statistically different change from our training period.**"],"metadata":{"id":"CbOFix3I1Leh"}},{"cell_type":"markdown","source":["But, the distribution of our predictions does not keep up! That is an obvious example of **model decay. Something new happens in the world, but it misses the patterns.**"],"metadata":{"id":"m2fLq7_B1a-C"}},{"cell_type":"markdown","source":["It is tempting to investigate further. Is there anything in the data that can explain this change? If there is some new signal, retraining would likely help the model to keep up. The Target Drift report has a section to help us explore the relationship between the features and the target (or model predictions).\n","‍When browsing through the individual features, we can inspect if we notice any new patterns. We know that predictions did not change, so we only look at the relations with the target. For example, there is a shift towards higher temperatures (measured in Celsius) with a corresponding increase in rented bikes.\n","\n","Maybe, it would pick up these patterns in retraining. But for now, we simply move on to the next week without any updates."],"metadata":{"id":"wXe-5sUn1yWJ"}},{"cell_type":"markdown","source":["### Week 3: when things go south"],"metadata":{"id":"RfIqni0-4hBS"}},{"cell_type":"code","source":["regression_perfomance = Report(metrics=[RegressionPreset()])\n","regression_perfomance.run(current_data=current.loc['2011-02-15 00:00:00':'2011-02-21 23:00:00'], \n","                          reference_data=reference,\n","                          column_mapping=column_mapping)\n","\n","regression_perfomance.show()"],"metadata":{"id":"J61Zn7jd1Ope","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"12I6rxV4tPSOC1ulykUQ95MpxdOmAeYrl"},"executionInfo":{"status":"ok","timestamp":1680061501650,"user_tz":-480,"elapsed":6592,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"569c9513-db8c-4a76-f95a-3e8bd156fcd9"},"execution_count":92,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Okay, now things do look bad. On week 3, we face a major quality drop. Both absolute and percentage error grew significantly. If we look at the plots, the model predictions are visibly scattered. We also face a **new data segment with high demand that the model fails to predict.** But even within the known range of target value, the model now makes errors. Things did change since the training. We can see that the model does not extrapolate well. The predicted demand stays within the same known range, while actual values are peaking."],"metadata":{"id":"jLXpBPTX4yFh"}},{"cell_type":"markdown","source":["If we zoom in on specific days, we might suggest that the error is higher on specific (active) hours of the day. We are doing just fine from 10 pm to 6 am!"],"metadata":{"id":"rnehcGDO5MvQ"}},{"cell_type":"markdown","source":["In our example, we particularly want to understand the segment where the model underestimates the target function. The `Error Bias table` gives up more details. We sort it by the `\"Range%\"` field. If the values of a specific feature are significantly different in the group where the model under- or over-estimates, this feature will rank high. **In our case, we can see that the extreme errors are dependent on the \"temp\" (temperature) and \"atemp\" (feels-like temperature) features.**"],"metadata":{"id":"M2WaWSyu5kJ6"}},{"cell_type":"markdown","source":["After this quick analysis, we have a more specific idea about model performance and its weaknesses. The model faces new, unusually high demand. Given how it was trained, it tends to underestimate it. On top of it, these errors are not at all random. At the very least, they are related to the temperature we observe. The higher it is, the larger the underestimation. **It suggests new patterns that are related to the weather that the model could not learn before. Days got warmer, and the model went rogue.**\n","\n","If we run a target drift report, we will also see a relevant change in the linear correlations between the feature and the target. Temperature and humidity stand out."],"metadata":{"id":"mY2qSYOB65dQ"}},{"cell_type":"code","source":["target_drift = Report(metrics=[TargetDriftPreset()])\n","target_drift.run(current_data=current.loc['2011-02-15 00:00:00':'2011-02-21 23:00:00'],\n","                 reference_data=reference,\n","                 column_mapping=column_mapping)\n","\n","target_drift.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"13_S9dqFc56JXuhbbORQT5lixmSEJ2KI-"},"id":"pDEkUgaEiHVg","executionInfo":{"status":"ok","timestamp":1680062583397,"user_tz":-480,"elapsed":5596,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"e4406aad-2bf9-4669-a978-36f25307f02f"},"execution_count":93,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["We should retrain as soon as possible and do this often until we learn all the patterns. If we are not comfortable with frequent retraining, we might choose an algorithm that is more suitable for time series or is better in extrapolation."],"metadata":{"id":"IM8Tmqf07BuO"}},{"cell_type":"markdown","source":["### Data Drift"],"metadata":{"id":"sh-nc7Qp7NKK"}},{"cell_type":"markdown","source":["In practice, once we receive the ground truth, we can indeed course-correct quickly. Had we retrained the model after week one, it would have likely ended less dramatically. **But what if we do not have the ground truth available? Can we catch such decay in advance?**\n","\n","In this case, we can analyze the data drift. We do not need actuals to calculate the error. Instead, our goal is to see if the input data has changed."],"metadata":{"id":"g6WPMeSu7O2K"}},{"cell_type":"markdown","source":["**Once again, let's compare the first week of production to our data in training.** We can, of course, look at all our features. But we can also conclude that categorical features (like \"season,\" \"holiday\" and \"workingday\") are not likely to change. Let's look at numerical features only!\n","\n","We specify these features so that the tool applies the correct statistical test. It would be Kolmogorov-Smirnov in this case."],"metadata":{"id":"Ib0cUpnS7ixR"}},{"cell_type":"code","source":["column_mapping = ColumnMapping()\n","\n","column_mapping.numerical_features = numerical_features"],"metadata":{"id":"Fgg-JXN24rrd","executionInfo":{"status":"ok","timestamp":1680062665101,"user_tz":-480,"elapsed":360,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["data_drift = Report(metrics = [DataDriftPreset()])\n","data_drift.run(current_data = current.loc['2011-01-29 00:00:00':'2011-02-07 23:00:00'],\n","               reference_data = reference,\n","               column_mapping=column_mapping)\n","\n","data_drift.show()"],"metadata":{"id":"qDk5S6e-8Q8-","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15NOzWvzYacrjojsvzwp58R8nv6EOKpTU"},"executionInfo":{"status":"ok","timestamp":1680062670153,"user_tz":-480,"elapsed":3360,"user":{"displayName":"phonchi chung","userId":"13517391734500420886"}},"outputId":"2db54d12-eddf-498f-b571-4536e8935c06"},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["> The data drift report compares the distributions of each feature in the two datasets. It [automatically picks an appropriate statistical test](https://docs.evidentlyai.com/reference/data-drift-algorithm) or metric based on the feature type and volume. It then returns p-values or distances and visually plots the distributions. You can also adjust the drift detection method or thresholds, or pass your own."],"metadata":{"id":"HICuul0BmSTT"}},{"cell_type":"markdown","source":["Once we show the report, it returns an answer. We can see already during the first week there is a statistical change in feature distributions.\n","\n","Let's zoom in on our usual suspect—temperature. The report gives us two views on how the feature distributions evolve with time. We can notice how the observed temperature becomes higher day by day. The values clearly drift out of our green corridor (one standard deviation from the mean) that we saw in training. Looking at the steady growth, we can suspect an upward trend."],"metadata":{"id":"uaLxHzFP8gR6"}},{"cell_type":"markdown","source":["As we checked earlier, we did not detect drift in the model predictions after week one. Given that our model is not good at extrapolating, we should not really expect it. Such prediction drift might still happen and signal about things like broken input data. Otherwise, we would observe it if we had a more sensitive model. Regardless of this, the data drift alone provides excellent early monitoring to detect the change and react to it."],"metadata":{"id":"uBklQ9iN86dz"}},{"cell_type":"markdown","source":["For more information please refer to https://github.com/evidentlyai/evidently, https://github.com/SeldonIO/alibi-detect, https://github.com/great-expectations/great_expectations or https://github.com/whylabs/whylogs"],"metadata":{"id":"0rSXNKI_9QtJ"}},{"cell_type":"markdown","source":["## References"],"metadata":{"id":"AtFEKqSZ6VKw"}},{"cell_type":"markdown","source":["1. https://github.com/ageron/handson-ml2/blob/master/19_training_and_deploying_at_scale.ipynb\n","2. https://github.com/bentoml/BentoML\n","3. https://github.com/streamlit/streamlit\n","4. https://raw.githubusercontent.com/dataprofessor/code/master/streamlit/part2/iris-ml-app.py\n","5. https://gradio.app/image-classification-in-tensorflow/\n","6. https://evidentlyai.com/blog/tutorial-1-model-analytics-in-production"],"metadata":{"id":"y9YBJyOw6XSM"}},{"cell_type":"code","source":[],"metadata":{"id":"MLhDp66e8VfP"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"nav_menu":{},"toc":{"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":6,"toc_cell":false,"toc_section_display":"block","toc_window_display":false},"colab":{"provenance":[],"toc_visible":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}