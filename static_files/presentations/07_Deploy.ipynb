{"cells":[{"cell_type":"markdown","metadata":{"id":"1QiCFLer1FIe"},"source":["**Lab 7 – Deploy**"]},{"cell_type":"markdown","metadata":{"id":"9J5g6PDs1FIk"},"source":["<table align=\"left\">\n","  <td>\n","    <a href=\"https://colab.research.google.com/github/phonchi/nsysu-math608/blob/master/static_files/presentations/07_Deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/phonchi/nsysu-math608/blob/master/static_files/presentations/07_Deploy.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","source":["# 🛠️ Setup"],"metadata":{"id":"cUAyQuKOO-hO"}},{"cell_type":"code","source":["# @title Install packages\n","!pip install bentoml -qq\n","!pip install pyngrok -qq\n","!pip install PyYAML -U -qq\n","!pip install streamlit -qq\n","!pip install gradio -qq\n","!pip install git+https://github.com/evidentlyai/evidently.git -qq"],"metadata":{"id":"8YFCNVkuZ3U4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"87f6eef3-bfde-4b7d-dfd1-2cf78b33282a","executionInfo":{"status":"ok","timestamp":1729320314159,"user_tz":-480,"elapsed":96098,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.6.2.post1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m415.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.6.2.post1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.1/231.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for evidently (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["Notice that **you may need to restart the kernel** after the above installations."],"metadata":{"id":"ORfWcYOulopf"}},{"cell_type":"code","source":["# @title Import packages\n","\n","# Scientific computing\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","from matplotlib import cm\n","%matplotlib inline\n","\n","import warnings\n","# Suppress specific FutureWarning from evidently.utils.visualizations\n","warnings.filterwarnings(\n","    \"ignore\",\n","    category=FutureWarning,\n","    message=\".*'H' is deprecated and will be removed in a future version, please use 'h' instead.*\",\n","    module=\"evidently.utils.visualizations\"\n",")\n","\n","# Suppress FutureWarning from scikit-learn's regression metrics in evidently\n","warnings.filterwarnings(\n","    \"ignore\",\n","    category=FutureWarning,\n","    module=\"sklearn.metrics._regression\",\n","    message=\".*'squared' is deprecated.*\"\n",")\n","\n","# Modeling\n","from sklearn import datasets\n","from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn import ensemble\n","\n","# The latest TensorFlow versions are based on Keras 3\n","# it wasn't too hard to update the code to support Keras 3 for training,\n","# but unfortunately it's much harder for production,\n","# so I've had to revert to Keras 2. To do that, I set the TF_USE_LEGACY_KERAS environment variable\n","# to \"1\" and import the tf_keras package. This ensures that tf.keras points to tf_keras, which is Keras 2.*.\n","import os\n","os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n","import tf_keras\n","import tensorflow as tf\n","\n","# Deploy\n","import joblib\n","import bentoml\n","import gradio as gr\n","\n","\n","# Monitoring\n","from evidently import ColumnMapping\n","from evidently.report import Report\n","from evidently.metric_preset import DataDriftPreset, TargetDriftPreset, RegressionPreset\n","\n","# Helper library\n","from pyngrok import ngrok, conf\n","import getpass\n","\n","# Other system library\n","from pathlib import Path\n","import requests\n","import os\n","import json\n","import sys\n","import zipfile\n","import io\n","from datetime import datetime, time\n","\n","if not tf.config.list_physical_devices('GPU'):\n","    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n","    if \"google.colab\" in sys.modules:\n","        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n","              \"accelerator.\")\n","    if \"kaggle_secrets\" in sys.modules:\n","        print(\"Go to Settings > Accelerator and select GPU.\")"],"metadata":{"id":"5bV_HvPiH-9i","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["📌 The latest TensorFlow versions are based on Keras 3\n"," it wasn't too hard to update the code to support Keras 3 for training,\n"," but unfortunately it's much harder for production,\n"," so I've had to revert to Keras 2. To do that, I set the `TF_USE_LEGACY_KERAS` environment variable to \"1\" and import the `tf_keras` package. This ensures that `tf.keras` points to `tf_keras`, which is Keras 2.*."],"metadata":{"id":"TouRYp3vhKGX"}},{"cell_type":"markdown","source":["Here are some tips for this notebook [https://amitness.com/2020/06/google-colaboratory-tips/](https://amitness.com/2020/06/google-colaboratory-tips/) and [https://stackoverflow.com/questions/59741453/is-there-a-general-way-to-run-web-applications-on-google-colab](https://stackoverflow.com/questions/59741453/is-there-a-general-way-to-run-web-applications-on-google-colab)."],"metadata":{"id":"VCxpUaR0Eot3"}},{"cell_type":"markdown","source":["`ngrok` is a reverse proxy tool that opens secure tunnels from public URLs to localhost, perfect for exposing local web servers, building webhook integrations, enabling SSH access, testing chatbots, demoing from your own machine, and more. In this lab, we will use use [https://pyngrok.readthedocs.io/en/latest/integrations.html](https://pyngrok.readthedocs.io/en/latest/integrations.html). However, for production environment, it is recommended to use cloud service such as AWS, GCP or Azure, see [here](https://towardsdatascience.com/the-hierarchy-of-ml-tooling-on-the-public-cloud-ed387cac3c27) or [https://pycaret.gitbook.io/docs/get-started/functions/deploy#deploy_model](https://pycaret.gitbook.io/docs/get-started/functions/deploy#deploy_model) for more details."],"metadata":{"id":"xyQuXGAscwSG"}},{"cell_type":"code","source":["if \"google.colab\" in sys.modules:\n","    from google.colab import userdata\n","    token = userdata.get('ngrok')\n","    conf.get_default().auth_token = token\n","else:\n","    print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/\")\n","    conf.get_default().auth_token = getpass.getpass()"],"metadata":{"id":"mR37ypzgQtw5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup a tunnel to the port 8050\n","public_url = ngrok.connect(8050)"],"metadata":{"id":"ZX7_8hbYPMyo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["public_url"],"metadata":{"id":"S7fv6CyzPjMj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b465203-b5ba-4d83-ff0b-3ecf3b3d6ed0","executionInfo":{"status":"ok","timestamp":1729324173880,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"https://c680-34-90-244-234.ngrok-free.app\" -> \"http://localhost:8050\">"]},"metadata":{},"execution_count":89}]},{"cell_type":"markdown","source":["# 🔍 Deploying TensorFlow models to TensorFlow Serving (TFS) on remote server"],"metadata":{"id":"crG8mceteV3J"}},{"cell_type":"markdown","source":["You could create your own microservice using any technology you want (e.g., using the `Flask` library), but why reinvent the wheel when you can just use TF Serving?"],"metadata":{"id":"cV8Zc1Bqy91q"}},{"cell_type":"code","source":["tf_keras.__version__, tf.keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llxykshwWHHD","executionInfo":{"status":"ok","timestamp":1728361068179,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"5bafc037-83af-4f02-ba37-287d600d7611"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('2.17.0',\n"," <module 'tf_keras.api._v2.keras' from '/usr/local/lib/python3.10/dist-packages/tf_keras/api/_v2/keras/__init__.py'>)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["> The latest TensorFlow versions are based on Keras 3 it wasn't too hard to update the code to support Keras 3 for training, but unfortunately it's much harder for production, so I've had to revert to Keras 2. To do that, I set the `TF_USE_LEGACY_KERAS` environment variable to \"1\" and import the tf_keras package. This ensures that tf.keras points to tf_keras, which is Keras 2.*."],"metadata":{"id":"Rl7UhMl7WTjK"}},{"cell_type":"markdown","source":["## Exporting `SavedModels`"],"metadata":{"id":"Skjq-RutzUhU"}},{"cell_type":"markdown","source":["TensorFlow provides a simple `tf.keras.models.save_model()` function to export models to the `SavedModel` format. All you need to do is give it the model, specifying its name and version number, and the function will save the model’s computation graph and its weights:"],"metadata":{"id":"xKWJOHQZzX7I"}},{"cell_type":"code","source":["# Load and split the MNIST dataset\n","mnist = tf.keras.datasets.mnist.load_data()\n","(X_train_full, y_train_full), (X_test, y_test) = mnist\n","X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n","y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"],"metadata":{"id":"Ek0vl3M1yKJy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["📌 It’s usually a good idea to i**nclude all the preprocessing layers in the final model** you export so that it can ingest data in its natural form once it is deployed to production. This  avoids  having  to  take  care  of  preprocessing  separately  within  the  application that uses the model. Bundling the preprocessing steps within the model also makes it simpler to update them later on and limits the risk of mismatch between a model and\n","the preprocessing steps it requires!"],"metadata":{"id":"Vj-GEIXH7iPt"}},{"cell_type":"code","source":["# Set seed for reproducibility and clear any existing session\n","tf.random.set_seed(42)\n","tf.keras.backend.clear_session()\n","\n","# Define the model with an explicit Input layer\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=(28, 28), dtype=tf.uint8),  # Explicit Input layer\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Rescaling(scale=1 / 255),\n","    tf.keras.layers.Dense(100, activation=\"relu\"),\n","    tf.keras.layers.Dense(10, activation=\"softmax\")\n","])\n","\n","# Compile the model\n","model.compile(\n","    loss=\"sparse_categorical_crossentropy\",\n","    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Fit the model\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=10,\n","    validation_data=(X_valid, y_valid)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-V7C_DyLzfOK","outputId":"b62058e6-48f6-4e6a-df2f-f457a352d808","executionInfo":{"status":"ok","timestamp":1728360898713,"user_tz":-480,"elapsed":68870,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 9s 4ms/step - loss: 0.6775 - accuracy: 0.8257 - val_loss: 0.3725 - val_accuracy: 0.9010\n","Epoch 2/10\n","1719/1719 [==============================] - 5s 3ms/step - loss: 0.3531 - accuracy: 0.9014 - val_loss: 0.3015 - val_accuracy: 0.9146\n","Epoch 3/10\n","1719/1719 [==============================] - 6s 3ms/step - loss: 0.3032 - accuracy: 0.9143 - val_loss: 0.2656 - val_accuracy: 0.9256\n","Epoch 4/10\n","1719/1719 [==============================] - 10s 6ms/step - loss: 0.2721 - accuracy: 0.9230 - val_loss: 0.2427 - val_accuracy: 0.9342\n","Epoch 5/10\n","1719/1719 [==============================] - 8s 4ms/step - loss: 0.2484 - accuracy: 0.9301 - val_loss: 0.2235 - val_accuracy: 0.9366\n","Epoch 6/10\n","1719/1719 [==============================] - 6s 4ms/step - loss: 0.2293 - accuracy: 0.9359 - val_loss: 0.2087 - val_accuracy: 0.9428\n","Epoch 7/10\n","1719/1719 [==============================] - 6s 3ms/step - loss: 0.2133 - accuracy: 0.9400 - val_loss: 0.1941 - val_accuracy: 0.9462\n","Epoch 8/10\n","1719/1719 [==============================] - 5s 3ms/step - loss: 0.1997 - accuracy: 0.9434 - val_loss: 0.1851 - val_accuracy: 0.9478\n","Epoch 9/10\n","1719/1719 [==============================] - 8s 4ms/step - loss: 0.1879 - accuracy: 0.9469 - val_loss: 0.1751 - val_accuracy: 0.9496\n","Epoch 10/10\n","1719/1719 [==============================] - 6s 3ms/step - loss: 0.1776 - accuracy: 0.9506 - val_loss: 0.1659 - val_accuracy: 0.9534\n"]}]},{"cell_type":"code","source":["X_new = X_test[:3]  # pretend we have 3 new digit images to classify\n","np.round(model.predict(X_new), 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2LJJVPvzwWj","outputId":"6dcea116-cb4e-478d-bbb9-02ae02c07c21","executionInfo":{"status":"ok","timestamp":1728360899191,"user_tz":-480,"elapsed":479,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 106ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n","      dtype=float32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Now to version the model, you just need to create a subdirectory for each model version:"],"metadata":{"id":"1iUUdBrB7tfr"}},{"cell_type":"code","source":["model_name = \"my_mnist_model\"\n","model_version = \"0001\"\n","model_path = Path(model_name) / model_version"],"metadata":{"id":"R7sB3_2rz_KA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.models.save_model(\n","    model,\n","    model_path,\n","    overwrite=True,\n","    include_optimizer=True,\n","    save_format=\"tf\",\n","    signatures=None,\n","    options=None\n",")"],"metadata":{"id":"fGL8NoSU3k3w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A `SavedModel` represents a version of your model. It is stored as a directory containing a `saved_model.pb` file, which defines the computation graph (represented as a **serialized protocol buffer**), and a variables subdirectory\n","containing the variable values. For models containing a large number of weights, these variable values may be split across multiple files. A `SavedModel` also includes an `assets` subdirectory that may contain additional data, such as vocabulary files, class names, or some example instances for this model."],"metadata":{"id":"MTwiLc4_13fw"}},{"cell_type":"code","source":["for root, dirs, files in os.walk(model_name):\n","    indent = '    ' * root.count(os.sep)\n","    print('{}{}/'.format(indent, os.path.basename(root)))\n","    for filename in files:\n","        print('{}{}'.format(indent + '    ', filename))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwjxBrY48VCK","executionInfo":{"status":"ok","timestamp":1728360943681,"user_tz":-480,"elapsed":312,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"87824c09-5013-4f28-e547-df69dff93a70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["my_mnist_model/\n","    0001/\n","        keras_metadata.pb\n","        fingerprint.pb\n","        saved_model.pb\n","        variables/\n","            variables.data-00000-of-00001\n","            variables.index\n","        assets/\n"]}]},{"cell_type":"markdown","source":["As you might expect, you can load a `SavedModel` using the `tf.keras.models.load_model()` function."],"metadata":{"id":"qrn8ac6t1aL1"}},{"cell_type":"code","source":["saved_model = tf.keras.models.load_model(model_path)\n","np.round(saved_model.predict(X_new), 2)"],"metadata":{"id":"wHPPMDzt0MP4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728360946735,"user_tz":-480,"elapsed":822,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"16f37bd0-95e6-4218-c397-f0d8aaa92ace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 47ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n","      dtype=float32)"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["TensorFlow also comes with a small `saved_model_cli` command-line tool to inspect `SavedModels`:"],"metadata":{"id":"wlmN7c9X4deT"}},{"cell_type":"code","source":["!saved_model_cli show --dir {model_path} --all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"550WGkUX4Mhc","outputId":"3df181fe-ff64-46fc-fcb3-b91a3d96dc93","executionInfo":{"status":"ok","timestamp":1728360959578,"user_tz":-480,"elapsed":4638,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-10-08 04:15:54.320875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-08 04:15:54.339146: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-08 04:15:54.344728: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-08 04:15:55.471778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1728360956.902893    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1728360956.958928    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1728360956.959253    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","\n","MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n","\n","signature_def['__saved_model_init_op']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['__saved_model_init_op'] tensor_info:\n","        dtype: DT_INVALID\n","        shape: unknown_rank\n","        name: NoOp\n","  Method name is: \n","\n","signature_def['serving_default']:\n","  The given SavedModel SignatureDef contains the following input(s):\n","    inputs['input_1'] tensor_info:\n","        dtype: DT_UINT8\n","        shape: (-1, 28, 28)\n","        name: serving_default_input_1:0\n","  The given SavedModel SignatureDef contains the following output(s):\n","    outputs['dense_1'] tensor_info:\n","        dtype: DT_FLOAT\n","        shape: (-1, 10)\n","        name: StatefulPartitionedCall:0\n","  Method name is: tensorflow/serving/predict\n","The MetaGraph with tag set ['serve'] contains the following ops: {'StaticRegexFullMatch', 'AddV2', 'Pack', 'Relu', 'StatefulPartitionedCall', 'Const', 'ReadVariableOp', 'SaveV2', 'ShardedFilename', 'MergeV2Checkpoints', 'Reshape', 'Identity', 'Mul', 'Cast', 'AssignVariableOp', 'StringJoin', 'VarHandleOp', 'MatMul', 'Select', 'NoOp', 'Placeholder', 'RestoreV2', 'Softmax', 'DisableCopyOnRead', 'BiasAdd'}\n","\n","Concrete Functions:I0000 00:00:1728360956.995691    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1728360956.995925    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1728360956.996087    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1728360957.073402    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","I0000 00:00:1728360957.073710    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-10-08 04:15:57.073844: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1728360957.073941    9606 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","\n","  Function Name: '__call__'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","\n","  Function Name: '_default_save_signature'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='input_1')\n","\n","  Function Name: 'call_and_return_all_conditional_losses'\n","    Option #1\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: False\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n","    Option #2\n","      Callable with:\n","        Argument #1\n","          input_1: TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name='input_1')\n","        Argument #2\n","          DType: bool\n","          Value: True\n","        Argument #3\n","          DType: NoneType\n","          Value: None\n"]}]},{"cell_type":"markdown","source":["A `SavedModel` contains one or more metagraphs. When you pass a `tf.keras` model, by default the function saves a simple `SavedModel`: it saves a single metagraph tagged \"serve\", which contains two signature definitions, an initialization function (called  `_saved_model_init_op`) and a default serving function (called `serving_default`). When saving a `tf.keras` model, the default serving function corresponds to the model’s `call()` function, which of course makes predictions."],"metadata":{"id":"7lisp5Ox5KPZ"}},{"cell_type":"markdown","source":["## Serve your model with TensorFlow Serving (Server side)"],"metadata":{"id":"y8lzCevs56av"}},{"cell_type":"markdown","source":["There are many ways to install TF Serving: using the system’s package manager, using a Docker image, installing from source, and more. Since Colab/Kaggle runs on Ubuntu, we can use Ubuntu’s  apt  package manager like this:"],"metadata":{"id":"vVhUpbsP6io2"}},{"cell_type":"code","source":["if \"google.colab\" in sys.modules or \"kaggle_secrets\" in sys.modules:\n","    url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n","    src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n","    !echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n","    !curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n","    !apt update -q && apt-get install -y tensorflow-model-server\n","    %pip install -q -U tensorflow-serving-api"],"metadata":{"id":"xANYl8LW4mhv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728361206945,"user_tz":-480,"elapsed":25307,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"582c8813-83a0-4c08-9649-9bdb41877569"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n","\r100  2943  100  2943    0     0  14971      0 --:--:-- --:--:-- --:--:-- 15015\n","OK\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,030 kB]\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:9 https://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n","Get:10 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:13 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [342 B]\n","Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,371 kB]\n","Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:17 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [350 B]\n","Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,590 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,159 kB]\n","Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,318 kB]\n","Fetched 15.9 MB in 3s (5,457 kB/s)\n","Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","54 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mhttps://storage.googleapis.com/tensorflow-serving-apt/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tensorflow-model-server\n","0 upgraded, 1 newly installed, 0 to remove and 54 not upgraded.\n","Need to get 615 MB of archives.\n","After this operation, 0 B of additional disk space will be used.\n","Get:1 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.17.0 [615 MB]\n","Fetched 615 MB in 9s (70.9 MB/s)\n","Selecting previously unselected package tensorflow-model-server.\n","(Reading database ... 123620 files and directories currently installed.)\n","Preparing to unpack .../tensorflow-model-server_2.17.0_all.deb ...\n","Unpacking tensorflow-model-server (2.17.0) ...\n","Setting up tensorflow-model-server (2.17.0) ...\n"]}]},{"cell_type":"markdown","source":["> The  code  above starts  by  adding  TensorFlow's  package  repository  to  Ubuntu's  list  of package  sources.  Then  it  downloads  TensorFlow's  public  GPG  key  and  adds  it  to the  package  manager’s  key  list  so  it  can  verify  TensorFlow's  package  signatures. Next, it uses  apt  to install the  `tensorflow-model-server`  package. Lastly, it installs the  `tensorflow-serving-api`  library, which we will need to communicate with the\n","server."],"metadata":{"id":"Vn3kputH-V5x"}},{"cell_type":"markdown","source":["If `tensorflow_model_server` is installed (e.g., if you are running this notebook in Colab/Kaggle), then the following 2 cells will start the server. If your OS is Windows, you may need to run the `tensorflow_model_server` command in a terminal, and replace `${MODEL_DIR}` with the full path to the `my_mnist_model` directory. This is where we start running TensorFlow Serving and load our model. After it loads we can start making inference requests using REST. There are some important parameters:\n","\n","* `port`: The port that you'll use for gRPC requests.\n","* `rest_api_port`: The port that you'll use for REST requests.\n","* `model_name`: You'll use this in the URL of REST requests. It can be anything.\n","* `model_base_path`: This is the path to the directory where you've saved your model."],"metadata":{"id":"lbp5_Vf39fFu"}},{"cell_type":"code","source":["os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"],"metadata":{"id":"smENzAY76z0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash --bg\n","nohup tensorflow_model_server \\\n","     --port=8500 \\\n","     --rest_api_port=8050 \\\n","     --model_name=my_mnist_model \\\n","     --model_base_path=\"${MODEL_DIR}\" > server.log 2>&1"],"metadata":{"id":"PBGHxWHr7C7n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> The  `%%bash  --bg`   magic  command  executes  the  cell  as  a  bash script,  running  it  in  the  background.  The  `>my_server.log  2>&1`   part  redirects  the standard output and standard error to the `server.log` file. And that’s it! TF Serving is now running in the background, and its logs are saved to `server.log`."],"metadata":{"id":"ri7TQRCb_Z4Z"}},{"cell_type":"code","source":["!tail server.log"],"metadata":{"id":"DAuShYuE7H2P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728361606190,"user_tz":-480,"elapsed":321,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"50fe0cbe-c858-4d22-8dd8-22358d047fbc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[warn] getaddrinfo: address family for nodename not supported\n","[evhttp_server.cc : 250] NET_LOG: Entering the event loop ...\n"]}]},{"cell_type":"markdown","source":["## Querying TF Serving through the REST API (client side)"],"metadata":{"id":"75N3zNzk92fg"}},{"cell_type":"markdown","source":["Let’s start by creating the query. It must contain the name of the function signature you want to call, and of course the input data. Since the request must use the JSON format, we have to convert the input images from a `NumPy` array to a Python list:"],"metadata":{"id":"xD8fQFTv-D2e"}},{"cell_type":"code","source":["input_data_json = json.dumps({\n","    \"signature_name\": \"serving_default\",\n","    \"instances\": X_new.tolist(),\n","})"],"metadata":{"id":"tx5imAfy7W8x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that the JSON format is 100% text-based:"],"metadata":{"id":"gJ9fpeDQ-MTo"}},{"cell_type":"code","source":["repr(input_data_json)[:1500] + \"...\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"tzPnf4Tk7pn0","outputId":"baf499db-7b1b-41d6-960a-ad67b4bb828a","executionInfo":{"status":"ok","timestamp":1728361284800,"user_tz":-480,"elapsed":346,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 84, 185, 159, 151, 60, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 222, 254, 254, 254, 254, 241, 198, 198, 198, 198, 198, 198, 198, 198, 170, 52, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 67, 114, 72, 114, 163, 227, 254, 225, 254, 254, 254, 250, 229, 254, 254, 140, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 66, 14, 67, 67, 67, 59, 21, 236, 254, 106, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 83, 253, 209, 18, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 233, 255, 83, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 254, 238, 44, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 249, 254, 62, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["Now let’s send the input data to TF Serving by sending an HTTP POST request. This can be done easily using the `requests` library:"],"metadata":{"id":"uvg-AMbO-T4g"}},{"cell_type":"code","source":["SERVER_URL = 'http://localhost:8050/v1/models/my_mnist_model:predict'\n","response = requests.post(SERVER_URL, data=input_data_json)\n","response.raise_for_status() # raise an exception in case of error\n","response = response.json()"],"metadata":{"id":"KgBfYn8e7rNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24zwOGxYY-Og","executionInfo":{"status":"ok","timestamp":1728361302443,"user_tz":-480,"elapsed":374,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"55557ab5-5c5b-4fc1-9fbd-6e14fd80ff64"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'predictions': [[3.53230826e-05,\n","   5.75696575e-08,\n","   0.00096685387,\n","   0.00230657682,\n","   1.07747702e-07,\n","   4.59877228e-05,\n","   1.85086302e-09,\n","   0.996408045,\n","   3.26793561e-05,\n","   0.00020429118],\n","  [0.000352457399,\n","   2.44364637e-05,\n","   0.986950219,\n","   0.00840780139,\n","   9.57692858e-09,\n","   0.0020658609,\n","   0.00163580687,\n","   5.1095661e-09,\n","   0.000563289446,\n","   1.647002e-08],\n","  [4.42781202e-05,\n","   0.98272413,\n","   0.00545220776,\n","   0.00212101149,\n","   0.000384204206,\n","   0.000592352764,\n","   0.00147938705,\n","   0.00412784144,\n","   0.00271356269,\n","   0.000361029204]]}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["The response is a dictionary containing a single \"predictions\" key. The corresponding value is the list of predictions. This list is a Python list, so let’s convert it to a `NumPy` array and round the floats it contains to the\n","second decimal:"],"metadata":{"id":"fFyZFS9V-cA4"}},{"cell_type":"code","source":["y_proba = np.array(response[\"predictions\"])\n","y_proba.round(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-K8iZuQo7xn1","outputId":"86380023-370e-4b7f-ac76-eac1ff5eb74b","executionInfo":{"status":"ok","timestamp":1728361321892,"user_tz":-480,"elapsed":320,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["For more information, please refer to https://github.com/tensorflow/serving which include the usuage of gRPC."],"metadata":{"id":"b6f4iUDeAegQ"}},{"cell_type":"markdown","source":["## Deploying a new model version"],"metadata":{"id":"8UGzlBoKA6OA"}},{"cell_type":"markdown","source":["Now let’s create a new model version and export a `SavedModel` to the `my_mnist_model/0002` directory, just like earlier:"],"metadata":{"id":"XoatJ_43BTjY"}},{"cell_type":"code","source":["# Change the architecture\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=(28, 28), dtype=tf.uint8),  # Explicit Input layer\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Rescaling(scale=1 / 255),\n","    tf.keras.layers.Dense(50, activation=\"relu\"),\n","    tf.keras.layers.Dense(50, activation=\"relu\"),\n","    tf.keras.layers.Dense(10, activation=\"softmax\")\n","])\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n","              metrics=[\"accuracy\"])\n","history = model.fit(X_train, y_train, epochs=10,\n","                    validation_data=(X_valid, y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4gE94r57zBE","outputId":"9bc78937-13b9-45d3-c0cb-c412a3273bc1","executionInfo":{"status":"ok","timestamp":1728361493371,"user_tz":-480,"elapsed":60619,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1719/1719 [==============================] - 8s 4ms/step - loss: 0.7706 - accuracy: 0.7897 - val_loss: 0.3431 - val_accuracy: 0.9044\n","Epoch 2/10\n","1719/1719 [==============================] - 5s 3ms/step - loss: 0.3227 - accuracy: 0.9069 - val_loss: 0.2663 - val_accuracy: 0.9232\n","Epoch 3/10\n","1719/1719 [==============================] - 6s 4ms/step - loss: 0.2693 - accuracy: 0.9227 - val_loss: 0.2305 - val_accuracy: 0.9346\n","Epoch 4/10\n","1719/1719 [==============================] - 5s 3ms/step - loss: 0.2375 - accuracy: 0.9323 - val_loss: 0.2108 - val_accuracy: 0.9404\n","Epoch 5/10\n","1719/1719 [==============================] - 6s 3ms/step - loss: 0.2142 - accuracy: 0.9392 - val_loss: 0.1914 - val_accuracy: 0.9444\n","Epoch 6/10\n","1719/1719 [==============================] - 6s 4ms/step - loss: 0.1951 - accuracy: 0.9435 - val_loss: 0.1817 - val_accuracy: 0.9496\n","Epoch 7/10\n","1719/1719 [==============================] - 5s 3ms/step - loss: 0.1788 - accuracy: 0.9486 - val_loss: 0.1669 - val_accuracy: 0.9528\n","Epoch 8/10\n","1719/1719 [==============================] - 6s 4ms/step - loss: 0.1651 - accuracy: 0.9527 - val_loss: 0.1597 - val_accuracy: 0.9560\n","Epoch 9/10\n","1719/1719 [==============================] - 5s 3ms/step - loss: 0.1529 - accuracy: 0.9562 - val_loss: 0.1474 - val_accuracy: 0.9600\n","Epoch 10/10\n","1719/1719 [==============================] - 6s 4ms/step - loss: 0.1429 - accuracy: 0.9586 - val_loss: 0.1383 - val_accuracy: 0.9626\n"]}]},{"cell_type":"code","source":["model_version = \"0002\"\n","model_name = \"my_mnist_model\"\n","model_path = os.path.join(model_name, model_version)\n","\n","tf.keras.models.save_model(\n","    model,\n","    model_path,\n","    overwrite=True,\n","    include_optimizer=True,\n","    save_format=\"tf\",\n","    signatures=None,\n","    options=None\n",")"],"metadata":{"id":"rCx3wneqA-ld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for root, dirs, files in os.walk(model_name):\n","    indent = '    ' * root.count(os.sep)\n","    print('{}{}/'.format(indent, os.path.basename(root)))\n","    for filename in files:\n","        print('{}{}'.format(indent + '    ', filename))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kz6jGDHhBJHQ","outputId":"10eb862d-a51a-4a98-f627-e33b4f18256e","executionInfo":{"status":"ok","timestamp":1728361494199,"user_tz":-480,"elapsed":8,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["my_mnist_model/\n","    0002/\n","        keras_metadata.pb\n","        fingerprint.pb\n","        saved_model.pb\n","        variables/\n","            variables.data-00000-of-00001\n","            variables.index\n","        assets/\n","    0001/\n","        keras_metadata.pb\n","        fingerprint.pb\n","        saved_model.pb\n","        variables/\n","            variables.data-00000-of-00001\n","            variables.index\n","        assets/\n"]}]},{"cell_type":"markdown","source":["At regular intervals (the delay is configurable), TensorFlow Serving checks for new model versions. If it finds one, it will automatically handle the transition gracefully: by default, it will answer pending requests (if any) with the previous model version, while handling new requests with the new version. As soon as every pending request has been answered, the previous model version is unloaded. You can see this at work in the TF Serving logs:"],"metadata":{"id":"JNiIxJDABhvx"}},{"cell_type":"code","source":["SERVER_URL = 'http://localhost:8050/v1/models/my_mnist_model:predict'\n","\n","response = requests.post(SERVER_URL, data=input_data_json)\n","response.raise_for_status()\n","response = response.json()"],"metadata":{"id":"bykQlJsvBLir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_proba = np.array(response[\"predictions\"])\n","y_proba.round(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FThGiclBOHo","outputId":"a10a8a4a-c3d5-4c60-c784-407f3ecfc17d","executionInfo":{"status":"ok","timestamp":1728361616369,"user_tz":-480,"elapsed":318,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99, 0.  , 0.  ],\n","       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["!pgrep tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AspWanW5KfZP","outputId":"a307d5e6-9ec2-44d0-8be5-0ddcc484556a","executionInfo":{"status":"ok","timestamp":1728361618738,"user_tz":-480,"elapsed":321,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["15262\n"]}]},{"cell_type":"code","source":["!kill $(pgrep tensorflow)"],"metadata":{"id":"VZonNdWhKhdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pgrep tensorflow"],"metadata":{"id":"V5ryPqy8Z0Cy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As you can see, TF Serving makes it quite simple to deploy new models. Moreover, if you discover that version 2 does not work as well as you expected, then rolling back to version 1 is as simple as removing the `my_mnist_model/0002` directory."],"metadata":{"id":"L6eqGpg-Bwme"}},{"cell_type":"markdown","source":["You can also refer to https://github.com/microsoft/ML-For-Beginners/blob/main/3-Web-App/1-Web-App/README.md or https://github.com/rodrigo-arenas/fast-ml-deploy which use [Flask](https://flask.palletsprojects.com/en/) and [FastAPI](https://fastapi.tiangolo.com/) that may have more flexibility."],"metadata":{"id":"UgV76GJjDJiZ"}},{"cell_type":"markdown","source":["If you would like to deploy to GCP vertex AI, checkout [here](https://github.com/ageron/handson-ml3/blob/main/19_training_and_deploying_at_scale.ipynb)."],"metadata":{"id":"RElpvr6NCuJY"}},{"cell_type":"markdown","source":["# 📘 Deploy a REST API server using [`BentoML`](https://docs.bentoml.com/en/latest/index.html#) on remote server"],"metadata":{"id":"5HnKXdgmhhTv"}},{"cell_type":"markdown","source":["To begin with `BentoML`, you will need to save your trained models with `BentoML` API in its model store (a local directory managed by `BentoML`). The model store is used for managing all your trained models locally as well as accessing them for serving."],"metadata":{"id":"G4rQkFrGDM--"}},{"cell_type":"markdown","source":["## Train a classifier model using the iris dataset and store it into local store"],"metadata":{"id":"xghZJBNqhs0O"}},{"cell_type":"code","source":["# Load training data\n","iris = datasets.load_iris()\n","X, y = iris.data, iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"N6RLmbgHho9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","clf = svm.SVC(gamma='scale')\n","clf.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"VE741FV7kyQ0","executionInfo":{"status":"ok","timestamp":1729321220520,"user_tz":-480,"elapsed":3,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"8ff66ba6-c5a7-48bf-df48-6796c2fda7e9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC()"],"text/html":["<style>#sk-container-id-3 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-3 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-3 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-3 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-3 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-3 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-3 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-3 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-3 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-3 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-3 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-3 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-3 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-3 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-3 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-3 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-3 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["y_pred = clf.predict(X_test)\n","print(classification_report(y_test,y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TC0bmn6ihxRY","outputId":"11fc3892-b9cd-40fe-ecb0-a279891ae8cf","executionInfo":{"status":"ok","timestamp":1729321221822,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        10\n","           1       1.00      1.00      1.00         9\n","           2       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n"]}]},{"cell_type":"code","source":["clf.predict([[5.9, 3.0, 5.1, 1.8]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDP4h6QQagXJ","executionInfo":{"status":"ok","timestamp":1729321236970,"user_tz":-480,"elapsed":403,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"f1b40a9e-ec4d-4f10-90e5-33809403a39e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Save the `clf` model with `BentoML`. We begin by saving a trained model instance to **`BentoML`’s local model store**. The local model store is used to version your models as well as control which models are packaged with your bento. It is noted that there are a [wide range of models](https://docs.bentoml.org/en/latest/reference/frameworks/index.html#) can be saved via `BentoML`.\n","\n","> It is possible to use pre-trained models directly with `BentoML` or import existing trained model files to `BentoML`."],"metadata":{"id":"Q8zYLNH_itMe"}},{"cell_type":"code","source":["# Save model to the BentoML local model store\n","with bentoml.models.create(\"iris_sklearn\") as bento_model:\n","    joblib.dump(clf, bento_model.path_of(\"model.pkl\"))\n","print(f\"Model saved: {bento_model}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Tr-eMEYimGA","outputId":"ecacb5c3-80b1-467a-8042-47564ffb80b7","executionInfo":{"status":"ok","timestamp":1729321283216,"user_tz":-480,"elapsed":420,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved: Model(tag=\"iris_sklearn:6ktksgun46rtsasc\")\n"]}]},{"cell_type":"markdown","source":["Models saved can be accessed via `bentoml models` CLI command:"],"metadata":{"id":"GdbaGBQGjkT3"}},{"cell_type":"code","source":["!bentoml models list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMj0y2KRiwkZ","outputId":"460a48df-8571-4533-82f5-659f61551cc3","executionInfo":{"status":"ok","timestamp":1729321289623,"user_tz":-480,"elapsed":2327,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m \u001b[0m\u001b[1mTag                          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n"," iris_sklearn:6ktksgun46rtsasc          5.45 KiB  2024-10-19 07:01:21 \n"]}]},{"cell_type":"markdown","source":["To verify that the saved model can be loaded correctly:"],"metadata":{"id":"ABLTgSPMjuOG"}},{"cell_type":"code","source":["# This stage retrieves the metadata and information associated with the model\n","# (e.g., file paths, versions, model framework) from the BentoML model store.\n","iris_model = bentoml.models.get(\"iris_sklearn:latest\")\n","# This stage loads the actual model object from the serialized file (model.pkl)\n","# into memory so you can use it for inference.\n","loaded_model = joblib.load(iris_model.path_of(\"model.pkl\"))\n","# We can instead load specific version of model iris_sklearn:ahcmqvufggxziasc\n","loaded_model.predict([[5.9, 3.0, 5.1, 1.8]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njBF04-Yjfek","outputId":"3b98f71e-35c0-485b-c0ff-1abf81f48190","executionInfo":{"status":"ok","timestamp":1729321349471,"user_tz":-480,"elapsed":950,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## Create a `BentoML` Service for serving the model"],"metadata":{"id":"UsAvuehvj1zR"}},{"cell_type":"markdown","source":["Services are the core components of `BentoML`, where the serving logic is defined. With the model saved in the model store, we can define the service by creating a Python file `service.py` with the following contents:"],"metadata":{"id":"g2wgm8sFk5oY"}},{"cell_type":"code","source":["%%writefile service.py\n","\n","# Import necessary modules for processing, validation, and typing\n","import numpy as np\n","from pydantic import Field  # To define and validate input fields\n","from typing_extensions import Annotated  # To annotate types for more precise type hints\n","\n","# Import BentoML for service creation and model handling\n","import bentoml\n","from bentoml.validators import Shape  # To validate the shape of incoming data\n","\n","# Create a BentoML service with resource allocation\n","@bentoml.service(\n","    resources={\n","        \"cpu\": \"2\",  # Allocate 1 CPU for this service\n","        \"memory\": \"4Gi\",  # Allocate 2 GB of memory for this service\n","    },\n",")\n","class IrisClassifier:\n","    \"\"\"\n","    A simple Iris classification service using a pre-trained sklearn compatible model.\n","    This service will load the model and provide an API for classification.\n","    \"\"\"\n","\n","    # Load the model once at the class level to declare it as a dependency for the service.\n","    # Using BentoML's model management system to get the latest version of the model.\n","    # Class attribute\n","    iris_model = bentoml.models.get(\"iris_sklearn:latest\")\n","\n","    def __init__(self):\n","        \"\"\"\n","        Initialize the service by loading the sklearn model from BentoML's model store.\n","        This ensures that the model is loaded when the service starts and ready for inference.\n","        \"\"\"\n","        import joblib  # Import joblib to load the model\n","\n","        # Load the model from the BentoML store and deserialize it using joblib\n","        self.model = joblib.load(self.iris_model.path_of(\"model.pkl\"))\n","\n","    # Define an API endpoint that clients can call to classify data\n","    @bentoml.api\n","    def classify(\n","        self,\n","        # The input is expected to be a NumPy array with a shape (-1, 4), i.e., any number of rows and 4 columns.\n","        # This represents the 4 features of the Iris dataset (sepal length, sepal width, petal length, petal width).\n","        input_series: Annotated[np.ndarray, Shape((-1, 4))] = Field(\n","            default=[[5.2, 2.3, 5.0, 0.7]]  # Default input if no data is provided\n","        ),\n","    ) -> np.ndarray:\n","        \"\"\"\n","        Define the classify API. This method accepts an array of input data, processes it,\n","        and returns the model's predictions.\n","        - input_series: The input should be a NumPy array with shape (-1, 4) where -1 represents\n","                        any number of samples and 4 represents the number of features.\n","        - Returns: A NumPy array containing the predicted class for each input sample.\n","        \"\"\"\n","        # Use the loaded model to make predictions on the input data and return the results\n","        return self.model.predict(input_series)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlhoGXS8jxOA","outputId":"ccc11584-b575-4042-d83d-32e1b1068b54","executionInfo":{"status":"ok","timestamp":1729323255693,"user_tz":-480,"elapsed":401,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting service.py\n"]}]},{"cell_type":"markdown","source":["> - `@bentoml.service`: Defines the entire service, specifying the computational resources required (CPU, memory, etc.) and organizing models, methods, and dependencies. **When you add `@bentoml.service` to a class**, you are telling BentoML that the class represents a service.\n","- The `@bentoml.api` decorator is used to define an API endpoint for the service. **This is how you expose a function that clients can call to interact with the model.** It enables you to define how the service will handle requests, such as making predictions or doing some processing based on input data."],"metadata":{"id":"ovTTGLRJmwxK"}},{"cell_type":"markdown","source":["In this example, we defined the input and output type to be `numpy.ndarray`. More options, such as `pandas.DataFrame`, `JSON` and `PIL.image` are also supported. The `bentoml.api` decorator adds a function to the `bentoml.Service` object's APIs list. The input and output parameter takes an IO Descriptor object, which specifies the API function's expected input/output types, and is used for generating HTTP endpoints. Inside the API function, users can define any business logic, feature fetching, and feature transformation code."],"metadata":{"id":"xz5SAEJulUG_"}},{"cell_type":"markdown","source":["> `BentoML` Server runs the Service API in an ASGI web serving layer. **The ASGI web serving layer will expose REST endpoints for inference APIs, such as POST /predict and common infrastructure APIs, such as GET /metrics for monitoring.** You can use other ASGI app like FastAPI or WSGI app like `Flask`, see [here](https://docs.bentoml.org/en/latest/guides/asgi.html)."],"metadata":{"id":"BzDoMDYgOLmQ"}},{"cell_type":"markdown","source":["We now have everything we need to serve our first request. Launch the server in debug mode by running the `bentoml serve` command in the current working directory. Using the `--reload` option allows the server to reflect any changes made to the `service.py` module without restarting:"],"metadata":{"id":"i_ZCPRN9lsLY"}},{"cell_type":"code","source":["!rm -rf nohup.out\n","!nohup bentoml serve service.py:IrisClassifier --reload --port 8050 &"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oLpk4yqoZFH","outputId":"af0d01b7-a3fc-4df9-8653-80488a5ab642","executionInfo":{"status":"ok","timestamp":1729323260775,"user_tz":-480,"elapsed":418,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}]},{"cell_type":"markdown","source":["We can then send requests to the newly started service with any HTTP client:"],"metadata":{"id":"IbSWqAIPuPGf"}},{"cell_type":"code","source":["input_data = {\n","    \"input_series\": [[5.9, 3.0, 5.1, 1.8]]\n","}\n","# POST is used here because you're sending data to the server for processing\n","requests.post(\n","    \"http://127.0.0.1:8050/classify\",\n","    json=input_data\n","    ).text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"F-cNwCoXl6u3","outputId":"f99c3069-5d06-4288-cd67-6f3e564316dc","executionInfo":{"status":"ok","timestamp":1729323301433,"user_tz":-480,"elapsed":7673,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[2]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["# Send a GET request to the /health endpoint\n","response = requests.get(\"http://localhost:8050/healthz\")\n","\n","# Print the health status\n","if response.status_code == 200:\n","    print(\"Health Check Passed:\", response.text)\n","else:\n","    print(\"Health Check Failed:\", response.status_code)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJbvPzubs8jt","executionInfo":{"status":"ok","timestamp":1729323456445,"user_tz":-480,"elapsed":8290,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"e707a0cb-3008-4adc-fdc7-ccff28fa82db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Health Check Passed: \n","\n"]}]},{"cell_type":"markdown","source":["Alternatively, we could use:"],"metadata":{"id":"n96qvB2Nh-0g"}},{"cell_type":"code","source":["input_series = [\n","    [5.1, 3.5, 1.4, 0.2],\n","    [6.2, 2.9, 4.3, 1.3],\n","    [5.9, 3.0, 5.1, 1.8],\n","    [4.6, 3.1, 1.5, 0.2],\n","    [6.7, 3.1, 4.4, 1.4],\n","    [5.5, 2.6, 4.4, 1.2],\n","    [7.7, 3.0, 6.1, 2.3],\n","    [4.9, 3.0, 1.4, 0.2],\n","]\n","\n","with bentoml.SyncHTTPClient(\"http://localhost:8050\", timeout=120) as client:\n","    pred = client.classify(input_series)\n","    print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJ24FZc8h14D","executionInfo":{"status":"ok","timestamp":1729323546710,"user_tz":-480,"elapsed":10398,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"605c747b-76e0-4b78-d9d6-a984777e0ed5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 0 1 1 2 0]\n"]}]},{"cell_type":"code","source":["!pgrep bentoml"],"metadata":{"id":"_T7XLWIzmPlg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kill $(pgrep bentoml)"],"metadata":{"id":"z5jPb8BrqSMT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323553744,"user_tz":-480,"elapsed":416,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"0a6dc2f5-df35-41f8-b7ed-f435b86e3576"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n"]}]},{"cell_type":"markdown","source":["## Build and Deploy Bentos 🍱"],"metadata":{"id":"ldMJBh23vEc_"}},{"cell_type":"markdown","source":["Once we are happy with the service definition, we can build the model and service into a `bento`. Bento is the distribution format for a service. It is a self-contained archive that contains all the source code, model files and dependency specifications required to run the service. Checkout [Building Bentos](https://docs.bentoml.org/en/latest/guides/build-options.html) for more details."],"metadata":{"id":"TZ4o7ucOvF4-"}},{"cell_type":"markdown","source":["To build a Bento, first create a file named `bentofile.yaml` in your project directory:"],"metadata":{"id":"L5qUMltdvcBu"}},{"cell_type":"code","source":["%%writefile bentofile.yaml\n","service: \"service.py:IrisClassifier\"  # A convention for locating your service: <YOUR_SERVICE_PY>:<YOUR_SERVICE_ANNOTATION>\n","description: \"file: ./README.md\"\n","labels:\n","    owner: nsysu-math608\n","    stage: demo\n","include:\n"," - \"*.py\"  # A pattern for matching which files to include in the bento\n","python:\n","  packages:\n","   - scikit-learn  # Additional libraries to be included in the bento\n","   - pandas\n","  lock_packages: False"],"metadata":{"id":"l0sEOEowu4w0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323594946,"user_tz":-480,"elapsed":401,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"feafd943-e798-4d21-ae86-c58978e40502"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing bentofile.yaml\n"]}]},{"cell_type":"code","source":["%%writefile README.md\n","This is a iris classifier build in math608"],"metadata":{"id":"Vj5BPdZPv06u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323598295,"user_tz":-480,"elapsed":382,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"1f1c2d77-a0fc-4a12-b7fe-32df4b5ba506"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing README.md\n"]}]},{"cell_type":"markdown","source":["Next, use the bentoml build CLI command in the same directory to build a bento."],"metadata":{"id":"oq-lbzYhvgI3"}},{"cell_type":"code","source":["!bentoml build"],"metadata":{"id":"eAA9xJnAvYa_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323606173,"user_tz":-480,"elapsed":2308,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"c79b2290-6907-4c96-a45d-051767e395e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: `bentoml.models.get()` as the class attribute is not recommended because it requires the model to exist at import time. Use `iris_model = BentoModel('iris_sklearn:6ktksgun46rtsasc')` instead.\n","INFO: Adding current BentoML version to requirements.txt: bentoml==1.3.9\n","\n","██████╗ ███████╗███╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n","██╔══██╗██╔════╝████╗  ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n","██████╔╝█████╗  ██╔██╗ ██║   ██║   ██║   ██║██╔████╔██║██║\n","██╔══██╗██╔══╝  ██║╚██╗██║   ██║   ██║   ██║██║╚██╔╝██║██║\n","██████╔╝███████╗██║ ╚████║   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n","╚═════╝ ╚══════╝╚═╝  ╚═══╝   ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n","\n","\u001b[32mSuccessfully built \u001b[0m\u001b[1;32mBento\u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mtag\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"iris_classifier\u001b[0m\u001b[32m:lldd3run5wwfqasc\"\u001b[0m\u001b[1;32m)\u001b[0m\u001b[32m.\u001b[0m\n","\n","\u001b[34mNext steps: \u001b[0m\n","\n","\u001b[34m* Deploy to BentoCloud:\u001b[0m\n","\u001b[34m    $ bentoml deploy iris_classifier:lldd3run5wwfqasc -n $\u001b[0m\u001b[1;34m{\u001b[0m\u001b[34mDEPLOYMENT_NAME\u001b[0m\u001b[1;34m}\u001b[0m\n","\n","\u001b[34m* Update an existing deployment on BentoCloud:\u001b[0m\n","\u001b[34m    $ bentoml deployment update --bento iris_classifier:lldd3run5wwfqasc $\u001b[0m\u001b[1;34m{\u001b[0m\u001b[34mDEPLOYMENT_NAME\u001b[0m\u001b[1;34m}\u001b[0m\n","\n","\u001b[34m* Containerize your Bento with `bentoml containerize`:\u001b[0m\n","\u001b[34m    $ bentoml containerize iris_classifier:lldd3run5wwfqasc \u001b[0m\n","\n","\u001b[34m* Push to BentoCloud with `bentoml push`:\u001b[0m\n","\u001b[34m    $ bentoml push iris_classifier:lldd3run5wwfqasc \u001b[0m\n"]}]},{"cell_type":"markdown","source":["Bentos built will be saved in the local bento store, which you can view using the `bentoml list` CLI command."],"metadata":{"id":"4zwY6y2xwDdf"}},{"cell_type":"code","source":["!bentoml list"],"metadata":{"id":"yIlQ2J8qvnD5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323619270,"user_tz":-480,"elapsed":2152,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"381ad3d3-c21b-45b4-b860-1dccdbcde4bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m \u001b[0m\u001b[1mTag                             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModel Size\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n"," iris_classifier:lldd3run5wwfqasc  18.67 KiB  5.45 KiB    2024-10-19 07:40:04 \n"]}]},{"cell_type":"markdown","source":["We can serve bentos from the bento store using the `bentoml serve` `--production` CLI command. Using the `--production` option will serve the bento in production mode."],"metadata":{"id":"lTmUPXn7wPFu"}},{"cell_type":"code","source":["%%bash --bg\n","nohup bentoml serve iris_classifier:latest \\\n","     --production \\\n","     --port 8050 > bentoml.log 2>&1"],"metadata":{"id":"_IlkMx2Is1ap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is another way to query the server"],"metadata":{"id":"fv4Ai48uwu9u"}},{"cell_type":"code","source":["!curl -X POST -H \"content-type: application/json\" \\\n","  --data '{\"input_series\": [[5.9, 3.0, 5.1, 1.8]]}' \\\n","  http://127.0.0.1:8050/classify"],"metadata":{"id":"KgAcBHm3wbDI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323678717,"user_tz":-480,"elapsed":397,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"b31f998c-9aab-402a-d43c-bb2865dff2ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2]"]}]},{"cell_type":"markdown","source":["The Bento directory contains all code, files, models and configs required for running this service. `BentoML` standarlizes this file structure which enables serving runtimes and deployment tools to be built on top of it. By default, Bentos are managed under the `~/bentoml/bentos` directory:"],"metadata":{"id":"PbXF0hyfw_og"}},{"cell_type":"code","source":["path =\"/root/bentoml/bentos/iris_classifier/\""],"metadata":{"id":"3agYCiqHwqhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for root, dirs, files in os.walk(path):\n","    indent = ' ' * root.count(os.sep)\n","    print('{}{}/'.format(indent, os.path.basename(root)))\n","    for filename in files:\n","        print('{}{}'.format(indent + ' ', filename))"],"metadata":{"id":"tUKsg5nM0OsH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323687778,"user_tz":-480,"elapsed":406,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"d1b650b2-d6f0-4f3c-a543-626fa48b5e76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     /\n","      latest\n","     lldd3run5wwfqasc/\n","      README.md\n","      bento.yaml\n","      src/\n","       bentofile.yaml\n","       service.py\n","       __pycache__/\n","        service.cpython-310.pyc\n","      env/\n","       python/\n","        version.txt\n","        requirements.txt\n","        install.sh\n","       docker/\n","        Dockerfile\n","        entrypoint.sh\n","      apis/\n","       schema.json\n","       openapi.yaml\n"]}]},{"cell_type":"code","source":["!lsof -i :8050"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY-WHfIVvoCa","executionInfo":{"status":"ok","timestamp":1729324185729,"user_tz":-480,"elapsed":401,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"08768890-d18b-4f2f-d4c7-949c4369b638"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["COMMAND PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n","python3 293 root   54u  IPv4 427918      0t0  TCP localhost:55736->localhost:8050 (CLOSE_WAIT)\n","python3 293 root   55u  IPv4 399534      0t0  TCP localhost:37954->localhost:8050 (CLOSE_WAIT)\n","python3 293 root   56u  IPv4 486198      0t0  TCP localhost:57360->localhost:8050 (CLOSE_WAIT)\n","python3 293 root   58u  IPv4 471106      0t0  TCP localhost:48184->localhost:8050 (CLOSE_WAIT)\n"]}]},{"cell_type":"code","source":["!ps aux | grep bentoml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2LaVQ6w-vFI8","executionInfo":{"status":"ok","timestamp":1729324182331,"user_tz":-480,"elapsed":423,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"a36772e3-233e-42bc-cf08-ab80d9f0f348"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root       22169  0.0  0.0   6484  2256 ?        S    07:49   0:00 grep bentoml\n"]}]},{"cell_type":"code","source":["!kill 12246"],"metadata":{"id":"Z70zQRBSvZ6S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pgrep bentoml"],"metadata":{"id":"ke_qrRHQzj0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kill $(pgrep bentoml)"],"metadata":{"id":"hNslyi-QzkxH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729323716360,"user_tz":-480,"elapsed":404,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"4e522a81-4712-4799-d7fb-ab4de9475763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n"]}]},{"cell_type":"markdown","source":["For more information, please refer to https://docs.bentoml.org/en/latest/index.html"],"metadata":{"id":"Bw_A1VnIyReH"}},{"cell_type":"markdown","source":["# 📘 Deploy web base application in local computer using `streamit`"],"metadata":{"id":"SB48ta6AGzYI"}},{"cell_type":"markdown","source":["Streamlit's simple and focused API lets you build incredibly rich and powerful tools. It contains a large number of [elements](https://docs.streamlit.io/library/api-reference) and [components](https://streamlit.io/components) that you can use.\n","\n","There are a few ways to display data (tables, arrays, data frames) in Streamlit apps. Below, [`st.write()`](https://docs.streamlit.io/library/api-reference/write-magic/magic) can be used to write anything from text, plots to tables. In addition, when you've got the data or model into the state that you want to explore, you can add in widgets like `st.slider()`, `st.button()` or `st.selectbox()`.\n","\n","Finally, Streamlit makes it easy to organize your widgets in a left panel sidebar with `st.sidebar`. Each element that's passed to `st.sidebar` is pinned to the left, allowing users to focus on the content in your app while still having access to UI controls. For example, if you want to add a selectbox and a slider to a sidebar, use `st.sidebar.slider` and `st.sidebar.selectbox` instead of `st.slider` and `st.selectbox`:"],"metadata":{"id":"3BN-1OnBuWpa"}},{"cell_type":"code","source":["# @title Download image\n","!gdown --fuzzy https://drive.google.com/file/d/119iIKzLliTAjvrbtiTqgGP3QrPVg70q6/view?usp=sharing\n","!gdown --fuzzy https://drive.google.com/file/d/11E1DFsV5ZHkSnDV2AJOLp1QSWND9ecTe/view?usp=sharing\n","!gdown --fuzzy https://drive.google.com/file/d/11FSlllRYY-S9dPAYKVpDLo3kyonGTfzE/view?usp=sharing"],"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"3F51lGJIy3Nw","executionInfo":{"status":"ok","timestamp":1729324908903,"user_tz":-480,"elapsed":13715,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"37774f20-5ec6-4f8e-fd44-e52b42042275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=119iIKzLliTAjvrbtiTqgGP3QrPVg70q6\n","To: /content/setosa.png\n","100% 579k/579k [00:00<00:00, 109MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=11E1DFsV5ZHkSnDV2AJOLp1QSWND9ecTe\n","To: /content/versicolor.png\n","100% 527k/527k [00:00<00:00, 117MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=11FSlllRYY-S9dPAYKVpDLo3kyonGTfzE\n","To: /content/virginica.png\n","100% 524k/524k [00:00<00:00, 139MB/s]\n"]}]},{"cell_type":"code","source":["%%writefile iris-app.py\n","\n","# Import necessary libraries\n","import streamlit as st  # Streamlit is used for creating web apps\n","import pandas as pd\n","from sklearn import datasets\n","from sklearn.ensemble import RandomForestClassifier\n","from PIL import Image  # PIL is used to load images\n","\n","# Display the app title and description\n","st.write(\"\"\"\n","# Simple Iris Flower Prediction App\n","\n","This app predicts the **Iris flower** type and shows its corresponding image!\n","\"\"\")\n","\n","# Sidebar for user input\n","st.sidebar.header('User Input Parameters')\n","\n","# Function to create a dataframe with user input from sliders in the sidebar\n","def user_input_features():\n","    # Sliders for user input of flower features\n","    sepal_length = st.sidebar.slider('Sepal length', 4.3, 7.9, 5.4)\n","    sepal_width = st.sidebar.slider('Sepal width', 2.0, 4.4, 3.4)\n","    petal_length = st.sidebar.slider('Petal length', 1.0, 6.9, 1.3)\n","    petal_width = st.sidebar.slider('Petal width', 0.1, 2.5, 0.2)\n","\n","    # Store the inputs in a dictionary\n","    data = {'sepal_length': sepal_length,\n","            'sepal_width': sepal_width,\n","            'petal_length': petal_length,\n","            'petal_width': petal_width}\n","\n","    # Convert the dictionary into a pandas DataFrame to easily manage the input data\n","    features = pd.DataFrame(data, index=[0])\n","    return features\n","\n","# Store the user input parameters in a dataframe\n","df = user_input_features()\n","\n","# Display user input parameters in the app\n","st.subheader('User Input parameters')\n","st.write(df)\n","\n","# Load the Iris dataset from sklearn\n","iris = datasets.load_iris()\n","X = iris.data  # Features (sepal/petal measurements)\n","Y = iris.target  # Labels (flower species)\n","\n","# Initialize and train the RandomForestClassifier model on the Iris dataset\n","clf = RandomForestClassifier()\n","clf.fit(X, Y)\n","\n","# Make a prediction based on the user input features\n","prediction = clf.predict(df)\n","prediction_proba = clf.predict_proba(df)  # Get prediction probabilities\n","\n","# Display the target names for the Iris dataset\n","st.subheader('Class labels and their corresponding index number')\n","st.write(iris.target_names)\n","\n","# Display the prediction result (the predicted flower species)\n","st.subheader('Prediction')\n","st.write(iris.target_names[prediction])\n","\n","# Display the prediction probability for each class\n","st.subheader('Prediction Probability')\n","st.write(prediction_proba)\n","\n","# Load the image corresponding to the prediction\n","if prediction == 0:\n","    image = Image.open('setosa.png')\n","    st.image(image, caption='Iris Setosa', use_column_width=True)\n","elif prediction == 1:\n","    image = Image.open('versicolor.png')\n","    st.image(image, caption='Iris Versicolor', use_column_width=True)\n","else:\n","    image = Image.open('virginica.png')\n","    st.image(image, caption='Iris Virginica', use_column_width=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5WOyr1cQcXN","executionInfo":{"status":"ok","timestamp":1729324986423,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"baef4bc8-3de5-4162-bd31-e3c37de67321"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting iris-app.py\n"]}]},{"cell_type":"code","source":["%%bash --bg\n","streamlit run iris-app.py --server.port 8050 > debug.log 2>&1"],"metadata":{"id":"gLBRsyy0G6Uo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> 2>&1: This redirects the standard error (i.e., error messages) to the same location as the standard output. The 2 refers to the file descriptor for errors (stderr), and 1 refers to the file descriptor for standard output (stdout). So, 2>&1 makes sure both normal output and errors go to the debug.log file."],"metadata":{"id":"x6Jg4Q8dxF5q"}},{"cell_type":"markdown","source":["As soon as you run the script as shown above, a local Streamlit server will spin up and your app will open in a new tab in your default web browser. The app is your canvas, where you'll draw charts, text, widgets, tables, and more."],"metadata":{"id":"gbbZ3vTORYZ5"}},{"cell_type":"code","source":["!tail debug.log"],"metadata":{"id":"FFZL2c_5Kaso","executionInfo":{"status":"ok","timestamp":1729324991654,"user_tz":-480,"elapsed":531,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"49171335-9400-4ec9-a414-f5a53bd993d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\n","\n","  You can now view your Streamlit app in your browser.\n","\n","  Local URL: http://localhost:8050\n","  Network URL: http://172.28.0.12:8050\n","  External URL: http://34.90.244.234:8050\n","\n"]}]},{"cell_type":"code","source":["public_url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJuBFXjdtkJA","outputId":"f8cb467c-651f-4451-d65a-97045eb3265e","executionInfo":{"status":"ok","timestamp":1729324993197,"user_tz":-480,"elapsed":432,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"https://c680-34-90-244-234.ngrok-free.app\" -> \"http://localhost:8050\">"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","source":["Try to click the above link to access the web app. For more information, please refer to https://github.com/streamlit/streamlit"],"metadata":{"id":"-JN1a3SutjUI"}},{"cell_type":"code","source":["!pgrep streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhJbvI0_t-Hx","outputId":"1a7945a5-03b8-400b-ed5a-c4e91ee63136","executionInfo":{"status":"ok","timestamp":1729325106180,"user_tz":-480,"elapsed":380,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25598\n"]}]},{"cell_type":"code","source":["!kill $(pgrep streamlit)"],"metadata":{"id":"R-6Fhs4auDgR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 📘 Deploy web base application in local computer using `Gradio`"],"metadata":{"id":"mJsFDLpWQ7HK"}},{"cell_type":"markdown","source":["UI models are perfect to use with Gradio's image input component, so in this section we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like this."],"metadata":{"id":"mg_eEi4luu9R"}},{"cell_type":"markdown","source":["## Setting up the Image Classification Model"],"metadata":{"id":"zXerdxtzxKOB"}},{"cell_type":"markdown","source":["First, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from Keras. You can use a different pretrained model or train your own."],"metadata":{"id":"X6jU4ZkUxNJB"}},{"cell_type":"code","source":["!wget https://huggingface.co/spaces/gradio/keras-image-classifier/resolve/main/banana.jpg\n","!wget https://huggingface.co/spaces/gradio/keras-image-classifier/resolve/main/car.jpg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00anQWulwYlR","outputId":"339fb8ea-0961-4f87-eb87-29e57ebc93e3","executionInfo":{"status":"ok","timestamp":1729325115871,"user_tz":-480,"elapsed":819,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-19 08:05:14--  https://huggingface.co/spaces/gradio/keras-image-classifier/resolve/main/banana.jpg\n","Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.103, 18.239.50.49, ...\n","Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28437 (28K) [image/jpeg]\n","Saving to: ‘banana.jpg’\n","\n","\rbanana.jpg            0%[                    ]       0  --.-KB/s               \rbanana.jpg          100%[===================>]  27.77K  --.-KB/s    in 0s      \n","\n","2024-10-19 08:05:14 (228 MB/s) - ‘banana.jpg’ saved [28437/28437]\n","\n","--2024-10-19 08:05:14--  https://huggingface.co/spaces/gradio/keras-image-classifier/resolve/main/car.jpg\n","Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.103, 18.239.50.49, ...\n","Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 79626 (78K) [image/jpeg]\n","Saving to: ‘car.jpg’\n","\n","car.jpg             100%[===================>]  77.76K  --.-KB/s    in 0.08s   \n","\n","2024-10-19 08:05:14 (951 KB/s) - ‘car.jpg’ saved [79626/79626]\n","\n"]}]},{"cell_type":"code","source":["inception_net = tf.keras.applications.MobileNetV2()"],"metadata":{"id":"EI-LD2DUORgC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae5bccac-9dfd-4069-e7b0-0bcfdb73cc32","executionInfo":{"status":"ok","timestamp":1729325125677,"user_tz":-480,"elapsed":3224,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n","14536120/14536120 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"markdown","source":["## Defining a predict function"],"metadata":{"id":"MYWY_7oExPd5"}},{"cell_type":"markdown","source":["Next, we will need to define a function that takes in the user input, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from [this text file](https://raw.githubusercontent.com/gradio-app/mobilenet-example/master/labels.txt).\n","\n","In the case of our pretrained model, it will look like this:"],"metadata":{"id":"yVHc0kSuxQuC"}},{"cell_type":"code","source":["# Download human-readable labels for ImageNet.\n","response = requests.get(\"https://git.io/JJkYN\")\n","labels = response.text.split(\"\\n\")\n","\n","def classify_image(inp):\n","    if isinstance(inp, Image.Image):\n","        inp = np.array(inp)\n","    # Ensure the image has three channels (RGB)\n","    if inp.shape[-1] == 4:\n","        inp = inp[..., :3]\n","    # Resize the image to (224, 224) if it's not already\n","    if inp.shape[0] != 224 or inp.shape[1] != 224:\n","        inp = tf.image.resize(inp, [224, 224]).numpy()\n","    # Expand dimensions to match model's expected input\n","    inp = np.expand_dims(inp, axis=0)\n","\n","    # Preprocess the image using MobileNetV2's preprocessing\n","    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n","    prediction = inception_net.predict(inp).flatten()\n","\n","    # Get top 3 predictions\n","    top_indices = prediction.argsort()[-3:][::-1]\n","    confidences = {labels[i]: float(prediction[i]) for i in top_indices}\n","\n","    return confidences"],"metadata":{"id":"RO2OSENMvSkR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's break this down. The function takes one parameter:\n","* `inp`: the input image as a NumPy array\n","\n","Then, the function adds a batch dimension, passes it through the model, and returns:\n","* `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities"],"metadata":{"id":"gGFmr0vMxbX6"}},{"cell_type":"markdown","source":["## Creating a Gradio Interface"],"metadata":{"id":"qDONv9Gkxjnh"}},{"cell_type":"markdown","source":["Now that we have our predictive function set up, we can create a Gradio Interface around it. In this case, the input component is a drag-and-drop image component. To create this input, we can use the `gradio.inputs.Image` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\n","\n","The output component will be a \"label\", which displays the top labels in a nice form. Since we don't want to show all 1,000 class labels, we will customize it to show only the top 3 images.\n","\n","Finally, we'll add one more parameter, the examples, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:"],"metadata":{"id":"nsem8PFexno5"}},{"cell_type":"code","source":["gr.Interface(fn=classify_image,\n","       inputs=gr.Image(width=224, height=224),\n","       outputs=gr.Label(num_top_classes=3, label=\"Predition Probabilities\"),\n","       examples=[\"banana.jpg\", \"car.jpg\"],\n","       description=\"Please upload an image\",\n","       title=\"Classification using MobileNet\",\n","      ).launch(server_port=8050, share=True, debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"id":"ikag2HB1vWWJ","outputId":"0851bb4f-7653-4874-99d9-d72b2f350978","executionInfo":{"status":"ok","timestamp":1729325380858,"user_tz":-480,"elapsed":17965,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://0edd6c3f447778352c.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://0edd6c3f447778352c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:8050 <> https://0edd6c3f447778352c.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":110}]},{"cell_type":"markdown","source":["Gradio automatically produces sharable links with others, but you can also access the web app with our port as follows:"],"metadata":{"id":"3vtNvjJ4x1Ny"}},{"cell_type":"code","source":["public_url"],"metadata":{"id":"XddIL9oaxFGC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729325384637,"user_tz":-480,"elapsed":414,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"fd3818ff-0a66-4561-d124-3107b65c5b1b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"https://c680-34-90-244-234.ngrok-free.app\" -> \"http://localhost:8050\">"]},"metadata":{},"execution_count":111}]},{"cell_type":"markdown","source":["You can see that there is a `flaaged` directory which collect data from users who try the model. To close the gradio, just call the `close_all()` function."],"metadata":{"id":"U0RRajuMfc7F"}},{"cell_type":"code","source":["gr.close_all()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8iwl5dDmVUMq","executionInfo":{"status":"ok","timestamp":1729325385736,"user_tz":-480,"elapsed":2,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"62ea4a35-3903-4d13-b8fd-050c486be64d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Closing server running on port: 8050\n","Closing server running on port: 8050\n","Closing server running on port: 8050\n"]}]},{"cell_type":"markdown","source":["For more information, please refer to https://github.com/gradio-app/gradio"],"metadata":{"id":"6OJN8KHSyFsR"}},{"cell_type":"markdown","source":["# 🔍 Deploy web base applocation using `Tensorflow.js`"],"metadata":{"id":"Ra51x79aRCfQ"}},{"cell_type":"markdown","source":["Tensorflow.js is a WebGL accelerated JavaScript library for training and deploying ML models. The TensorFlow.js project includes a `tensorflowjs_converter` tool that can convert a TensorFlow `SavedModel` or a Keras model file to the TensorFlow.js Layers format: this is a directory\n","containing a set of sharded weight files in binary format and a model.json file that describes the model’s architecture and links to the weight files. This format is optimized to be downloaded efficiently on the web.\n","\n","Users can then download the model and run predictions in the browser using the TensorFlow.js library. Here is a code snippet to give you an idea of what the JavaScript API looks like:\n","\n","\n","```\n","import * as tf from '@tensorflow/tfjs';\n","const model = await tf.loadLayersModel('https://example.com/tfjs/model.json');\n","const image = tf.fromPixels(webcamElement);\n","const prediction = model.predict(image);\n","```"],"metadata":{"id":"Htbhi0Iey96K"}},{"cell_type":"markdown","source":["For more information, please refer to https://github.com/tensorflow/tfjs."],"metadata":{"id":"01GAbm5jyifw"}},{"cell_type":"markdown","source":["# 🔍 Deploy mobile application using `LiteRT`"],"metadata":{"id":"VRiSAp-DRHg6"}},{"cell_type":"markdown","source":["Once again, doing justice to this topic would require a whole book. If you want to learn more about `LiteRT`, check out the O’Reilly book [Practical Deep Learning for Cloud, Mobile, and Edge](https://www.oreilly.com/library/view/practical-deep-learning/9781492034858/) or refer to https://www.tensorflow.org/lite."],"metadata":{"id":"55tvq75Zzdmi"}},{"cell_type":"markdown","source":["# 📘 Monitoring shift with evidently"],"metadata":{"id":"VW_L5gzOQ-8Z"}},{"cell_type":"markdown","source":["## The task at hand: bike demand forecasting"],"metadata":{"id":"eVVQCG8F2sg6"}},{"cell_type":"markdown","source":["We took a Kaggle dataset on [Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand/data). Our goal is to predict the volume of bike rentals on an hourly basis. To do that, we have some data about the season, weather, and day of the week."],"metadata":{"id":"tdeMSRUU2wpx"}},{"cell_type":"code","source":["# @title Download dataset\n","content = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\").content\n","with zipfile.ZipFile(io.BytesIO(content)) as arc:\n","    raw_data = pd.read_csv(arc.open(\"hour.csv\"), header=0, sep=',', parse_dates=['dteday'], index_col='dteday')\n","raw_data.index = raw_data.apply(\n","    lambda row: datetime.combine(row.name, time(hour=int(row['hr']))), axis = 1)"],"metadata":{"id":"1qTX9Ty1RA88","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":735},"id":"CGRUpV_q1bEG","executionInfo":{"status":"ok","timestamp":1729325689976,"user_tz":-480,"elapsed":397,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"4a3f4264-5668-4368-b0ca-3782b821ab34"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     instant  season  yr  mnth  hr  holiday  weekday  \\\n","2011-01-01 00:00:00        1       1   0     1   0        0        6   \n","2011-01-01 01:00:00        2       1   0     1   1        0        6   \n","2011-01-01 02:00:00        3       1   0     1   2        0        6   \n","2011-01-01 03:00:00        4       1   0     1   3        0        6   \n","2011-01-01 04:00:00        5       1   0     1   4        0        6   \n","...                      ...     ...  ..   ...  ..      ...      ...   \n","2012-12-31 19:00:00    17375       1   1    12  19        0        1   \n","2012-12-31 20:00:00    17376       1   1    12  20        0        1   \n","2012-12-31 21:00:00    17377       1   1    12  21        0        1   \n","2012-12-31 22:00:00    17378       1   1    12  22        0        1   \n","2012-12-31 23:00:00    17379       1   1    12  23        0        1   \n","\n","                     workingday  weathersit  temp   atemp   hum  windspeed  \\\n","2011-01-01 00:00:00           0           1  0.24  0.2879  0.81     0.0000   \n","2011-01-01 01:00:00           0           1  0.22  0.2727  0.80     0.0000   \n","2011-01-01 02:00:00           0           1  0.22  0.2727  0.80     0.0000   \n","2011-01-01 03:00:00           0           1  0.24  0.2879  0.75     0.0000   \n","2011-01-01 04:00:00           0           1  0.24  0.2879  0.75     0.0000   \n","...                         ...         ...   ...     ...   ...        ...   \n","2012-12-31 19:00:00           1           2  0.26  0.2576  0.60     0.1642   \n","2012-12-31 20:00:00           1           2  0.26  0.2576  0.60     0.1642   \n","2012-12-31 21:00:00           1           1  0.26  0.2576  0.60     0.1642   \n","2012-12-31 22:00:00           1           1  0.26  0.2727  0.56     0.1343   \n","2012-12-31 23:00:00           1           1  0.26  0.2727  0.65     0.1343   \n","\n","                     casual  registered  cnt  \n","2011-01-01 00:00:00       3          13   16  \n","2011-01-01 01:00:00       8          32   40  \n","2011-01-01 02:00:00       5          27   32  \n","2011-01-01 03:00:00       3          10   13  \n","2011-01-01 04:00:00       0           1    1  \n","...                     ...         ...  ...  \n","2012-12-31 19:00:00      11         108  119  \n","2012-12-31 20:00:00       8          81   89  \n","2012-12-31 21:00:00       7          83   90  \n","2012-12-31 22:00:00      13          48   61  \n","2012-12-31 23:00:00      12          37   49  \n","\n","[17379 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-aa623ac0-aa50-4739-a8de-e061a2d52dc0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2011-01-01 00:00:00</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.81</td>\n","      <td>0.0000</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 01:00:00</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0000</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 02:00:00</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0000</td>\n","      <td>5</td>\n","      <td>27</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 03:00:00</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0000</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 04:00:00</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2012-12-31 19:00:00</th>\n","      <td>17375</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.26</td>\n","      <td>0.2576</td>\n","      <td>0.60</td>\n","      <td>0.1642</td>\n","      <td>11</td>\n","      <td>108</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>2012-12-31 20:00:00</th>\n","      <td>17376</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.26</td>\n","      <td>0.2576</td>\n","      <td>0.60</td>\n","      <td>0.1642</td>\n","      <td>8</td>\n","      <td>81</td>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>2012-12-31 21:00:00</th>\n","      <td>17377</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.26</td>\n","      <td>0.2576</td>\n","      <td>0.60</td>\n","      <td>0.1642</td>\n","      <td>7</td>\n","      <td>83</td>\n","      <td>90</td>\n","    </tr>\n","    <tr>\n","      <th>2012-12-31 22:00:00</th>\n","      <td>17378</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.26</td>\n","      <td>0.2727</td>\n","      <td>0.56</td>\n","      <td>0.1343</td>\n","      <td>13</td>\n","      <td>48</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>2012-12-31 23:00:00</th>\n","      <td>17379</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.26</td>\n","      <td>0.2727</td>\n","      <td>0.65</td>\n","      <td>0.1343</td>\n","      <td>12</td>\n","      <td>37</td>\n","      <td>49</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17379 rows × 16 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa623ac0-aa50-4739-a8de-e061a2d52dc0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-aa623ac0-aa50-4739-a8de-e061a2d52dc0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-aa623ac0-aa50-4739-a8de-e061a2d52dc0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2d7130b9-bde6-4d14-b9e7-1ff375dab24f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d7130b9-bde6-4d14-b9e7-1ff375dab24f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2d7130b9-bde6-4d14-b9e7-1ff375dab24f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_8778c1c7-8098-41ba-91eb-d6172195dbfc\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('raw_data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_8778c1c7-8098-41ba-91eb-d6172195dbfc button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('raw_data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"raw_data","summary":"{\n  \"name\": \"raw_data\",\n  \"rows\": 17379,\n  \"fields\": [\n    {\n      \"column\": \"instant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5017,\n        \"min\": 1,\n        \"max\": 17379,\n        \"num_unique_values\": 17379,\n        \"samples\": [\n          12831,\n          8689,\n          7092\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mnth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"holiday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workingday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weathersit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19255612124972407,\n        \"min\": 0.02,\n        \"max\": 1.0,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.16,\n          0.82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"atemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17185021563536587,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          0.7879,\n          0.9242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1929298340629125,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.29,\n          0.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"windspeed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12234022857279413,\n        \"min\": 0.0,\n        \"max\": 0.8507,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.8507,\n          0.4925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"casual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 0,\n        \"max\": 367,\n        \"num_unique_values\": 322,\n        \"samples\": [\n          201,\n          171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"registered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151,\n        \"min\": 0,\n        \"max\": 886,\n        \"num_unique_values\": 776,\n        \"samples\": [\n          342,\n          744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 181,\n        \"min\": 1,\n        \"max\": 977,\n        \"num_unique_values\": 869,\n        \"samples\": [\n          594,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":116},{"output_type":"stream","name":"stdout","text":["Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"]}]},{"cell_type":"markdown","source":["## Train a model"],"metadata":{"id":"JanaILJc3COD"}},{"cell_type":"markdown","source":["We trained a random forest model using data for the four weeks from January. Let's imagine that in practice, we just started the data collection, and that was all the data available. The performance of the trained model looked acceptable, so we decided to give it a go.\n","\n","We further assume that we only learn the ground truth (the actual demand) **at the end of each week.** That is a realistic assumption in real-world machine learning. Integrating and updating different data sources is not always straightforward. Even after the actual event has occurred! Maybe the daily usage data is stored locally and is only sent and merged in the database once per week."],"metadata":{"id":"uZHcdMIa3GOS"}},{"cell_type":"markdown","source":["To run it, we prepare our performance data as a `Pandas` `DataFrame`. It should include:\n","* **Model application logs**—features that went into the model and corresponding prediction; and\n","* **Ground truth data**—the actual number of bikes rented each hour as our \"target.\""],"metadata":{"id":"VQKN3CCfm1Ln"}},{"cell_type":"markdown","source":["Once we train the model, we can take our training dataset and generated predictions and specify it as the \"Reference\" data. We can select this period directly from the `DataFrame` since it has datetime as an index:"],"metadata":{"id":"sIjj3KO7ZGg4"}},{"cell_type":"code","source":["reference = raw_data.loc['2011-01-01 00:00:00':'2011-01-28 23:00:00'] # Training data\n","\n","target = 'cnt'\n","prediction = 'prediction'\n","numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'hr', 'weekday']\n","categorical_features = ['season', 'holiday', 'workingday']"],"metadata":{"id":"9kzjKdUd3M6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reference.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"1XbNrI9XYvYn","executionInfo":{"status":"ok","timestamp":1729325959330,"user_tz":-480,"elapsed":418,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"808f3574-33b2-4cb2-abad-e92237c88466"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     instant  season  yr  mnth  hr  holiday  weekday  \\\n","2011-01-01 00:00:00        1       1   0     1   0        0        6   \n","2011-01-01 01:00:00        2       1   0     1   1        0        6   \n","2011-01-01 02:00:00        3       1   0     1   2        0        6   \n","2011-01-01 03:00:00        4       1   0     1   3        0        6   \n","2011-01-01 04:00:00        5       1   0     1   4        0        6   \n","\n","                     workingday  weathersit  temp   atemp   hum  windspeed  \\\n","2011-01-01 00:00:00           0           1  0.24  0.2879  0.81        0.0   \n","2011-01-01 01:00:00           0           1  0.22  0.2727  0.80        0.0   \n","2011-01-01 02:00:00           0           1  0.22  0.2727  0.80        0.0   \n","2011-01-01 03:00:00           0           1  0.24  0.2879  0.75        0.0   \n","2011-01-01 04:00:00           0           1  0.24  0.2879  0.75        0.0   \n","\n","                     casual  registered  cnt  \n","2011-01-01 00:00:00       3          13   16  \n","2011-01-01 01:00:00       8          32   40  \n","2011-01-01 02:00:00       5          27   32  \n","2011-01-01 03:00:00       3          10   13  \n","2011-01-01 04:00:00       0           1    1  "],"text/html":["\n","  <div id=\"df-56e1dfdc-ad9b-4ac8-86e2-4d9462dfa4c8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2011-01-01 00:00:00</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.81</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 01:00:00</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 02:00:00</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>5</td>\n","      <td>27</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 03:00:00</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2011-01-01 04:00:00</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56e1dfdc-ad9b-4ac8-86e2-4d9462dfa4c8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-56e1dfdc-ad9b-4ac8-86e2-4d9462dfa4c8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-56e1dfdc-ad9b-4ac8-86e2-4d9462dfa4c8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2ed1c2a1-b4d7-42a1-b26c-6b6f8ee0064d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ed1c2a1-b4d7-42a1-b26c-6b6f8ee0064d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2ed1c2a1-b4d7-42a1-b26c-6b6f8ee0064d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"reference","summary":"{\n  \"name\": \"reference\",\n  \"rows\": 618,\n  \"fields\": [\n    {\n      \"column\": \"instant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 178,\n        \"min\": 1,\n        \"max\": 618,\n        \"num_unique_values\": 618,\n        \"samples\": [\n          50,\n          583,\n          83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mnth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"holiday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workingday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weathersit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08089604949213,\n        \"min\": 0.02,\n        \"max\": 0.46,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"atemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0803852285187921,\n        \"min\": 0.0,\n        \"max\": 0.4545,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1753306415631887,\n        \"min\": 0.21,\n        \"max\": 1.0,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          0.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"windspeed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12155418491981466,\n        \"min\": 0.0,\n        \"max\": 0.5821,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"casual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 47,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"registered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 0,\n        \"max\": 247,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          166\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 1,\n        \"max\": 249,\n        \"num_unique_values\": 166,\n        \"samples\": [\n          82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["reference[numerical_features + categorical_features].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wic2e-nXtX3e","outputId":"021e24f2-8e0f-446e-e455-9cf8f4a2d08d","executionInfo":{"status":"ok","timestamp":1729325970934,"user_tz":-480,"elapsed":447,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(618, 9)"]},"metadata":{},"execution_count":119}]},{"cell_type":"code","source":["regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n","regressor.fit(reference[numerical_features + categorical_features], reference[target])"],"metadata":{"id":"h27i8bmk3Pgp","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1729325989035,"user_tz":-480,"elapsed":577,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"65483168-bb5f-41ee-a4b4-0737534d32bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor(n_estimators=50, random_state=0)"],"text/html":["<style>#sk-container-id-4 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-4 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-4 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-4 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-4 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-4 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-4 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-4 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-4 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-4 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-4 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-4 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-4 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-4 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-4 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-4 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-4 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-4 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-4 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-4 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-4 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-4 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-4 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-4 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-4 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-4 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-4 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-4 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-4 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=50, random_state=0)</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["ref_prediction = regressor.predict(reference[numerical_features + categorical_features])\n","reference['prediction'] = ref_prediction"],"metadata":{"id":"caX_rP9i3Z9A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We also map the columns to show `Evidently` what each column contains and perform a correct analysis:"],"metadata":{"id":"1l5XKuVunKPJ"}},{"cell_type":"code","source":["column_mapping = ColumnMapping()\n","\n","column_mapping.target = target\n","column_mapping.prediction = prediction\n","column_mapping.numerical_features = numerical_features\n","column_mapping.categorical_features = categorical_features"],"metadata":{"id":"Y1m9tO5imGp5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["By default, `Evidently` uses the index as an x-axis in plots. In this case, it is datetime, so we do not need to add anything else explicitly. Otherwise, we would have to specify it in our column mapping."],"metadata":{"id":"AvQliK72ZcTw"}},{"cell_type":"markdown","source":["Next, we call a corresponding report for regression models."],"metadata":{"id":"L00A7MrPnwoF"}},{"cell_type":"code","source":["regression_perfomance = Report(metrics=[RegressionPreset()], options={\"render\": {\"raw_data\": True}})\n","regression_perfomance.run(current_data=reference, reference_data=None, column_mapping=column_mapping)"],"metadata":{"id":"6L4hN2avmJxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# You can also specify the metrics see https://docs.evidentlyai.com/reference/all-metrics\n","#the_report = Report(metrics=[\n","#    RegressionQualityMetric(),\n","#    RegressionErrorPlot(),\n","#    RegressionErrorDistribution(),\n","#    DataDriftPreset(stattest=anderson_stat_test, stattest_threshold=0.9),\n","#])"],"metadata":{"id":"OVx_ym6slJiF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And display the results right in the Jupyter notebook."],"metadata":{"id":"0KpXFbben4nH"}},{"cell_type":"code","source":["regression_perfomance.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1NGC6ReKdT0ORGDPdjFBK6eEiFSMZJQQA"},"id":"025_Z2s7nzSR","outputId":"d6c3f915-20ff-48e3-db2e-2a7167ae0b8e","executionInfo":{"status":"ok","timestamp":1729326071280,"user_tz":-480,"elapsed":6532,"user":{"displayName":"phonchi","userId":"13517391734500420886"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["We also save it as a .html file to be able to share it easily."],"metadata":{"id":"hqrrGQ19n-YR"}},{"cell_type":"code","source":["!mkdir reports\n","regression_perfomance.save_html('reports/regression_performance_at_training.html')"],"metadata":{"id":"UlLhOT-bn5lk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that the model has a fine quality given that we only trained on four weeks of data! The error is symmetric and distributed around zero. There is no obvious under- or over-estimation."],"metadata":{"id":"PoWgZ4pTpkyB"}},{"cell_type":"markdown","source":["**We will continue treating this dataset from model performance in training as our \"reference.\"** It gives us a good feel of the quality we can expect from our model in production use. So, we can contrast the future performance against this benchmark."],"metadata":{"id":"nE4AEQjDptqg"}},{"cell_type":"markdown","source":["## The first week in production"],"metadata":{"id":"A0bri5iupxKw"}},{"cell_type":"markdown","source":["Observing the model in production has straightforward goals. We want to detect if something goes wrong. Ideally, in advance. We also want to diagnose the root cause and get a quick understanding of how to address it. Maybe, the model degrades too fast, and we need to retrain it more often? Perhaps, the error is too high, and we need to adapt the model and rebuild it? Which new patterns are emerging?"],"metadata":{"id":"VLyYWGkGp5Qf"}},{"cell_type":"markdown","source":["**In our case, we simply start by checking how well the model performs outside the training data.** Our first week becomes what would have otherwise been a holdout dataset."],"metadata":{"id":"BsMCe5LtqCA_"}},{"cell_type":"markdown","source":["> For demonstration purposes, we generated all predictions for several weeks ahead in a single batch. In reality, we would run the model sequentially as the data comes in."],"metadata":{"id":"dQxmp_hcqcGO"}},{"cell_type":"code","source":["current = raw_data.loc['2011-01-29 00:00:00':'2011-02-28 23:00:00']\n","current_prediction = regressor.predict(current[numerical_features + categorical_features])\n","current['prediction'] = current_prediction"],"metadata":{"id":"IUHnh0T4bEtd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's start by comparing the performance in the first week to what we have seen in training. The first 28 days are our Reference dataset; the next 7 are the Production."],"metadata":{"id":"QJZfR_1nqN9v"}},{"cell_type":"code","source":["regression_perfomance = Report(metrics=[RegressionPreset()], options={\"render\": {\"raw_data\": True}})\n","regression_perfomance.run(current_data=current.loc['2011-01-29 00:00:00':'2011-02-07 23:00:00'],\n","                          reference_data=reference,\n","                          column_mapping=column_mapping)"],"metadata":{"id":"VBj1VwxhqXCv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729326326401,"user_tz":-480,"elapsed":1100,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"a70e1b00-1410-434f-ed1a-3ebc62dbaa59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning:\n","\n","R^2 score is not well-defined with less than two samples.\n","\n"]}]},{"cell_type":"code","source":["regression_perfomance.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10TfBwLf-B4A1Y_voMC_ZOlDhjOlCJbsr"},"id":"c-7cgGIaXqXq","executionInfo":{"status":"ok","timestamp":1729326345282,"user_tz":-480,"elapsed":6118,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"9b17e67d-1903-46c6-c2c5-08a66ae020f4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["The error has slightly increased and is leaning towards underestimation. Let's check if there is any statistical change in our target. To do that, we will generate the Target Drift report."],"metadata":{"id":"qbkfM_41qzyg"}},{"cell_type":"code","source":["target_drift = Report(metrics=[TargetDriftPreset()], options={\"render\": {\"raw_data\": True}})\n","target_drift.run(current_data=current.loc['2011-01-29 00:00:00':'2011-02-07 23:00:00'],\n","                 reference_data=reference,\n","                 column_mapping=column_mapping)"],"metadata":{"id":"wVXKswZzqkHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_drift.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1rCiTnxfNqlDRUmEGvWHHBLPKnKJLJ6rP"},"id":"99NYOCCtYAYy","executionInfo":{"status":"ok","timestamp":1729326440647,"user_tz":-480,"elapsed":5061,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"962999e7-bb41-4724-d29a-af35ba07408c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["We can see that the distribution of the actual number of bikes rented remains sufficiently similar. To be more precise, the similarity hypothesis is not rejected. No drift is detected. The distributions of our predictions did not change much either.\n","\n","Despite this, a rational decision is to update your model by including the new week's data. This way, the model can continue to learn, and we can probably improve the error. For the sake of demonstration, we'll stick to see how fast things go really wrong."],"metadata":{"id":"LWS-ySJzvECQ"}},{"cell_type":"markdown","source":["## The second week: failing to keep up"],"metadata":{"id":"4QDm3J2ivVzI"}},{"cell_type":"markdown","source":["Once again, we benchmark our new week against the reference dataset."],"metadata":{"id":"DLzuOsh8vbdB"}},{"cell_type":"code","source":["regression_performance = Report(metrics=[RegressionPreset()], options={\"render\": {\"raw_data\": True}})\n","regression_perfomance.run(current_data=current.loc['2011-02-07 00:00:00':'2011-02-14 23:00:00'],\n","                          reference_data=reference,\n","                          column_mapping=column_mapping)"],"metadata":{"id":"6dEvt5nSq6KS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regression_perfomance.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1o8Ka2CyRJuyrngT7o-soM6TmRP9IEXGS"},"id":"z2K26AvsYlYp","executionInfo":{"status":"ok","timestamp":1729326539050,"user_tz":-480,"elapsed":5944,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"2160d422-9cdc-46af-c894-28b9c70d4a3c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["At first glance, the model performance in the second week does not differ much. MAE remains almost the same. But, the skew towards under-estimation continues to grow. It seems that the error is not random! To know more, we move to the plots. We can see that the model catches overall daily trends just fine. So it learned something useful! **But, at peak hours, the actual demand tends to be higher than predicted.**\n","\n","In the error distribution plot, we can see how it became \"wider,\" as we have more predictions with a high error. The shift to the left is visible, too. In some extreme instances, we have errors between 80 and 40 bikes that were unseen previously."],"metadata":{"id":"MolwD2Jmz8ep"}},{"cell_type":"markdown","source":["Let's check our target as well."],"metadata":{"id":"_x9MCofe0lMp"}},{"cell_type":"code","source":["target_drift = Report(metrics=[TargetDriftPreset()], options={\"render\": {\"raw_data\": True}})\n","target_drift.run(current_data=current.loc['2011-02-07 00:00:00':'2011-02-14 23:00:00'],\n","                 reference_data=reference,\n","                 column_mapping=column_mapping)"],"metadata":{"id":"uGXfwnbQvnsP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_drift.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yT_txe37IPqkfXMgVgWhzwNj2qmzBtqv"},"id":"5Dy4JGGeZLRo","executionInfo":{"status":"ok","timestamp":1729326653321,"user_tz":-480,"elapsed":5056,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"b60a2033-d505-4906-fd7e-8a9098ac2915"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Things are getting interesting!\n","\n","**We can see that the target distribution is now different: the similarity hypothesis is rejected. Literally, people are renting more bikes. And this is a statistically different change from our training period.**"],"metadata":{"id":"CbOFix3I1Leh"}},{"cell_type":"markdown","source":["But, the distribution of our predictions does not keep up! That is an obvious example of **model decay. Something new happens in the world, but it misses the patterns.**"],"metadata":{"id":"m2fLq7_B1a-C"}},{"cell_type":"markdown","source":["It is tempting to investigate further. Is there anything in the data that can explain this change? If there is some new signal, retraining would likely help the model to keep up. The Target Drift report has a section to help us explore the relationship between the features and the target (or model predictions).\n","‍When browsing through the individual features, we can inspect if we notice any new patterns. We know that predictions did not change, so we only look at the relations with the target. **For example, there is a shift towards higher temperatures (measured in Celsius) with a corresponding increase in rented bikes.**\n","\n","Maybe, it would pick up these patterns in retraining. But for now, we simply move on to the next week without any updates."],"metadata":{"id":"wXe-5sUn1yWJ"}},{"cell_type":"markdown","source":["## Week 3: when things go south"],"metadata":{"id":"RfIqni0-4hBS"}},{"cell_type":"code","source":["regression_performance = Report(metrics=[RegressionPreset()], options={\"render\": {\"raw_data\": True}})\n","regression_perfomance.run(current_data=current.loc['2011-02-15 00:00:00':'2011-02-21 23:00:00'],\n","                          reference_data=reference,\n","                          column_mapping=column_mapping)"],"metadata":{"id":"J61Zn7jd1Ope","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729326797792,"user_tz":-480,"elapsed":576,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"0315e06e-b746-489a-efeb-595009305f6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning:\n","\n","R^2 score is not well-defined with less than two samples.\n","\n"]}]},{"cell_type":"code","source":["regression_perfomance.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1w00iQjZgkpOeTgYvJsszbw1ltUNdfJCg"},"id":"w0tpbcfebHXH","executionInfo":{"status":"ok","timestamp":1729326806924,"user_tz":-480,"elapsed":7206,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"6c262adf-a334-4f33-ae7a-6f6a54a94e97"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Okay, now things do look bad. On week 3, we face a major quality drop. Both absolute and percentage error grew significantly. If we look at the plots, the model predictions are visibly scattered. We also face a **new data segment with high demand that the model fails to predict.** But even within the known range of target value, the model now makes errors. Things did change since the training. We can see that the model does not extrapolate well. The predicted demand stays within the same known range, while actual values are peaking."],"metadata":{"id":"jLXpBPTX4yFh"}},{"cell_type":"markdown","source":["If we zoom in on specific days, we might suggest that the error is higher on specific (active) hours of the day. We are doing just fine from 10 pm to 6 am!"],"metadata":{"id":"rnehcGDO5MvQ"}},{"cell_type":"markdown","source":["In our example, we particularly want to understand the segment where the model underestimates the target function. The `Error Bias table` gives up more details. We sort it by the `\"Range%\"` field. **If the values of a specific feature are significantly different in the group where the model under- or over-estimates, this feature will rank high**. **In our case, we can see that the extreme errors are dependent on the \"temp\" (temperature) and \"atemp\" (feels-like temperature) features.**"],"metadata":{"id":"M2WaWSyu5kJ6"}},{"cell_type":"markdown","source":["After this quick analysis, we have a more specific idea about model performance and its weaknesses. The model faces new, unusually high demand. Given how it was trained, it tends to underestimate it. On top of it, these errors are not at all random. At the very least, they are related to the temperature we observe. The higher it is, the larger the underestimation. **It suggests new patterns that are related to the weather that the model could not learn before. Days got warmer, and the model went rogue.**\n","\n","If we run a target drift report, we will also see a relevant change in the linear correlations between the feature and the target. Temperature and humidity stand out."],"metadata":{"id":"mY2qSYOB65dQ"}},{"cell_type":"code","source":["target_drift = Report(metrics=[TargetDriftPreset()], options={\"render\": {\"raw_data\": True}})\n","target_drift.run(current_data=current.loc['2011-02-15 00:00:00':'2011-02-21 23:00:00'],\n","                 reference_data=reference,\n","                 column_mapping=column_mapping)"],"metadata":{"id":"pDEkUgaEiHVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_drift.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"11-8Fii8rIFONMXWU2G_1k8gUU4nf3v_6"},"id":"wl7k3w3HeQz-","executionInfo":{"status":"ok","timestamp":1729326919555,"user_tz":-480,"elapsed":4963,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"3951e999-1c0c-439c-bd05-1de07f8762e1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["We should retrain as soon as possible and do this often until we learn all the patterns. If we are not comfortable with frequent retraining, we might choose an algorithm that is more suitable for time series or is better in extrapolation."],"metadata":{"id":"IM8Tmqf07BuO"}},{"cell_type":"markdown","source":["## Data Drift"],"metadata":{"id":"sh-nc7Qp7NKK"}},{"cell_type":"markdown","source":["In practice, once we receive the ground truth, we can indeed course-correct quickly. Had we retrained the model after week one, it would have likely ended less dramatically. **But what if we do not have the ground truth available? Can we catch such decay in advance?**\n","\n","In this case, we can analyze the data drift. We do not need actuals to calculate the error. Instead, our goal is to see if the input data has changed."],"metadata":{"id":"g6WPMeSu7O2K"}},{"cell_type":"markdown","source":["**Once again, let's compare the first week of production to our data in training.** We can, of course, look at all our features. But we can also conclude that categorical features (like \"season,\" \"holiday\" and \"workingday\") are not likely to change. Let's look at numerical features only!\n","\n","We specify these features so that the tool applies the correct statistical test. It would be Kolmogorov-Smirnov in this case."],"metadata":{"id":"Ib0cUpnS7ixR"}},{"cell_type":"code","source":["column_mapping = ColumnMapping()\n","\n","column_mapping.numerical_features = numerical_features"],"metadata":{"id":"Fgg-JXN24rrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_drift = Report(metrics = [DataDriftPreset()], options={\"render\": {\"raw_data\": True}})\n","data_drift.run(current_data = current.loc['2011-01-29 00:00:00':'2011-02-07 23:00:00'],\n","               reference_data = reference,\n","               column_mapping=column_mapping)"],"metadata":{"id":"qDk5S6e-8Q8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_drift.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1WXpZ3un4gtPMi9tqCh5vWuZGP3wsN5Af"},"id":"ird6PbCjeZKG","executionInfo":{"status":"ok","timestamp":1729327090407,"user_tz":-480,"elapsed":4437,"user":{"displayName":"phonchi","userId":"13517391734500420886"}},"outputId":"a45cb36e-ce35-4bba-b7c4-43174795173c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["> The data drift report compares the distributions of each feature in the two datasets. It [automatically picks an appropriate statistical test](https://docs.evidentlyai.com/reference/data-drift-algorithm) or metric based on the feature type and volume. It then returns p-values or distances and visually plots the distributions. You can also adjust the drift detection method or thresholds, or pass your own."],"metadata":{"id":"HICuul0BmSTT"}},{"cell_type":"markdown","source":["Once we show the report, it returns an answer. We can see already during the first week there is a statistical change in feature distributions.\n","\n","Let's zoom in on our usual suspect—temperature. The report gives us two views on how the feature distributions evolve with time. We can notice how the observed temperature becomes higher day by day. The values clearly drift out of our green corridor (one standard deviation from the mean) that we saw in training. Looking at the steady growth, we can suspect an upward trend."],"metadata":{"id":"uaLxHzFP8gR6"}},{"cell_type":"markdown","source":["As we checked earlier, we did not detect drift in the model predictions after week one. Given that our model is not good at extrapolating, we should not really expect it. Such prediction drift might still happen and signal about things like broken input data. Otherwise, we would observe it if we had a more sensitive model. Regardless of this, the data drift alone provides excellent early monitoring to detect the change and react to it."],"metadata":{"id":"uBklQ9iN86dz"}},{"cell_type":"markdown","source":["For more information please refer to https://github.com/evidentlyai/evidently, https://github.com/SeldonIO/alibi-detect, https://github.com/great-expectations/great_expectations or https://github.com/whylabs/whylogs"],"metadata":{"id":"0rSXNKI_9QtJ"}},{"cell_type":"markdown","source":["# 📘 References"],"metadata":{"id":"AtFEKqSZ6VKw"}},{"cell_type":"markdown","source":["1. https://github.com/ageron/handson-ml2/blob/master/19_training_and_deploying_at_scale.ipynb\n","2. https://github.com/bentoml/BentoML\n","3. https://github.com/streamlit/streamlit\n","4. https://raw.githubusercontent.com/dataprofessor/code/master/streamlit/part2/iris-ml-app.py\n","5. https://gradio.app/image-classification-in-tensorflow/\n","6. https://evidentlyai.com/blog/tutorial-1-model-analytics-in-production"],"metadata":{"id":"y9YBJyOw6XSM"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"nav_menu":{},"toc":{"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":6,"toc_cell":false,"toc_section_display":"block","toc_window_display":false},"colab":{"provenance":[],"collapsed_sections":["crG8mceteV3J"]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}