{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZguKQsaEtw45"
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxvUeukG506E"
   },
   "source": [
    "#### Student ID: *Double click here to fill the Student ID*\n",
    "\n",
    "#### Name: *Double click here to fill the name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BHuiK8mtw5U"
   },
   "source": [
    "## Q1: Transfer Learning on the Dataset Used by the CNN Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obleIPRdcPi1"
   },
   "source": [
    "[CNN Explainer](https://poloclub.github.io/cnn-explainer/) is an interactive, open-source visualization tool designed to provide a comprehensive understanding of Convolutional Neural Networks (CNNs). In the last assignment, we attempted to replicate the original experiment using TinyVGG by training the model from scratch. However, the results were not satisfactory. In this exercise, we will continue our work and leverage transfer learning to improve performance on the test dataset. First, load the dataset using the following code (feel free to modify the code if you prefer to use PyTorch or other frameworks).\n",
    "\n",
    "To ensure reproducibility, please set all the random seeds to 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUx-PTLN9_m6"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy https://drive.google.com/file/d/1DvyriY4ehA56Bj3asAbCz_syYZvTkumW/view?usp=sharing\n",
    "!unzip cnn_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXuw0MUY-tB6"
   },
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "training_images = 'train_images/'\n",
    "vali_images = 'val_images/'\n",
    "test_images = 'test_images/'\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    training_images,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    seed=seed)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    vali_images,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=False,\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_images,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=False,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3ZRsJXwtw5U"
   },
   "source": [
    "#### (a) EfficientNet is a modern convolutional neural network obtained through [network architecture search](https://lilianweng.github.io/posts/2020-08-06-nas/). We will use it to perform transfer learning by following the procedure below: (10%)\n",
    "\n",
    "1. Add a callback to monitor the validation loss and save the best model based on the validation loss.\n",
    "\n",
    "2. Import the convolutional base of [`EfficientNetV2Backbone`](https://keras.io/api/keras_cv/models/backbones/efficientnetv2/) (`efficientnetv2_b0`) with pre-trained weights from ImageNet. Freeze all the weights in the convolutional base.\n",
    "\n",
    "3. Add a dropout layer after the convolutional base (remember to flatten the output of the base before applying dropout) with a dropout rate of 0.5, followed by a dense layer with softmax activation to classify the 10 classes.\n",
    "\n",
    "4. Train the model for 10 epochs using the [`Nadam`](https://keras.io/api/optimizers/Nadam/) optimizer with the default learning rate. Finally, report the accuracy on the test set. Remember to reload the best model before testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vs4aGKJ8G_Hr"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKBN2rt7qjGo"
   },
   "source": [
    "#### (b) Contrastive Language-Image Pre-Training (CLIP) is a foundational model that includes both text and image encoders. Its multimodal nature enables zero-shot classification. In this problem, we will leverage [`CLIP`](https://huggingface.co/docs/transformers/model_doc/clip) to perform classification. (10%)\n",
    "\n",
    "1. Load the model and processor using the checkpoint [`openai/clip-vit-base-patch32`](https://huggingface.co/openai/clip-vit-base-patch32) from Hugging Face.\n",
    "\n",
    "2. Use the following list as the candidate text labels:\n",
    "    ```\n",
    "    ['boat',\n",
    "     'bug',\n",
    "     'bus',\n",
    "     'car',\n",
    "     'espresso',\n",
    "     'koala',\n",
    "     'orange',\n",
    "     'panda',\n",
    "     'pepper',\n",
    "     'pizza']\n",
    "    ```\n",
    "\n",
    "3. Perform zero-shot 10-class classification using the processor and the `CLIP` model on the test dataset.\n",
    "\n",
    "4. Calculate the accuracy on the test dataset.\n",
    "\n",
    "**Hint:** Refer to our lab to learn how to perform zero-shot classification. Remember that you can extract the image data and labels from the test set into `X` and `y` `NumPy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-193Q_EzCPK"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roHGPOEUqtLP"
   },
   "source": [
    "#### (c) [Stable Diffusion](https://huggingface.co/blog/stable_diffusion) is a text-to-image model that can generate high-quality images using a diffusion model. Design a prompt (e.g., \"a photo of ...\") to generate three realistic photos that belong to one of the given 10 classes in the CNN Explainer (e.g., koala, bug) using `diffusers` or `KerasCV`. Finally, plot the three generated images. Additionally, resize the three images you generate into $64 \\times 64$ pixels. (10%)\n",
    "\n",
    "**Hint:** You can use `PIL`, `OpenCV`, `Skimage`, or even `NumPy` to resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvTRaPnZfjyR"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czaC_c-fPCpr"
   },
   "source": [
    "#### (d) Use the best model you identified in part (a) and the `CLIP` model from part (b) to perform inference on the three downsampled images you generated in (c). Are the results from both models correct for all three images? (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGEdx0089zVI"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl8vI7BMxsvk"
   },
   "source": [
    "> Ans: *double click here to answer the question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP6Kl7FKFk-I"
   },
   "source": [
    "### (e) Use [`KerasTuner`](https://keras.io/keras_tuner/) to Perform Network Architecture Search. The search space is described as follows (15%):\n",
    "\n",
    "|        | Type                | Activation | Notice|\n",
    "|--------|---------------------|---------|------------|\n",
    "| Output | Fully connected    | Softmax    ||\n",
    "| D1 | DropOut     |        ||\n",
    "| F1     | Fully connected         | ReLu ||\n",
    "| FL     | Flatten              |            ||\n",
    "| ...     |  |                  |The convoltion blocks may repeat 1~3 times|\n",
    "| P1     | Max pooling     |------------|\\||\n",
    "| R2     | ReLu         ||\\||\n",
    "| B2     | batch normalization ||\\||\n",
    "| C2     | Convolution     ||\\|-------> These 7 layer forms 1 convolution blocks|\n",
    "| R1     | ReLu         ||\\||\n",
    "| B1     | batch normalization ||\\||\n",
    "| C1     | Convolution      |------------|\\||\n",
    "| In     | Input         |           ||\n",
    "\n",
    "1. **Number of Convolutional Blocks:** Search for the number of convolutional blocks (each block consists of seven layers: (Convolution, Batch Normalization, ReLU) Ã— 2 followed by a pooling layer) from 1 to 3. Fix the filter size to 3 for the convolution layer.\n",
    "2. **Number of Filters:** Search for the number of filters used in the convolutional layers within the convolutional blocks from 16 to 96, with a step size of 16.\n",
    "3. **Number of Neurons in Dense Layer:** Search for the number of neurons in the first dense layer from 20 to 50, with a step size of 10.\n",
    "4. **Dropout Rate:** Search for the dropout rate from 0.3 to 0.8, with a step size of 0.1.\n",
    "5. **Learning Rate:** Use the Adam optimizer and search for the learning rate from 0.0001 to 0.01, using a logarithmic sampling strategy with a step size of 10.\n",
    "\n",
    "Use Bayesian optimization to conduct a maximum of 3 trials with two executions per trial. Evaluate the performance on the entire validation set for 10 epochs during the search.\n",
    "\n",
    "Finally, use the architecture you identified and report the test accuracy achieved with this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pHBu0XyfuRp"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOKAcNZwfuqJ"
   },
   "source": [
    "> Ans: *double click here to answer the question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChZb5jvSqx1o"
   },
   "source": [
    "## Q2: Analyze Sentiment Dataset Using Different Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2PxLTnfj-gw"
   },
   "source": [
    "[Sentiment Analysis](https://huggingface.co/tasks/text-classification) is a subfield of Natural Language Processing (NLP) that involves determining the emotional tone behind words. Its purpose is to understand the attitudes, opinions, and emotions of a speaker or writer with respect to a specific topic or the overall contextual polarity of a document. In this problem, we will use datasets sourced from three different websites: `imdb.com`, `amazon.com`, and `yelp.com`. We will classify each sentence as positive (1) or negative (0).\n",
    "\n",
    "Firstly, execute the following code cell to import the datasets and organize them into a unified dataset. Feel free to modify the code if you prefer to use `PyTorch` or other frameworks.\n",
    "\n",
    "To ensure reproducibility, please set all the random seeds to 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noIyNcFN7ZOS"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy https://drive.google.com/file/d/1E_l4Mh3OU6tRJWXFVrtXaHV-FN6j0Urm/view?usp=sharing\n",
    "!unzip -qq /content/nlp_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ct1b2tDh-6VH"
   },
   "outputs": [],
   "source": [
    "filepath_dict = {'yelp':  'nlp_data/yelp_labelled.txt',\n",
    "          'amazon': 'nlp_data/amazon_cells_labelled.txt',\n",
    "          'imdb':  'nlp_data/imdb_labelled.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "sentences = df['sentence'].to_numpy()\n",
    "y = df['label'].to_numpy()\n",
    "\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.3, random_state=2024)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((sentences_train, y_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((sentences_test, y_test))\n",
    "# For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n",
    "train_ds = train_ds.shuffle(3000).batch(32)\n",
    "val_ds = val_ds.batch(32)\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78DPz9LfMDwD"
   },
   "source": [
    "#### (a) The Bag-of-Words model is a popular approach in NLP for representing text data, and we will use this model first. (10%)\n",
    "\n",
    "1. **Build Text Representation:** Create representations of the input text using bigrams with different encoding methods (multi-hot, count, and TF-IDF). Set the maximum number of tokens to 10,000 during vectorization to obtain a 5,000-dimensional vector for each sample.\n",
    "\n",
    "2. **Construct Classifier:** Build a Random Forest classifier with `n_estimators` set to 10.\n",
    "\n",
    "3. **Compare Encoding Methods:** Use the model and the accuracy metric to compare the multi-hot, count, and TF-IDF encoding methods. Determine which encoding method performs best based on validation accuracy.\n",
    "\n",
    "**Hint:** Refer to our lab to learn how to use the `TextVectorization` layer in `Keras` to vectorize the training and validation sets. If you are using `PyTorch`, you may find `torchtext` and `TfidfVectorizer` from `sklearn` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9ds0zy3Arpe"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfK3zMOBaw_O"
   },
   "source": [
    "> Ans: *double click here to answer the question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OO0-SIIFq6FK"
   },
   "source": [
    "#### (b) Now we will try to improve the performance by tuning the hyperparameters using [`Optuna`](https://optuna.org/). (10%)\n",
    "\n",
    "1. **Define the Parameter Grid:**  \n",
    "   ```python\n",
    "   param_grid = {\n",
    "       'n_estimators': (10, 50),\n",
    "       'criterion': ['gini', 'entropy'],\n",
    "       'min_samples_split': (2, 4),\n",
    "       'max_features': ['sqrt', 'log2']\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. **Perform Hyperparameter Search:**  \n",
    "   Use Bayesian optimization with [`GPSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.GPSampler.html) to search for the best hyperparameters. Treat `n_estimators` and `min_samples_split` as integer parameters, and `criterion` and `max_features` as categorical parameters. Perform cross-validation with 5 folds during the search.\n",
    "\n",
    "3. **Construct and Evaluate the Model:**  \n",
    "   Build the Random Forest classifier using the best hyperparameters found in step 2. Report the accuracy on the validation set.\n",
    "\n",
    "**Hint:** Refer to the [`Optuna` documentation](https://optuna.readthedocs.io/en/stable/index.html) or our lab for guidance on setting up the sampler and defining the search space. Ensure that cross-validation is properly integrated into the hyperparameter tuning process to obtain reliable performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqgZO-arBEAV"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wRfx0ZSf42Z"
   },
   "source": [
    "> Ans: *double click here to answer the question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl_ezRItL-sz"
   },
   "source": [
    "#### (c) We will now proceed with a sequence model. To determine the maximum length used in the vectorizer, draw a histogram showing the distribution of the number of words in each sentence in the dataset. Furthermore, calculate the average number of words and the 95% quantile of the word counts, and label them on the plot. (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8VPRN7O9zMI"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGkIJ-MUrRMA"
   },
   "source": [
    "#### (d) (10%)\n",
    "\n",
    "1. **Set Maximum Length:** Set the maximum length to 10,000 when vectorizing the text and use the 95th percentile of the number of words in the sentences identified in part (c) as the maximum token length.\n",
    "\n",
    "2. **Build an RNN Model:** Construct a Recurrent Neural Network (RNN) with the following architecture:\n",
    "\n",
    "|        | Type                | Channels    | Activation | Notice|\n",
    "|--------|---------------------|---------|------------|------------|\n",
    "| Output | Fully connected     |       | Sigmoid    | Binary classification|\n",
    "| D1     | Dropout |         |            |with dropout rate set to 0.8|\n",
    "| R1     | Bidirectional RNN  with GRU cell        | 8      |        |Bidirectional RNN layer with 8 GRU cells|\n",
    "| E1     | Embedding         |       |        | Output of embedding is set to 8 dimensions and remember to mask the padded zeros |\n",
    "| In     | Input               |  |            |Input is truncated to x words with 10,000 dimensions |                                        |\n",
    "\n",
    "3. **Compile and Train the Model:**  \n",
    "    - Add a callback to monitor the validation loss and save the best model based on **validation accuracy**.\n",
    "    - Compile the model using the `Adam` optimizer with the default learning rate.\n",
    "    - Fit the model for 10 epochs.\n",
    "\n",
    "4. **Evaluate the Model:**  \n",
    "    - Report the accuracy on the validation set.\n",
    "    - Compare this accuracy to the results obtained in part (b) and provide comments on the performance differences.\n",
    "\n",
    "**Hint:** Refer to our lab to learn how to use the `TextVectorization` layer in `Keras` to vectorize the training and validation sets. If you are using `PyTorch`, you may find `torchtext` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_E6uusHEHId"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BpoxccFf_eh"
   },
   "source": [
    "> Ans: *double click here to answer the question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjY6TUoerNY5"
   },
   "source": [
    "#### (e) Generative Pre-trained Transformer (GPT) is a powerful pretrained foundation model that can generate text based on the [Transformer](https://transformer.realcat.top/). (10%)\n",
    "\n",
    "1. **Load the Model and Tokenizer:**  \n",
    "   Load the model and tokenizer using the checkpoint [`gpt2-xl`](https://huggingface.co/gpt2-xl) from Hugging Face.\n",
    "\n",
    "2. **Generate a Positive Review:**  \n",
    "   Design a prompt and use the `generate()` method to produce 30 tokens that represent a positive review. For example, you can input the text \"The movie is great since\" and allow the model to generate 30 tokens.\n",
    "\n",
    "3. **Classify the Generated Review:**  \n",
    "   Feed the generated review into the best model identified in parts (a) and (c). Determine whether the model predicts the review as positive.\n",
    "\n",
    "**Hint:** You can adjust parameters such as `do_sample`, `top_k`, `num_beams`, or `temperature` in the `generate()` function to make the generated text more convincing. Refer to our lab for a brief introduction. You may also find the [Transformer Explainer](https://transformer.realcat.top/) useful for understanding GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5ZQhPpDrAdr"
   },
   "outputs": [],
   "source": [
    "# coding your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnLC8ZuAxiZk"
   },
   "source": [
    "> Ans: *double click here to answer the question.*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
